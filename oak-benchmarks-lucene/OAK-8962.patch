diff --git oak-benchmarks-lucene/pom.xml oak-benchmarks-lucene/pom.xml
new file mode 100644
index 0000000..d639ecc
--- /dev/null
+++ oak-benchmarks-lucene/pom.xml
@@ -0,0 +1,55 @@
+<?xml version="1.0" encoding="UTF-8"?>
+
+<!--
+   Licensed to the Apache Software Foundation (ASF) under one or more
+   contributor license agreements.  See the NOTICE file distributed with
+   this work for additional information regarding copyright ownership.
+   The ASF licenses this file to You under the Apache License, Version 2.0
+   (the "License"); you may not use this file except in compliance with
+   the License.  You may obtain a copy of the License at
+
+       http://www.apache.org/licenses/LICENSE-2.0
+
+   Unless required by applicable law or agreed to in writing, software
+   distributed under the License is distributed on an "AS IS" BASIS,
+   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+   See the License for the specific language governing permissions and
+   limitations under the License.
+  -->
+<project xmlns="http://maven.apache.org/POM/4.0.0"
+         xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
+         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
+
+    <parent>
+        <groupId>org.apache.jackrabbit</groupId>
+        <artifactId>oak-parent</artifactId>
+        <version>1.27-SNAPSHOT</version>
+        <relativePath>../oak-parent/pom.xml</relativePath>
+    </parent>
+    <modelVersion>4.0.0</modelVersion>
+
+    <artifactId>oak-benchmarks-lucene</artifactId>
+
+    <properties>
+        <skip.deployment>true</skip.deployment>
+    </properties>
+
+    <dependencies>
+        <dependency>
+            <groupId>org.apache.jackrabbit</groupId>
+            <artifactId>oak-benchmarks</artifactId>
+            <version>${project.version}</version>
+        </dependency>
+        <dependency>
+            <groupId>org.apache.jackrabbit</groupId>
+            <artifactId>oak-lucene</artifactId>
+            <version>${project.version}</version>
+        </dependency>
+        <dependency>
+            <groupId>org.jetbrains</groupId>
+            <artifactId>annotations</artifactId>
+        </dependency>
+    </dependencies>
+
+
+</project>
\ No newline at end of file
diff --git oak-benchmarks-lucene/src/main/java/org/apache/jackrabbit/oak/benchmark/HybridIndexTest.java oak-benchmarks-lucene/src/main/java/org/apache/jackrabbit/oak/benchmark/HybridIndexTest.java
new file mode 100644
index 0000000..1361f94
--- /dev/null
+++ oak-benchmarks-lucene/src/main/java/org/apache/jackrabbit/oak/benchmark/HybridIndexTest.java
@@ -0,0 +1,590 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+package org.apache.jackrabbit.oak.benchmark;
+
+import java.io.File;
+import java.io.IOException;
+import java.lang.reflect.Field;
+import java.util.ArrayList;
+import java.util.Arrays;
+import java.util.List;
+import java.util.Queue;
+import java.util.Random;
+import java.util.concurrent.Executors;
+import java.util.concurrent.LinkedBlockingDeque;
+import java.util.concurrent.ExecutorService;
+import java.util.concurrent.ThreadPoolExecutor;
+import java.util.concurrent.TimeUnit;
+import java.util.concurrent.atomic.AtomicInteger;
+import java.util.function.Predicate;
+
+import javax.jcr.Node;
+import javax.jcr.Repository;
+import javax.jcr.RepositoryException;
+import javax.jcr.Session;
+import javax.jcr.query.Query;
+import javax.jcr.query.QueryManager;
+import javax.jcr.query.QueryResult;
+
+import com.google.common.base.Joiner;
+import com.google.common.collect.Iterators;
+import com.google.common.collect.Lists;
+import com.google.common.util.concurrent.MoreExecutors;
+import org.apache.commons.io.FileUtils;
+import org.apache.jackrabbit.oak.Oak;
+import org.apache.jackrabbit.oak.api.Type;
+import org.apache.jackrabbit.oak.api.jmx.IndexStatsMBean;
+import org.apache.jackrabbit.oak.fixture.JcrCreator;
+import org.apache.jackrabbit.oak.fixture.OakRepositoryFixture;
+import org.apache.jackrabbit.oak.fixture.RepositoryFixture;
+import org.apache.jackrabbit.oak.jcr.Jcr;
+import org.apache.jackrabbit.oak.plugins.index.AsyncIndexInfoService;
+import org.apache.jackrabbit.oak.plugins.index.AsyncIndexInfoServiceImpl;
+import org.apache.jackrabbit.oak.plugins.index.AsyncIndexUpdate;
+import org.apache.jackrabbit.oak.plugins.index.IndexConstants;
+import org.apache.jackrabbit.oak.plugins.index.IndexPathService;
+import org.apache.jackrabbit.oak.plugins.index.IndexPathServiceImpl;
+import org.apache.jackrabbit.oak.plugins.index.IndexUtils;
+import org.apache.jackrabbit.oak.plugins.index.lucene.IndexCopier;
+import org.apache.jackrabbit.oak.plugins.index.lucene.IndexTracker;
+import org.apache.jackrabbit.oak.plugins.index.lucene.LuceneIndexConstants;
+import org.apache.jackrabbit.oak.plugins.index.lucene.LuceneIndexEditorProvider;
+import org.apache.jackrabbit.oak.plugins.index.lucene.LuceneIndexProvider;
+import org.apache.jackrabbit.oak.plugins.index.lucene.hybrid.DocumentQueue;
+import org.apache.jackrabbit.oak.plugins.index.lucene.hybrid.LocalIndexObserver;
+import org.apache.jackrabbit.oak.plugins.index.lucene.hybrid.NRTIndexFactory;
+import org.apache.jackrabbit.oak.plugins.index.lucene.property.PropertyIndexCleaner;
+import org.apache.jackrabbit.oak.plugins.index.lucene.reader.DefaultIndexReaderFactory;
+import org.apache.jackrabbit.oak.plugins.index.lucene.reader.LuceneIndexReaderFactory;
+import org.apache.jackrabbit.oak.plugins.index.lucene.util.IndexDefinitionBuilder;
+import org.apache.jackrabbit.oak.plugins.index.lucene.util.IndexDefinitionBuilder.PropertyRule;
+import org.apache.jackrabbit.oak.plugins.index.search.FulltextIndexConstants;
+import org.apache.jackrabbit.oak.spi.commit.BackgroundObserver;
+import org.apache.jackrabbit.oak.spi.lifecycle.RepositoryInitializer;
+import org.apache.jackrabbit.oak.spi.mount.MountInfoProvider;
+import org.apache.jackrabbit.oak.spi.mount.Mounts;
+import org.apache.jackrabbit.oak.spi.query.QueryIndexProvider;
+import org.apache.jackrabbit.oak.spi.state.NodeBuilder;
+import org.apache.jackrabbit.oak.spi.state.NodeStore;
+import org.apache.jackrabbit.oak.spi.whiteboard.Registration;
+import org.apache.jackrabbit.oak.spi.whiteboard.Whiteboard;
+import org.apache.jackrabbit.oak.spi.whiteboard.WhiteboardUtils;
+import org.apache.jackrabbit.oak.stats.Clock;
+import org.apache.jackrabbit.oak.stats.StatisticsProvider;
+import org.jetbrains.annotations.NotNull;
+import org.jetbrains.annotations.Nullable;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import static com.google.common.base.Preconditions.checkNotNull;
+import static java.util.Collections.singleton;
+import static java.util.Collections.singletonList;
+import static org.apache.jackrabbit.oak.plugins.index.IndexConstants.DECLARING_NODE_TYPES;
+import static org.apache.jackrabbit.oak.plugins.index.IndexConstants.INDEX_DEFINITIONS_NODE_TYPE;
+import static org.apache.jackrabbit.oak.spi.nodetype.NodeTypeConstants.NT_OAK_UNSTRUCTURED;
+import static org.apache.jackrabbit.oak.spi.whiteboard.WhiteboardUtils.scheduleWithFixedDelay;
+
+public class HybridIndexTest extends AbstractTest<HybridIndexTest.TestContext> {
+    enum Status {
+        NONE, STARTING, STARTED, STOPPING, STOPPED, ABORTED;
+
+        private int count;
+
+        public void inc(){
+            count++;
+        }
+
+        public int count(){
+            return count;
+        }
+
+        public Status next(){
+            Status[] ss = values();
+            if (ordinal() == ss.length - 1){
+                return ss[0];
+            }
+            return ss[ordinal() + 1];
+        }
+    }
+
+    private final Random random = new Random(42); //fixed seed
+    private String indexedPropName = "foo";
+    private int nodesPerIteration = Status.values().length;
+    private int numOfIndexes = Integer.getInteger("numOfIndexes", 10);
+    private int refreshDeltaMillis = Integer.getInteger("refreshDeltaMillis", 1000);
+    private int asyncInterval = Integer.getInteger("asyncInterval", 5);
+    private int cleanerIntervalInSecs = Integer.getInteger("cleanerIntervalInSecs", 10);
+    private int queueSize = Integer.getInteger("queueSize", 1000);
+    private boolean hybridIndexEnabled = Boolean.getBoolean("hybridIndexEnabled");
+    private boolean dumpStats = Boolean.getBoolean("dumpStats");
+    private boolean useOakCodec = Boolean.parseBoolean(System.getProperty("useOakCodec", "true"));
+    private boolean syncIndexing = Boolean.parseBoolean(System.getProperty("syncIndexing", "false"));
+    private String indexingMode = System.getProperty("indexingMode", "nrt");
+
+    private boolean searcherEnabled = Boolean.parseBoolean(System.getProperty("searcherEnabled", "true"));
+    private File indexCopierDir;
+    private IndexCopier copier;
+    private NRTIndexFactory nrtIndexFactory;
+    private LuceneIndexProvider luceneIndexProvider;
+    private LuceneIndexEditorProvider luceneEditorProvider;
+    private DocumentQueue queue;
+    private LocalIndexObserver localIndexObserver;
+    private RepositoryInitializer indexInitializer = new PropertyIndexInitializer();
+    private TestContext defaultContext;
+    private final File workDir;
+    private Whiteboard whiteboard;
+    private Searcher searcher;
+    private Mutator mutator;
+    private final AtomicInteger indexedNodeCount = new AtomicInteger();
+    private List<TestContext> contexts = new ArrayList<>();
+    private final StatisticsProvider statsProvider;
+    private final Logger log = LoggerFactory.getLogger(getClass());
+    private final ExecutorService executorService = MoreExecutors.getExitingExecutorService(
+            (ThreadPoolExecutor) Executors.newFixedThreadPool(5));
+    private final List<Registration> regs = new ArrayList<>();
+    private BackgroundObserver backgroundObserver;
+
+
+    public HybridIndexTest(File workDir, StatisticsProvider statsProvider) {
+        this.workDir = workDir;
+        this.statsProvider = statsProvider;
+    }
+
+    @Override
+    protected Repository[] createRepository(RepositoryFixture fixture) throws Exception {
+        if (fixture instanceof OakRepositoryFixture) {
+            return ((OakRepositoryFixture) fixture).setUpCluster(1, new JcrCreator() {
+                @Override
+                public Jcr customize(Oak oak) {
+                    Jcr jcr = new Jcr(oak);
+                    whiteboard = oak.getWhiteboard();
+                    prepareLuceneIndexer(workDir, getNodeStore(oak));
+
+                    backgroundObserver = new BackgroundObserver(luceneIndexProvider, executorService, 5);
+
+                    jcr.with((QueryIndexProvider) luceneIndexProvider)
+                            .with(backgroundObserver)
+                            .with(luceneEditorProvider)
+                            .with(new NodeTypeIndexFixerInitializer());
+
+                    if (hybridIndexEnabled) {
+                        jcr.with(localIndexObserver);
+                        indexInitializer = new LuceneIndexInitializer();
+                    }
+
+                    jcr.with(indexInitializer);
+
+                    //Configure the default global fulltext index as it impacts
+                    //both pure property index based setup and nrt based
+                    //So more closer to real world
+                    jcr.with(new LuceneFullTextInitializer());
+
+                    //Async indexing is enabled for both property and lucene
+                    //as for property it relies on counter index
+                    oak.withAsyncIndexing("async", asyncInterval);
+                    return jcr;
+                }
+            });
+        }
+        return super.createRepository(fixture);
+    }
+
+    @Override
+    public void beforeSuite() throws Exception {
+        if (hybridIndexEnabled) {
+            runAsyncIndex();
+        }
+        defaultContext = new TestContext();
+        contexts.add(defaultContext);
+        searcher = new Searcher();
+        mutator = new Mutator();
+
+        if (searcherEnabled) {
+            addBackgroundJob(searcher);
+        }
+
+        addBackgroundJob(mutator);
+    }
+
+    @Override
+    protected TestContext prepareThreadExecutionContext() throws RepositoryException {
+        TestContext ctx = new TestContext();
+        contexts.add(ctx);
+        return ctx;
+    }
+
+    @Override
+    protected void runTest() throws Exception {
+        runTest(defaultContext);
+    }
+
+    @Override
+    protected void runTest(TestContext ctx)  throws Exception {
+        //Create tree in breadth first fashion with each node having 50 child
+        Node parent = ctx.session.getNode(ctx.paths.remove());
+        Status status = Status.NONE;
+        for (int i = 0; i < nodesPerIteration; i++) {
+            Node child = parent.addNode(nextNodeName());
+            child.setProperty(indexedPropName, status.name());
+            ctx.session.save();
+            ctx.paths.add(child.getPath());
+            indexedNodeCount.incrementAndGet();
+            status.inc();
+            status = status.next();
+        }
+    }
+
+    @Override
+    protected void disposeThreadExecutionContext(TestContext context) throws RepositoryException {
+        context.dispose();
+    }
+
+    @Override
+    protected void afterSuite() throws Exception {
+        //TODO This to avoid issue with Indexing still running post afterSuite call
+        //TO handle this properly we would need a callback after repository shutdown
+        //and before NodeStore teardown
+        getAsyncIndexUpdate().close();
+
+        if (backgroundObserver != null){
+            backgroundObserver.close();
+        }
+
+        int sleepCount = 0;
+        while (backgroundObserver.getMBean().getQueueSize()> 0 && ++sleepCount < 100) {
+            TimeUnit.MILLISECONDS.sleep(100);
+        }
+
+        for (Registration r : regs) {
+            r.unregister();
+        }
+
+        //Close hybrid stuff after async is closed
+        if (hybridIndexEnabled){
+            queue.close();
+            nrtIndexFactory.close();
+        }
+
+        if (indexCopierDir != null) {
+            FileUtils.deleteDirectory(indexCopierDir);
+        }
+        System.out.printf("numOfIndexes: %d, refreshDeltaMillis: %d, asyncInterval: %d, queueSize: %d , " +
+                        "hybridIndexEnabled: %s, indexingMode: %s, useOakCodec: %s, cleanerIntervalInSecs: %d, " +
+                        "syncIndexing: %s %n",
+                numOfIndexes, refreshDeltaMillis, asyncInterval, queueSize, hybridIndexEnabled,
+                indexingMode, useOakCodec, cleanerIntervalInSecs, syncIndexing);
+
+        if (dumpStats) {
+            dumpStats();
+        }
+    }
+
+    @Override
+    protected String[] statsNames() {
+        return new String[]{"Searcher", "Mutator", "Indexed"};
+    }
+
+    @Override
+    protected String[] statsFormats() {
+        return new String[]{"%8d", "%8d", "%8d"};
+    }
+
+    @Override
+    protected Object[] statsValues() {
+        return new Object[]{searcher.resultSize, mutator.mutationCount, indexedNodeCount.get()};
+    }
+
+    @Override
+    protected String comment() {
+        List<String> commentElements = new ArrayList<>();
+        if (hybridIndexEnabled){
+            commentElements.add(indexingMode);
+
+            if (useOakCodec){
+                commentElements.add("oakCodec");
+            }
+            if (syncIndexing) {
+                commentElements.add("sync");
+            }
+        } else {
+            commentElements.add("property");
+        }
+
+        commentElements.add("numIdxs:"+ numOfIndexes);
+        return Joiner.on(',').join(commentElements);
+    }
+
+    protected class TestContext {
+        final Session session = loginWriter();
+        final Queue<String> paths = new LinkedBlockingDeque<>();
+
+        final Node dump;
+
+        public TestContext() throws RepositoryException {
+            dump = session.getRootNode()
+                    .addNode(nextNodeName(), NT_OAK_UNSTRUCTURED)
+                    .addNode(nextNodeName(), NT_OAK_UNSTRUCTURED)
+                    .addNode(nextNodeName(), NT_OAK_UNSTRUCTURED)
+                    .addNode(nextNodeName(), NT_OAK_UNSTRUCTURED)
+                    .addNode(nextNodeName(), NT_OAK_UNSTRUCTURED)
+                    .addNode(nextNodeName(), NT_OAK_UNSTRUCTURED);
+            session.save();
+            paths.add(dump.getPath());
+        }
+
+        public void dispose() throws RepositoryException {
+            dump.remove();
+            session.logout();
+        }
+    }
+
+    private String randomStatus() {
+        Status status = Status.values()[random.nextInt(Status.values().length)];
+        status.inc();
+        return status.name();
+    }
+
+    private void prepareLuceneIndexer(File workDir, NodeStore nodeStore) {
+        try {
+            indexCopierDir = createTemporaryFolderIn(workDir);
+            copier = new IndexCopier(executorService, indexCopierDir, true);
+        } catch (IOException e) {
+            throw new RuntimeException(e);
+        }
+
+        IndexPathService indexPathService = new IndexPathServiceImpl(nodeStore);
+        AsyncIndexInfoService asyncIndexInfoService = new AsyncIndexInfoServiceImpl(nodeStore);
+
+        nrtIndexFactory = new NRTIndexFactory(copier, Clock.SIMPLE,
+                TimeUnit.MILLISECONDS.toSeconds(refreshDeltaMillis), StatisticsProvider.NOOP);
+        MountInfoProvider mip = Mounts.defaultMountInfoProvider();
+        LuceneIndexReaderFactory indexReaderFactory = new DefaultIndexReaderFactory(mip, copier);
+
+        IndexTracker tracker = new IndexTracker(indexReaderFactory, nrtIndexFactory);
+
+        luceneIndexProvider = new LuceneIndexProvider(tracker);
+        luceneEditorProvider = new LuceneIndexEditorProvider(copier,
+                tracker,
+                null, //extractedTextCache
+                null, //augmentorFactory
+                mip);
+
+        queue = new DocumentQueue(queueSize, tracker, executorService, statsProvider);
+        localIndexObserver = new LocalIndexObserver(queue, statsProvider);
+        luceneEditorProvider.setIndexingQueue(queue);
+
+        if (syncIndexing) {
+            PropertyIndexCleaner cleaner = new PropertyIndexCleaner(nodeStore, indexPathService, asyncIndexInfoService, statsProvider);
+            regs.add(scheduleWithFixedDelay(whiteboard, cleaner,
+                    cleanerIntervalInSecs, true, true));
+        }
+
+
+        Thread.setDefaultUncaughtExceptionHandler((t, e) -> log.warn("Uncaught exception", e));
+    }
+
+    private void runAsyncIndex() {
+        checkNotNull(getAsyncIndexUpdate()).run();
+    }
+
+    private AsyncIndexUpdate getAsyncIndexUpdate() {
+        return (AsyncIndexUpdate)WhiteboardUtils.getService(whiteboard, Runnable.class, new Predicate<Runnable>() {
+                @Override
+                public boolean test(@Nullable Runnable input) {
+                    return input instanceof AsyncIndexUpdate;
+                }
+            });
+    }
+
+    private void dumpStats() {
+        IndexStatsMBean indexStats = WhiteboardUtils.getService(whiteboard, IndexStatsMBean.class);
+        System.out.println(indexStats.getConsolidatedExecutionStats());
+        String queueSize = Arrays.toString(statsProvider.getStats().getTimeSeries("HYBRID_QUEUE_SIZE", false)
+                .getValuePerSecond());
+        System.out.println("Queue size - " + queueSize);
+    }
+
+    @SuppressWarnings("ResultOfMethodCallIgnored")
+    private static File createTemporaryFolderIn(File parentFolder) throws IOException {
+        File createdFolder = File.createTempFile("oak-", "", parentFolder);
+        createdFolder.delete();
+        createdFolder.mkdir();
+        return createdFolder;
+    }
+
+    private static NodeStore getNodeStore(Oak oak) {
+        try {
+            Field f = Oak.class.getDeclaredField("store");
+            f.setAccessible(true);
+            return (NodeStore) f.get(oak);
+        } catch (Exception e) {
+            throw new RuntimeException(e);
+        }
+    }
+
+    private class PropertyIndexInitializer implements RepositoryInitializer {
+
+        @Override
+        public void initialize(@NotNull NodeBuilder builder) {
+            NodeBuilder oakIndex = IndexUtils.getOrCreateOakIndex(builder);
+            addPropIndexDefn(oakIndex, indexedPropName);
+            for (int i = 0; i < numOfIndexes - 1; i++) {
+                addPropIndexDefn(oakIndex, indexedPropName + i);
+            }
+        }
+
+        private void addPropIndexDefn(NodeBuilder parent, String propName){
+            try {
+                NodeBuilder idx = IndexUtils.createIndexDefinition(parent, propName, false,
+                        singleton(propName), null, "property", null);
+                if ( propName.equals(indexedPropName)) {
+                    idx.setProperty("tags", singletonList("fooIndex"), Type.STRINGS);
+                }
+            } catch (RepositoryException e) {
+                throw new RuntimeException(e);
+            }
+
+        }
+    }
+
+    private class LuceneIndexInitializer implements RepositoryInitializer {
+        @Override
+        public void initialize(@NotNull NodeBuilder builder) {
+            NodeBuilder oakIndex = IndexUtils.getOrCreateOakIndex(builder);
+
+            IndexDefinitionBuilder defnBuilder = new IndexDefinitionBuilder();
+            defnBuilder.evaluatePathRestrictions();
+            defnBuilder.async("async", indexingMode, "async");
+            PropertyRule pr = defnBuilder.indexRule("nt:base").property(indexedPropName).propertyIndex();
+            if (syncIndexing) {
+                pr.sync();
+            }
+            if (useOakCodec) {
+                defnBuilder.codec("oakCodec");
+            }
+
+            for (int i = 0; i < numOfIndexes - 1; i++) {
+                defnBuilder.indexRule("nt:base").property(indexedPropName + i).propertyIndex();
+            }
+
+            oakIndex.setChildNode(indexedPropName, defnBuilder.build());
+            oakIndex.child(indexedPropName).setProperty("tags", singletonList("fooIndex"), Type.STRINGS);
+        }
+    }
+
+    private class LuceneFullTextInitializer implements RepositoryInitializer {
+        @Override
+        public void initialize(@NotNull NodeBuilder builder) {
+            NodeBuilder oakIndex = IndexUtils.getOrCreateOakIndex(builder);
+
+            IndexDefinitionBuilder defnBuilder = new IndexDefinitionBuilder();
+            defnBuilder.async("async", "async");
+            defnBuilder.codec("Lucene46");
+            defnBuilder.indexRule("nt:base")
+                    .property(FulltextIndexConstants.REGEX_ALL_PROPS, true)
+                    .nodeScopeIndex();
+            oakIndex.setChildNode("globalIndex", defnBuilder.build());
+        }
+    }
+
+    private class NodeTypeIndexFixerInitializer implements RepositoryInitializer {
+
+        @Override
+        public void initialize(@NotNull NodeBuilder builder) {
+            //Due to OAK-1150 currently all nodes get indexed
+            //With explicit list on those nodes would be indexed
+            NodeBuilder nodetype = builder.getChildNode("oak:index").getChildNode("nodetype");
+            if (nodetype.exists()) {
+                List<String> nodetypes = Lists.newArrayList();
+                if (nodetype.hasProperty(DECLARING_NODE_TYPES)){
+                    nodetypes = Lists.newArrayList(nodetype.getProperty(DECLARING_NODE_TYPES).getValue(Type.STRINGS));
+                }
+
+                if (nodetypes.isEmpty()) {
+                    nodetypes.add(INDEX_DEFINITIONS_NODE_TYPE);
+                    nodetypes.add("rep:Authorizable");
+                    nodetype.setProperty(DECLARING_NODE_TYPES, nodetypes, Type.NAMES);
+                    nodetype.setProperty(IndexConstants.REINDEX_PROPERTY_NAME, true);
+                }
+            }
+
+            //Disable counter index to disable traversal
+            NodeBuilder counter = builder.getChildNode("oak:index").getChildNode("counter");
+            if (counter.exists()) {
+                counter.setProperty("type", "disabled");
+            }
+        }
+    }
+
+    private class Searcher implements Runnable {
+        final Session session = loginWriter();
+        int resultSize = 0;
+        @Override
+        public void run() {
+            try{
+                run0();
+            } catch (RepositoryException e) {
+                throw new RuntimeException(e);
+            }
+        }
+
+        private void run0() throws RepositoryException {
+            session.refresh(false);
+            QueryManager qm = session.getWorkspace().getQueryManager();
+            Query q = qm.createQuery("select * from [nt:base] where [" + indexedPropName + "] = $status " +
+                    "option(index tag fooIndex)", Query.JCR_SQL2);
+            q.bindValue("status", session.getValueFactory().createValue(randomStatus()));
+            QueryResult result = q.execute();
+
+            //With property index at time traversing index wins (somehow reporting lower cost)
+            //and that leads to warning. So limit the iterator size
+            resultSize += Iterators.size(Iterators.limit(result.getNodes(), 500));
+        }
+    }
+
+    private class Mutator implements Runnable {
+        final Session session = loginWriter();
+        int mutationCount = 0;
+        @Override
+        public void run() {
+            try{
+                run0();
+            } catch (RepositoryException e) {
+                throw new RuntimeException(e);
+            }
+        }
+
+        private void run0() throws RepositoryException {
+            TestContext ctx = contexts.get(random.nextInt(contexts.size()));
+            String path = ctx.paths.peek();
+            session.refresh(false);
+            if (path != null){
+                Node node = session.getNode(path);
+                if(node.hasProperty(indexedPropName)){
+                    String value = node.getProperty(indexedPropName).getString();
+                    String newValue = Status.valueOf(value).next().name();
+                    node.setProperty(indexedPropName, newValue);
+                    session.save();
+                    mutationCount++;
+                }
+            }
+        }
+    }
+}
diff --git oak-benchmarks-lucene/src/main/java/org/apache/jackrabbit/oak/benchmark/LuceneBenchmarkRunner.java oak-benchmarks-lucene/src/main/java/org/apache/jackrabbit/oak/benchmark/LuceneBenchmarkRunner.java
new file mode 100644
index 0000000..f783bb9
--- /dev/null
+++ oak-benchmarks-lucene/src/main/java/org/apache/jackrabbit/oak/benchmark/LuceneBenchmarkRunner.java
@@ -0,0 +1,51 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.jackrabbit.oak.benchmark;
+
+
+import org.apache.jackrabbit.oak.stats.StatisticsProvider;
+
+import java.util.ArrayList;
+import java.util.Arrays;
+
+public class LuceneBenchmarkRunner extends BenchmarkRunner {
+
+    public static void main(String[] args) throws Exception {
+        statsProvider = options.has(benchmarkOptions.getMetrics()) ? getStatsProvider() : StatisticsProvider.NOOP;
+        initOptionSet(args);
+        BenchmarkRunner.addToBenchMarkList(
+                Arrays.asList(
+                        new LuceneFullTextSearchTest(
+                                benchmarkOptions.getWikipedia().value(options),
+                                benchmarkOptions.getFlatStructure().value(options),
+                                benchmarkOptions.getReport().value(options),
+                                benchmarkOptions.getWithStorage().value(options)),
+                        new LucenePropertyFullTextTest(
+                                benchmarkOptions.getWikipedia().value(options),
+                                benchmarkOptions.getFlatStructure().value(options),
+                                benchmarkOptions.getReport().value(options), benchmarkOptions.getWithStorage().value(options)),
+                        new LucenePropertyFTSeparated(
+                                benchmarkOptions.getWikipedia().value(options),
+                                benchmarkOptions.getFlatStructure().value(options),
+                                benchmarkOptions.getReport().value(options), benchmarkOptions.getWithStorage().value(options)),
+                        new HybridIndexTest(benchmarkOptions.getBase().value(options), statsProvider)
+                )
+        );
+
+        BenchmarkRunner.main(args);
+    }
+}
diff --git oak-benchmarks-lucene/src/main/java/org/apache/jackrabbit/oak/benchmark/LuceneFullTextSearchTest.java oak-benchmarks-lucene/src/main/java/org/apache/jackrabbit/oak/benchmark/LuceneFullTextSearchTest.java
new file mode 100644
index 0000000..bacfb77
--- /dev/null
+++ oak-benchmarks-lucene/src/main/java/org/apache/jackrabbit/oak/benchmark/LuceneFullTextSearchTest.java
@@ -0,0 +1,76 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+package org.apache.jackrabbit.oak.benchmark;
+
+
+import org.apache.jackrabbit.oak.Oak;
+import org.apache.jackrabbit.oak.fixture.JcrCreator;
+import org.apache.jackrabbit.oak.fixture.OakRepositoryFixture;
+import org.apache.jackrabbit.oak.fixture.RepositoryFixture;
+import org.apache.jackrabbit.oak.jcr.Jcr;
+import org.apache.jackrabbit.oak.plugins.index.lucene.IndexCopier;
+import org.apache.jackrabbit.oak.plugins.index.lucene.LuceneIndexEditorProvider;
+import org.apache.jackrabbit.oak.plugins.index.lucene.LuceneIndexProvider;
+import org.apache.jackrabbit.oak.plugins.index.lucene.util.LuceneInitializerHelper;
+import org.apache.jackrabbit.oak.spi.commit.Observer;
+import org.apache.jackrabbit.oak.spi.query.QueryIndexProvider;
+
+import javax.jcr.Repository;
+import java.io.File;
+import java.io.IOException;
+
+public class LuceneFullTextSearchTest extends FullTextSearchTest {
+
+    private final boolean disableCopyOnRead = Boolean.getBoolean("disableCopyOnRead");
+
+    public LuceneFullTextSearchTest(File dump, boolean flat, boolean doReport, Boolean storageEnabled) {
+        super(dump, flat, doReport, storageEnabled);
+    }
+
+
+    @Override
+    protected Repository[] createRepository(RepositoryFixture fixture) throws Exception {
+        if (fixture instanceof OakRepositoryFixture) {
+            return ((OakRepositoryFixture) fixture).setUpCluster(1, new JcrCreator() {
+                @Override
+                public Jcr customize(Oak oak) {
+                    LuceneIndexProvider provider = createLuceneIndexProvider();
+                    oak.with((QueryIndexProvider) provider)
+                            .with((Observer) provider)
+                            .with(new LuceneIndexEditorProvider())
+                            .with(new LuceneInitializerHelper("luceneGlobal", storageEnabled));
+                    return new Jcr(oak);
+                }
+            });
+        }
+        return super.createRepository(fixture);
+    }
+
+    private LuceneIndexProvider createLuceneIndexProvider() {
+        if (!disableCopyOnRead) {
+            try {
+                IndexCopier copier = new IndexCopier(executorService, indexCopierDir, true);
+                return new LuceneIndexProvider(copier);
+            } catch (IOException e) {
+                throw new RuntimeException(e);
+            }
+        }
+        return new LuceneIndexProvider();
+    }
+}
diff --git oak-benchmarks-lucene/src/main/java/org/apache/jackrabbit/oak/benchmark/LucenePropertyFTSeparated.java oak-benchmarks-lucene/src/main/java/org/apache/jackrabbit/oak/benchmark/LucenePropertyFTSeparated.java
new file mode 100644
index 0000000..630d4fe
--- /dev/null
+++ oak-benchmarks-lucene/src/main/java/org/apache/jackrabbit/oak/benchmark/LucenePropertyFTSeparated.java
@@ -0,0 +1,74 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.jackrabbit.oak.benchmark;
+
+import static com.google.common.collect.ImmutableSet.of;
+
+import java.io.File;
+
+import javax.jcr.Repository;
+
+import org.apache.jackrabbit.oak.Oak;
+import org.apache.jackrabbit.oak.fixture.JcrCreator;
+import org.apache.jackrabbit.oak.fixture.OakRepositoryFixture;
+import org.apache.jackrabbit.oak.fixture.RepositoryFixture;
+import org.apache.jackrabbit.oak.jcr.Jcr;
+import org.apache.jackrabbit.oak.plugins.index.lucene.LuceneIndexEditorProvider;
+import org.apache.jackrabbit.oak.plugins.index.lucene.LuceneIndexProvider;
+import org.apache.jackrabbit.oak.plugins.index.lucene.util.LuceneInitializerHelper;
+import org.apache.jackrabbit.oak.spi.commit.Observer;
+import org.apache.jackrabbit.oak.spi.query.QueryIndexProvider;
+
+/**
+ * same as {@link LucenePropertyFullTextTest} but will initialise a repository where the global
+ * full-text runs on a separate thread from lucene property.
+ */
+public class LucenePropertyFTSeparated extends LucenePropertyFullTextTest {
+
+    public LucenePropertyFTSeparated(final File dump, 
+                                     final boolean flat, 
+                                     final boolean doReport,
+                                     final Boolean storageEnabled) {
+        super(dump, flat, doReport, storageEnabled);
+        currentTest = this.getClass().getSimpleName();
+    }
+
+    @Override
+    protected Repository[] createRepository(RepositoryFixture fixture) throws Exception {
+        if (fixture instanceof OakRepositoryFixture) {
+            currentFixture = fixture.toString();
+            return ((OakRepositoryFixture) fixture).setUpCluster(1, new JcrCreator() {
+                @Override
+                public Jcr customize(Oak oak) {
+                    LuceneIndexProvider provider = new LuceneIndexProvider();
+                    oak.with((QueryIndexProvider) provider)
+                       .with((Observer) provider)
+                       .with(new LuceneIndexEditorProvider())
+                        .with(
+                            (new LuceneInitializerHelper("luceneGlobal", storageEnabled))
+                                .async("async-slow"))
+                       // the WikipediaImporter set a property `title`
+                       .with(new LucenePropertyInitialiser("luceneTitle", of("title")))
+                       .withAsyncIndexing("async", 5)
+                       .withAsyncIndexing("async-slow", 5);
+                    return new Jcr(oak);
+                }
+            });
+        }
+        return super.createRepository(fixture);
+    }
+}
diff --git oak-benchmarks-lucene/src/main/java/org/apache/jackrabbit/oak/benchmark/LucenePropertyFullTextTest.java oak-benchmarks-lucene/src/main/java/org/apache/jackrabbit/oak/benchmark/LucenePropertyFullTextTest.java
new file mode 100644
index 0000000..8c4b921
--- /dev/null
+++ oak-benchmarks-lucene/src/main/java/org/apache/jackrabbit/oak/benchmark/LucenePropertyFullTextTest.java
@@ -0,0 +1,295 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.jackrabbit.oak.benchmark;
+
+import static com.google.common.base.Preconditions.checkNotNull;
+import static com.google.common.collect.ImmutableSet.of;
+import static org.apache.jackrabbit.oak.api.Type.BOOLEAN;
+import static org.apache.jackrabbit.oak.api.Type.LONG;
+import static org.apache.jackrabbit.oak.api.Type.NAME;
+import static org.apache.jackrabbit.oak.api.Type.STRING;
+import static org.apache.jackrabbit.oak.plugins.index.IndexConstants.ASYNC_PROPERTY_NAME;
+import static org.apache.jackrabbit.oak.plugins.index.IndexConstants.INDEX_DEFINITIONS_NAME;
+import static org.apache.jackrabbit.oak.plugins.index.IndexConstants.INDEX_DEFINITIONS_NODE_TYPE;
+import static org.apache.jackrabbit.oak.plugins.index.IndexConstants.REINDEX_PROPERTY_NAME;
+import static org.apache.jackrabbit.oak.plugins.index.IndexConstants.TYPE_PROPERTY_NAME;
+import static org.apache.jackrabbit.oak.plugins.index.lucene.LuceneIndexConstants.TYPE_LUCENE;
+import static org.apache.jackrabbit.oak.plugins.index.search.FulltextIndexConstants.COMPAT_MODE;
+import static org.apache.jackrabbit.oak.plugins.index.search.FulltextIndexConstants.INDEX_RULES;
+import static org.apache.jackrabbit.oak.plugins.index.search.FulltextIndexConstants.PROP_NAME;
+import static org.apache.jackrabbit.oak.plugins.index.search.FulltextIndexConstants.PROP_NODE;
+import static org.apache.jackrabbit.oak.plugins.index.search.FulltextIndexConstants.PROP_PROPERTY_INDEX;
+
+import java.io.File;
+import java.util.Set;
+import java.util.concurrent.TimeUnit;
+import java.util.concurrent.atomic.AtomicReference;
+
+import javax.jcr.Repository;
+import javax.jcr.RepositoryException;
+import javax.jcr.Session;
+import javax.jcr.ValueFactory;
+import javax.jcr.query.Query;
+import javax.jcr.query.QueryManager;
+import javax.jcr.query.RowIterator;
+
+import org.apache.jackrabbit.oak.Oak;
+import org.apache.jackrabbit.oak.api.Tree;
+import org.apache.jackrabbit.oak.benchmark.wikipedia.WikipediaImport;
+import org.apache.jackrabbit.oak.commons.PathUtils;
+import org.apache.jackrabbit.oak.fixture.JcrCreator;
+import org.apache.jackrabbit.oak.fixture.OakRepositoryFixture;
+import org.apache.jackrabbit.oak.fixture.RepositoryFixture;
+import org.apache.jackrabbit.oak.jcr.Jcr;
+import org.apache.jackrabbit.oak.plugins.index.lucene.LuceneIndexEditorProvider;
+import org.apache.jackrabbit.oak.plugins.index.lucene.LuceneIndexProvider;
+import org.apache.jackrabbit.oak.plugins.index.lucene.util.LuceneInitializerHelper;
+import org.apache.jackrabbit.oak.plugins.tree.factories.TreeFactory;
+import org.apache.jackrabbit.oak.spi.commit.Observer;
+import org.apache.jackrabbit.oak.spi.lifecycle.RepositoryInitializer;
+import org.apache.jackrabbit.oak.spi.query.QueryIndexProvider;
+import org.apache.jackrabbit.oak.spi.state.NodeBuilder;
+import org.jetbrains.annotations.NotNull;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+/**
+ * <p>
+ * Perform a benchmark on how long it takes for an ingested item to be available in a Lucene
+ * Property index when indexed in conjunction with a Global full-text lucene (same thread). It makes
+ * use of the {@link WikipediaImport} to use a Wikipedia dump for content injestion.
+ * </p>
+ * <p>
+ * Suggested dump: 
+ * <a href="https://dumps.wikimedia.org/enwiki/20150403/enwiki-20150403-pages-articles.xml.bz2">https://dumps.wikimedia.org/enwiki/20150403/enwiki-20150403-pages-articles.xml.bz2</a>
+ * </p>
+ * <p>
+ * Usage example:
+ * </p>
+ * 
+ * <pre>
+ * java -Druntime=900 -Dlogback.configurationFile=logback-benchmark.xml \
+ *      -jar ~/.m2/repository/org/apache/jackrabbit/oak-run/1.4-SNAPSHOT/oak-run-1.4-SNAPSHOT.jar \
+ *      benchmark --wikipedia enwiki-20150403-pages-articles.xml.bz2 \
+ *      --base ~/tmp/oak/ LucenePropertyFullTextTest Oak-Tar Oak-Mongo
+ * </pre>
+ * <p>
+ * it will run the benchmark for 15 minutes against TarNS and MongoNS.
+ * </p>
+ */
+public class LucenePropertyFullTextTest extends AbstractTest<LucenePropertyFullTextTest.TestContext> {
+    private static final Logger LOG = LoggerFactory.getLogger(LucenePropertyFullTextTest.class);
+    private WikipediaImport importer;    
+    private Thread asyncImporter;
+    private boolean benchmarkCompleted, importerCompleted;
+    Boolean storageEnabled;
+    String currentFixture, currentTest;
+    
+    /**
+     * context used across the tests
+     */
+    class TestContext {
+        final Session session = loginWriter();
+        final String title;
+        
+        public TestContext(@NotNull final String title) {
+            this.title = checkNotNull(title);
+        }
+    }
+
+    /**
+     * helper class to initialise the Lucene Property index definition
+     */
+    static class LucenePropertyInitialiser implements RepositoryInitializer {
+        private String name;
+        private Set<String> properties;
+        
+        public LucenePropertyInitialiser(@NotNull final String name, 
+                                         @NotNull final Set<String> properties) {
+            this.name = checkNotNull(name);
+            this.properties = checkNotNull(properties);
+        }
+                
+        private boolean isAlreadyThere(@NotNull final NodeBuilder root) {
+            return checkNotNull(root).hasChildNode(INDEX_DEFINITIONS_NAME) &&
+                root.getChildNode(INDEX_DEFINITIONS_NAME).hasChildNode(name);
+        }
+        
+        @Override
+        public void initialize(final NodeBuilder builder) {
+            if (!isAlreadyThere(builder)) {
+                Tree t = TreeFactory.createTree(builder.child(INDEX_DEFINITIONS_NAME));
+                t = t.addChild(name);
+                t.setProperty("jcr:primaryType", INDEX_DEFINITIONS_NODE_TYPE, NAME);
+                t.setProperty(COMPAT_MODE, 2L, LONG);
+                t.setProperty(TYPE_PROPERTY_NAME, TYPE_LUCENE, STRING);
+                t.setProperty(ASYNC_PROPERTY_NAME, "async", STRING);
+                t.setProperty(REINDEX_PROPERTY_NAME, true);
+                
+                t = t.addChild(INDEX_RULES);
+                t.setOrderableChildren(true);
+                t.setProperty("jcr:primaryType", "nt:unstructured", NAME);
+                
+                t = t.addChild("nt:base");
+                
+                Tree propnode = t.addChild(PROP_NODE);
+                propnode.setOrderableChildren(true);
+                propnode.setProperty("jcr:primaryType", "nt:unstructured", NAME);
+                
+                for (String p : properties) {
+                    Tree t1 = propnode.addChild(PathUtils.getName(p));
+                    t1.setProperty(PROP_PROPERTY_INDEX, true, BOOLEAN);
+                    t1.setProperty(PROP_NAME, p);
+                }
+            }
+        }
+    }
+    
+    /**
+     * reference to the last added title. Used for looking up with queries.
+     */
+    private AtomicReference<String> lastTitle = new AtomicReference<String>();
+    
+    public LucenePropertyFullTextTest(final File dump, 
+                                      final boolean flat, 
+                                      final boolean doReport, 
+                                      final Boolean storageEnabled) {
+        this.importer = new WikipediaImport(dump, flat, doReport) {
+
+            @Override
+            protected void pageAdded(String title, String text) {
+                LOG.trace("Setting title: {}", title);
+                lastTitle.set(title);
+            }
+        };
+        this.storageEnabled = storageEnabled;
+        this.currentTest = this.getClass().getSimpleName();
+    }
+
+    @Override
+    protected Repository[] createRepository(RepositoryFixture fixture) throws Exception {
+        if (fixture instanceof OakRepositoryFixture) {
+            currentFixture = fixture.toString();
+            return ((OakRepositoryFixture) fixture).setUpCluster(1, new JcrCreator() {
+                @Override
+                public Jcr customize(Oak oak) {
+                    LuceneIndexProvider provider = new LuceneIndexProvider();
+                    oak.with((QueryIndexProvider) provider)
+                       .with((Observer) provider)
+                       .with(new LuceneIndexEditorProvider())
+                       .with((new LuceneInitializerHelper("luceneGlobal", storageEnabled)).async())
+                       // the WikipediaImporter set a property `title`
+                       .with(new LucenePropertyInitialiser("luceneTitle", of("title")))
+                       .withAsyncIndexing("async", 5);
+                    return new Jcr(oak);
+                }
+            });
+        }
+        return super.createRepository(fixture);
+    }
+
+    @Override
+    protected void beforeSuite() throws Exception {
+        LOG.debug("beforeSuite() - {} - {}", currentFixture, currentTest);
+        benchmarkCompleted = false;
+        importerCompleted = false;
+        asyncImporter = new Thread(new Runnable() {
+            @Override
+            public void run() {
+                try {
+                    importer.importWikipedia(loginWriter());
+                } catch (Exception e) {
+                    LOG.error("Error while importing the dump. Trying to halt everything.", e);
+                    importerCompleted = true;
+                } finally {
+                    if (!benchmarkCompleted) {
+                        importerCompleted = true;
+                        issueHaltRequest("Wikipedia import completed.");
+                    }
+                }
+            }
+        });
+        asyncImporter.start();
+
+        // allowing the async index to catch up. 
+        TimeUnit.SECONDS.sleep(10);
+    }
+
+    @Override
+    protected void afterSuite() throws Exception {
+        LOG.debug("afterSuite() - {} - {}", currentFixture, currentTest);
+        asyncImporter.join();
+    }
+    
+    @Override
+    protected void runTest() throws Exception {
+        if (lastTitle.get() == null) {
+            return;
+        }
+        runTest(new TestContext(lastTitle.get()));
+    }
+
+    @Override
+    protected void runTest(final TestContext ec) throws Exception {
+        if (importerCompleted) {
+            return;
+        }
+        final long maxWait = TimeUnit.MINUTES.toMillis(5);
+        final long waitUnit = 50;
+        long sleptSoFar = 0;
+        
+        while (!performQuery(ec) && sleptSoFar < maxWait) {
+            LOG.trace("title '{}' not found. Waiting and retry. sleptSoFar: {}ms", ec.title,
+                sleptSoFar);
+            sleptSoFar += waitUnit;
+            TimeUnit.MILLISECONDS.sleep(waitUnit);
+        }
+        
+        if (sleptSoFar < maxWait) {
+            // means we exited the loop as we found it.
+            LOG.info("{} - {} - title '{}' found with a wait/try of {}ms", currentFixture,
+                currentTest, ec.title, sleptSoFar);
+        } else {
+            LOG.warn("{} - {} - title '{}' timed out with a way/try of {}ms.", currentFixture,
+                currentTest, ec.title, sleptSoFar);
+        }
+    }
+    
+    private boolean performQuery(@NotNull final TestContext ec) throws RepositoryException {
+        QueryManager qm = ec.session.getWorkspace().getQueryManager();
+        ValueFactory vf = ec.session.getValueFactory();
+        Query q = qm.createQuery("SELECT * FROM [nt:base] WHERE [title] = $title", Query.JCR_SQL2);
+        q.bindValue("title", vf.createValue(ec.title));
+        LOG.trace("statement: {} - title: {}", q.getStatement(), ec.title);        
+        RowIterator rows = q.execute().getRows();
+        if (rows.hasNext()) {
+            rows.nextRow().getPath();
+            return true;
+        } else {
+            return false;
+        }
+    }
+
+    @Override
+    protected void issueHaltChildThreads() {
+        if (!importerCompleted) {
+            LOG.info("benchmark completed. Issuing an halt for the importer");
+            benchmarkCompleted = true;
+            this.importer.issueHaltImport();
+        }
+    }
+}
diff --git oak-benchmarks-lucene/src/main/java/org/apache/jackrabbit/oak/benchmark/util/OakLuceneIndexUtils.java oak-benchmarks-lucene/src/main/java/org/apache/jackrabbit/oak/benchmark/util/OakLuceneIndexUtils.java
new file mode 100644
index 0000000..ad8d229
--- /dev/null
+++ oak-benchmarks-lucene/src/main/java/org/apache/jackrabbit/oak/benchmark/util/OakLuceneIndexUtils.java
@@ -0,0 +1,106 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.jackrabbit.oak.benchmark.util;
+
+import com.google.common.base.Strings;
+import com.google.common.collect.Lists;
+import org.apache.jackrabbit.commons.JcrUtils;
+import org.apache.jackrabbit.oak.plugins.index.IndexConstants;
+import org.apache.jackrabbit.oak.plugins.index.lucene.LuceneIndexConstants;
+import org.apache.jackrabbit.oak.plugins.index.search.FulltextIndexConstants;
+import org.apache.jackrabbit.oak.spi.nodetype.NodeTypeConstants;
+
+import javax.jcr.Node;
+import javax.jcr.PropertyType;
+import javax.jcr.RepositoryException;
+import javax.jcr.Session;
+import java.util.List;
+import java.util.Map;
+
+public class OakLuceneIndexUtils {
+
+    /**
+     * Helper method to create or update a lucene property index definition.
+     *
+     * @param session the session
+     * @param indexDefinitionName the name of the node for the index definition
+     * @param propertyNames the list of properties to index
+     * @param type the types of the properties in order of the properties
+     * @param orderedPropsMap the ordered props and its properties
+     * @param persistencePath the path if the persistence=file (default is repository)
+     * @return the node just created
+     * @throws RepositoryException the repository exception
+     */
+    public static Node luceneIndexDefinition(Session session, String indexDefinitionName,
+                                             String async, String[] propertyNames, String[] type,
+                                             Map<String, Map<String, String>> orderedPropsMap, String persistencePath)
+            throws RepositoryException {
+
+        Node root = session.getRootNode();
+        Node indexDefRoot = JcrUtils.getOrAddNode(root, IndexConstants.INDEX_DEFINITIONS_NAME,
+                NodeTypeConstants.NT_UNSTRUCTURED);
+
+        Node indexDef = JcrUtils.getOrAddNode(indexDefRoot, indexDefinitionName,
+                IndexConstants.INDEX_DEFINITIONS_NODE_TYPE);
+
+        indexDef.setProperty(IndexConstants.TYPE_PROPERTY_NAME, LuceneIndexConstants.TYPE_LUCENE);
+        indexDef.setProperty(FulltextIndexConstants.FULL_TEXT_ENABLED, false);
+        if (async != null) {
+            indexDef.setProperty(IndexConstants.ASYNC_PROPERTY_NAME, async);
+        }
+        // Set indexed property names
+        indexDef.setProperty(FulltextIndexConstants.INCLUDE_PROPERTY_NAMES, propertyNames,
+                PropertyType.NAME);
+
+        Node propsNode = JcrUtils.getOrAddNode(indexDef, FulltextIndexConstants.PROP_NODE);
+        for (int i = 0; i < propertyNames.length; i++) {
+            Node propNode =
+                    JcrUtils.getOrAddNode(propsNode, propertyNames[i], NodeTypeConstants.NT_OAK_UNSTRUCTURED);
+            propNode.setProperty(FulltextIndexConstants.PROP_TYPE, type[i]);
+        }
+
+        // Set ordered property names
+        if ((orderedPropsMap != null) && !orderedPropsMap.isEmpty()) {
+            List<String> orderedProps = Lists.newArrayList();
+            for (Map.Entry<String, Map<String, String>> orderedPropEntry : orderedPropsMap
+                    .entrySet()) {
+                Node propNode = JcrUtils.getOrAddNode(propsNode, orderedPropEntry.getKey(),
+                        NodeTypeConstants.NT_OAK_UNSTRUCTURED);
+                propNode.setProperty(FulltextIndexConstants.PROP_TYPE,
+                        orderedPropEntry.getValue().get(FulltextIndexConstants.PROP_TYPE));
+                orderedProps.add(orderedPropEntry.getKey());
+            }
+            if (!orderedProps.isEmpty()) {
+                indexDef.setProperty(FulltextIndexConstants.ORDERED_PROP_NAMES,
+                        orderedProps.toArray(new String[orderedProps.size()]),
+                        PropertyType.NAME);
+            }
+        }
+
+        // Set file persistence if specified
+        if (!Strings.isNullOrEmpty(persistencePath)) {
+            indexDef.setProperty(FulltextIndexConstants.PERSISTENCE_NAME,
+                    FulltextIndexConstants.PERSISTENCE_FILE);
+            indexDef.setProperty(FulltextIndexConstants.PERSISTENCE_PATH,
+                    persistencePath);
+        }
+        session.save();
+
+        return indexDef;
+    }
+
+}
diff --git oak-benchmarks-lucene/src/main/java/org/apache/jackrabbit/oak/run/BenchMarkLuceneCommand.java oak-benchmarks-lucene/src/main/java/org/apache/jackrabbit/oak/run/BenchMarkLuceneCommand.java
new file mode 100644
index 0000000..7906415
--- /dev/null
+++ oak-benchmarks-lucene/src/main/java/org/apache/jackrabbit/oak/run/BenchMarkLuceneCommand.java
@@ -0,0 +1,29 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.jackrabbit.oak.run;
+
+
+import org.apache.jackrabbit.oak.benchmark.LuceneBenchmarkRunner;
+import org.apache.jackrabbit.oak.run.commons.Command;
+
+public class BenchmarkLuceneCommand implements Command {
+
+    @Override
+    public void execute(String... args) throws Exception {
+        LuceneBenchmarkRunner.main(args);
+    }
+}
diff --git oak-benchmarks-lucene/src/main/java/org/apache/jackrabbit/oak/run/LuceneMain.java oak-benchmarks-lucene/src/main/java/org/apache/jackrabbit/oak/run/LuceneMain.java
new file mode 100644
index 0000000..257a880
--- /dev/null
+++ oak-benchmarks-lucene/src/main/java/org/apache/jackrabbit/oak/run/LuceneMain.java
@@ -0,0 +1,58 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.jackrabbit.oak.run;
+
+
+import com.google.common.collect.ImmutableMap;
+import org.apache.jackrabbit.oak.run.commons.Command;
+import org.apache.jackrabbit.oak.run.commons.Modes;
+import org.apache.jackrabbit.oak.run.commons.Utils;
+
+import static java.util.Arrays.copyOfRange;
+
+public class LuceneMain {
+
+    private static final Modes MODES = new Modes(ImmutableMap.<String, Command>of(
+            "benchmark", new BenchmarkLuceneCommand(),
+            "scalability", new ScalabilityCommand()
+    ));
+
+    private LuceneMain() {
+        // Prevent instantiation.
+    }
+
+    public static void main(String[] args) throws Exception {
+
+        Utils.printProductInfo(
+                args,
+                Main.class.getResourceAsStream("/META-INF/maven/org.apache.jackrabbit/oak-benchmarks-lucene/pom.properties")
+        );
+
+        Command c = MODES.getCommand("benchmark");
+        if (args.length > 0) {
+            c = MODES.getCommand(args[0]);
+
+            if (c == null) {
+                c = MODES.getCommand("benchmark");
+            }
+
+            args = copyOfRange(args, 1, args.length);
+        }
+
+        c.execute(args);
+    }
+}
diff --git oak-benchmarks-lucene/src/main/java/org/apache/jackrabbit/oak/run/LuceneScalabilityCommand.java oak-benchmarks-lucene/src/main/java/org/apache/jackrabbit/oak/run/LuceneScalabilityCommand.java
new file mode 100644
index 0000000..039ab56
--- /dev/null
+++ oak-benchmarks-lucene/src/main/java/org/apache/jackrabbit/oak/run/LuceneScalabilityCommand.java
@@ -0,0 +1,28 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.jackrabbit.oak.run;
+
+
+import org.apache.jackrabbit.oak.scalability.LuceneScalabilityRunner;
+
+public class LuceneScalabilityCommand extends ScalabilityCommand {
+
+    @Override
+    public void execute(String... args) throws Exception {
+        LuceneScalabilityRunner.main(args);
+    }
+}
diff --git oak-benchmarks-lucene/src/main/java/org/apache/jackrabbit/oak/scalability/LuceneScalabilityRunner.java oak-benchmarks-lucene/src/main/java/org/apache/jackrabbit/oak/scalability/LuceneScalabilityRunner.java
new file mode 100644
index 0000000..ed85b4e
--- /dev/null
+++ oak-benchmarks-lucene/src/main/java/org/apache/jackrabbit/oak/scalability/LuceneScalabilityRunner.java
@@ -0,0 +1,88 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+package org.apache.jackrabbit.oak.scalability;
+
+import org.apache.jackrabbit.oak.benchmark.util.Date;
+import org.apache.jackrabbit.oak.scalability.benchmarks.search.AggregateNodeSearcher;
+import org.apache.jackrabbit.oak.scalability.benchmarks.search.ConcurrentReader;
+import org.apache.jackrabbit.oak.scalability.benchmarks.search.ConcurrentWriter;
+import org.apache.jackrabbit.oak.scalability.benchmarks.search.FacetSearcher;
+import org.apache.jackrabbit.oak.scalability.benchmarks.search.FormatSearcher;
+import org.apache.jackrabbit.oak.scalability.benchmarks.search.FullTextSearcher;
+import org.apache.jackrabbit.oak.scalability.benchmarks.search.LastModifiedSearcher;
+import org.apache.jackrabbit.oak.scalability.benchmarks.search.MultiFilterOrderByKeysetPageSearcher;
+import org.apache.jackrabbit.oak.scalability.benchmarks.search.MultiFilterOrderByOffsetPageSearcher;
+import org.apache.jackrabbit.oak.scalability.benchmarks.search.MultiFilterOrderBySearcher;
+import org.apache.jackrabbit.oak.scalability.benchmarks.search.MultiFilterSplitOrderByKeysetPageSearcher;
+import org.apache.jackrabbit.oak.scalability.benchmarks.search.MultiFilterSplitOrderByOffsetPageSearcher;
+import org.apache.jackrabbit.oak.scalability.benchmarks.search.MultiFilterSplitOrderBySearcher;
+import org.apache.jackrabbit.oak.scalability.benchmarks.search.NodeTypeSearcher;
+import org.apache.jackrabbit.oak.scalability.benchmarks.search.OrderByDate;
+import org.apache.jackrabbit.oak.scalability.benchmarks.search.OrderByKeysetPageSearcher;
+import org.apache.jackrabbit.oak.scalability.benchmarks.search.OrderByOffsetPageSearcher;
+import org.apache.jackrabbit.oak.scalability.benchmarks.search.OrderBySearcher;
+import org.apache.jackrabbit.oak.scalability.benchmarks.search.SplitOrderByKeysetPageSearcher;
+import org.apache.jackrabbit.oak.scalability.benchmarks.search.SplitOrderByOffsetPageSearcher;
+import org.apache.jackrabbit.oak.scalability.benchmarks.search.SplitOrderBySearcher;
+import org.apache.jackrabbit.oak.scalability.suites.ScalabilityBlobSearchSuite;
+import org.apache.jackrabbit.oak.scalability.suites.ScalabilityNodeRelationshipSuite;
+import org.apache.jackrabbit.oak.scalability.suites.ScalabilityNodeSuite;
+
+import java.util.Arrays;
+
+public class LuceneScalabilityRunner extends ScalabilityRunner {
+
+    public static void main(String[] args) throws Exception {
+        initOptionSet(args);
+        ScalabilityRunner.addToScalabilitySuiteList(
+                Arrays.asList(
+                        new ScalabilityBlobSearchSuite(scalabilityOptions.getWithStorage().value(options))
+                                .addBenchmarks(new FullTextSearcher(),
+                                        new NodeTypeSearcher(),
+                                        new FormatSearcher(),
+                                        new FacetSearcher(),
+                                        new LastModifiedSearcher(Date.LAST_2_HRS),
+                                        new LastModifiedSearcher(Date.LAST_24_HRS),
+                                        new LastModifiedSearcher(Date.LAST_7_DAYS),
+                                        new LastModifiedSearcher(Date.LAST_MONTH),
+                                        new LastModifiedSearcher(Date.LAST_YEAR),
+                                        new OrderByDate()),
+                        new ScalabilityNodeSuite(scalabilityOptions.getWithStorage().value(options))
+                                .addBenchmarks(new OrderBySearcher(),
+                                        new SplitOrderBySearcher(),
+                                        new OrderByOffsetPageSearcher(),
+                                        new SplitOrderByOffsetPageSearcher(),
+                                        new OrderByKeysetPageSearcher(),
+                                        new SplitOrderByKeysetPageSearcher(),
+                                        new MultiFilterOrderBySearcher(),
+                                        new MultiFilterSplitOrderBySearcher(),
+                                        new MultiFilterOrderByOffsetPageSearcher(),
+                                        new MultiFilterSplitOrderByOffsetPageSearcher(),
+                                        new MultiFilterOrderByKeysetPageSearcher(),
+                                        new MultiFilterSplitOrderByKeysetPageSearcher(),
+                                        new ConcurrentReader(),
+                                        new ConcurrentWriter()),
+                        new ScalabilityNodeRelationshipSuite(scalabilityOptions.getWithStorage().value(options))
+                                .addBenchmarks(new AggregateNodeSearcher())
+                )
+        );
+
+    }
+
+}
diff --git oak-benchmarks-lucene/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/AggregateNodeSearcher.java oak-benchmarks-lucene/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/AggregateNodeSearcher.java
new file mode 100644
index 0000000..50d7d59
--- /dev/null
+++ oak-benchmarks-lucene/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/AggregateNodeSearcher.java
@@ -0,0 +1,116 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ *  or more contributor license agreements.  See the NOTICE file
+ *  distributed with this work for additional information
+ *  regarding copyright ownership.  The ASF licenses this file
+ *  to you under the Apache License, Version 2.0 (the
+ *  "License"); you may not use this file except in compliance
+ *  with the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ *  Unless required by applicable law or agreed to in writing,
+ *  software distributed under the License is distributed on an
+ *  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ *  KIND, either express or implied.  See the License for the
+ *  specific language governing permissions and limitations
+ *  under the License.
+ */
+
+package org.apache.jackrabbit.oak.scalability.benchmarks.search;
+
+import com.google.common.collect.Lists;
+
+import org.apache.jackrabbit.api.security.user.Authorizable;
+import org.jetbrains.annotations.NotNull;
+
+import javax.jcr.*;
+import javax.jcr.query.Query;
+import javax.jcr.query.QueryManager;
+
+import java.util.List;
+import java.util.Random;
+
+import org.apache.jackrabbit.oak.scalability.suites.ScalabilityNodeRelationshipSuite;
+import org.apache.jackrabbit.oak.scalability.suites.ScalabilityAbstractSuite.ExecutionContext;
+
+/**
+ * Retrieves search property by iterating over nodes and then executes search using the retrieved
+ * criteria.
+ */
+public class AggregateNodeSearcher extends SearchScalabilityBenchmark {
+    private static final String RELATIONSHIPS = "relationships";
+
+    /**
+     * Queries for nodes with property satisfying a set of properties and ordering by the latest.
+     *
+     * @param qm the query manager
+     * @param context the execution context
+     * @return the query object
+     * @throws RepositoryException
+     */
+    protected Query getQuery(@NotNull QueryManager qm,
+        ExecutionContext context) throws RepositoryException {
+        List<String> relationships = (List<String>) context.getMap().get(RELATIONSHIPS);
+        // /jcr:root//element(*, ActivityType)[((id = 1234 or id = '1354'))] order by jcr:created
+        // descending
+        StringBuilder statement = new StringBuilder("");
+        statement.append("/jcr:root")
+            .append("//element(*, ")
+            .append(
+                (String) context.getMap().get(ScalabilityNodeRelationshipSuite.CTX_ACT_NODE_TYPE_PROP))
+            .append(")");
+        statement.append("[((");
+
+        // adding all the possible mime-types in an OR fashion
+        for (String relationship : relationships) {
+            statement.append(ScalabilityNodeRelationshipSuite.SOURCE_ID).append(" = '")
+                .append(relationship).append("' or ");
+        }
+
+        // removing latest ' or '
+        statement.delete(statement.lastIndexOf(" or "), statement.length());
+
+        statement.append("))]");
+        // order by jcr:created descending
+        statement.append(" order by").append(" @").append(ScalabilityNodeRelationshipSuite.CREATED)
+            .append(" descending");
+
+        LOG.debug("{}", statement);
+
+        return qm.createQuery(statement.toString(), Query.XPATH);
+    }
+
+    @Override
+    public void execute(Repository repository, Credentials credentials,
+        ExecutionContext context) throws Exception {
+        Session session = repository.login(credentials);
+        QueryManager qm;
+        try {
+            List<Authorizable> users = (List<Authorizable>) context.getMap()
+                .get(ScalabilityNodeRelationshipSuite.CTX_USER);
+            Random rand = new Random(99);
+            Authorizable user = users.get(rand.nextInt(users.size()));
+            List<String> targets = getRelatedUsers(session, user);
+            context.getMap().put(RELATIONSHIPS, targets);
+            qm = session.getWorkspace().getQueryManager();
+            search(qm, context);
+            context.getMap().remove(RELATIONSHIPS);
+        } catch (RepositoryException e) {
+            e.printStackTrace();
+        }
+    }
+
+    private List<String> getRelatedUsers(Session session, Authorizable user)
+        throws RepositoryException {
+        List<String> targets = Lists.newArrayList();
+        Node relRootNode =
+            session.getNode(user.getPath() + "/" + ScalabilityNodeRelationshipSuite.RELATIONSHIPS);
+        NodeIterator children = relRootNode.getNodes();
+        while (children.hasNext()) {
+            Node node = children.nextNode();
+            targets.add(node.getProperty(ScalabilityNodeRelationshipSuite.TARGET_ID).getString());
+        }
+        return targets;
+    }
+}
diff --git oak-benchmarks-lucene/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/FacetSearcher.java oak-benchmarks-lucene/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/FacetSearcher.java
new file mode 100644
index 0000000..a23173e
--- /dev/null
+++ oak-benchmarks-lucene/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/FacetSearcher.java
@@ -0,0 +1,43 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+package org.apache.jackrabbit.oak.scalability.benchmarks.search;
+
+import javax.jcr.RepositoryException;
+import javax.jcr.query.Query;
+import javax.jcr.query.QueryManager;
+import org.apache.jackrabbit.oak.scalability.suites.ScalabilityAbstractSuite;
+import org.jetbrains.annotations.NotNull;
+
+/**
+ * Scalability test for facet query implementation
+ */
+public class FacetSearcher extends SearchScalabilityBenchmark {
+
+    @Override
+    protected Query getQuery(@NotNull QueryManager qm, ScalabilityAbstractSuite.ExecutionContext context) throws RepositoryException {
+
+        final String statement = "select [jcr:path], [facet(jcr:primaryType)] from [nt:base] where native('lucene','*:*')";
+
+        LOG.debug("statement: {}", statement);
+
+        return qm.createQuery(statement, Query.JCR_SQL2);
+    }
+
+
+}
diff --git oak-benchmarks-lucene/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/FormatSearcher.java oak-benchmarks-lucene/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/FormatSearcher.java
new file mode 100644
index 0000000..e7de878
--- /dev/null
+++ oak-benchmarks-lucene/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/FormatSearcher.java
@@ -0,0 +1,61 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+package org.apache.jackrabbit.oak.scalability.benchmarks.search;
+
+import javax.jcr.RepositoryException;
+import javax.jcr.query.Query;
+import javax.jcr.query.QueryManager;
+
+import org.apache.jackrabbit.oak.benchmark.util.MimeType;
+import org.apache.jackrabbit.oak.spi.nodetype.NodeTypeConstants;
+import org.apache.jackrabbit.oak.scalability.suites.ScalabilityBlobSearchSuite;
+import org.apache.jackrabbit.oak.scalability.suites.ScalabilityAbstractSuite.ExecutionContext;
+
+/**
+ * Searches on the file format/Mime type 
+ *
+ */
+public class FormatSearcher extends SearchScalabilityBenchmark {
+    @SuppressWarnings("deprecation")
+    @Override
+    protected Query getQuery(QueryManager qm, ExecutionContext context) throws RepositoryException {
+        StringBuilder statement = new StringBuilder("/jcr:root/");
+        
+        statement.append(((String) context.getMap().get(ScalabilityBlobSearchSuite.CTX_ROOT_NODE_NAME_PROP))).append("//element(*, ")
+            .append(context.getMap().get(ScalabilityBlobSearchSuite.CTX_FILE_NODE_TYPE_PROP)).append(")");
+        statement.append("[((");
+        
+        // adding all the possible mime-types in an OR fashion
+        for (MimeType mt : MimeType.values()) {
+            statement.append("jcr:content/@").append(NodeTypeConstants.JCR_MIMETYPE).append(" = '")
+                .append(mt.getValue()).append("' or ");
+        }
+
+        // removing latest ' or '
+        statement.delete(statement.lastIndexOf(" or "), statement.length());
+        
+        statement.append("))]");
+        
+        LOG.debug("{}", statement);
+        
+        return qm.createQuery(statement.toString(), Query.XPATH);
+    }
+    
+}
+
diff --git oak-benchmarks-lucene/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/FullTextSearcher.java oak-benchmarks-lucene/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/FullTextSearcher.java
new file mode 100644
index 0000000..d8a10c1
--- /dev/null
+++ oak-benchmarks-lucene/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/FullTextSearcher.java
@@ -0,0 +1,49 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+package org.apache.jackrabbit.oak.scalability.benchmarks.search;
+
+import java.util.List;
+import java.util.Random;
+
+import javax.jcr.RepositoryException;
+import javax.jcr.query.Query;
+import javax.jcr.query.QueryManager;
+import org.apache.jackrabbit.oak.scalability.suites.ScalabilityBlobSearchSuite;
+import org.apache.jackrabbit.oak.scalability.suites.ScalabilityAbstractSuite.ExecutionContext;
+import org.jetbrains.annotations.NotNull;
+
+/**
+ * Full text query search
+ *
+ */
+public class FullTextSearcher extends SearchScalabilityBenchmark {
+    private final Random random = new Random(93);
+
+    @SuppressWarnings("deprecation")
+    @Override
+    protected Query getQuery(@NotNull final QueryManager qm, ExecutionContext context) throws RepositoryException {
+        @SuppressWarnings("unchecked")
+        List<String> paths = (List<String>) context.getMap().get(ScalabilityBlobSearchSuite.CTX_SEARCH_PATHS_PROP);
+        
+        return qm.createQuery("//*[jcr:contains(., '" + paths.get(random.nextInt(paths.size()))  + "File"
+                + "*"
+                + "')] ", Query.XPATH);
+    }
+}
+
diff --git oak-benchmarks-lucene/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/LastModifiedSearcher.java oak-benchmarks-lucene/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/LastModifiedSearcher.java
new file mode 100644
index 0000000..f714ed5
--- /dev/null
+++ oak-benchmarks-lucene/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/LastModifiedSearcher.java
@@ -0,0 +1,80 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+package org.apache.jackrabbit.oak.scalability.benchmarks.search;
+
+import javax.jcr.RepositoryException;
+import javax.jcr.query.Query;
+import javax.jcr.query.QueryManager;
+
+import org.apache.jackrabbit.oak.benchmark.util.Date;
+import org.apache.jackrabbit.oak.scalability.suites.ScalabilityBlobSearchSuite;
+import org.apache.jackrabbit.oak.scalability.suites.ScalabilityAbstractSuite.ExecutionContext;
+
+/**
+ * perform searches using the {@code jcr:lastModified} and the provided timeframe
+ */
+public class LastModifiedSearcher extends SearchScalabilityBenchmark {
+    private final Date timeframe;
+    
+    public LastModifiedSearcher(Date timeframe) {
+        this.timeframe = timeframe;
+    }
+    
+    @SuppressWarnings("deprecation")
+    @Override
+    protected Query getQuery(QueryManager qm, ExecutionContext context) throws RepositoryException {
+        //  /jcr:root/content/dam//element(*, dam:Asset)[(jcr:content/@jcr:lastModified >= xs:dateTime('2013-05-09T09:44:01.403Z'))
+        final String path = (String) context.getMap().get(ScalabilityBlobSearchSuite.CTX_ROOT_NODE_NAME_PROP);
+        final String statement = "/jcr:root/" + path + "//element(*, "
+                                 + context.getMap().get(ScalabilityBlobSearchSuite.CTX_FILE_NODE_TYPE_PROP)
+                                 + ")[(jcr:content/@jcr:lastModified >= xs:dateTime('"
+                                 + timeframe.toISO_8601_2000() + "'))]";
+        
+        LOG.debug("LastModifiedSearcher: {}", statement);
+        
+        return qm.createQuery(statement, Query.XPATH);
+    }
+
+    @Override
+    public String toString() {
+        String s = "::";
+        
+        switch(timeframe) {
+        case LAST_2_HRS:
+            s += "Hour";
+            break;
+        case LAST_24_HRS:
+            s += "Day";
+            break;
+        case LAST_7_DAYS:
+            s += "Week";
+            break;
+        case LAST_MONTH:
+            s += "Month";
+            break;
+        case LAST_YEAR:
+            s += "Year";
+            break;
+        default:
+        }
+        
+        return super.toString() + s;
+    }
+}
+
diff --git oak-benchmarks-lucene/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/MultiFilterOrderByKeysetPageSearcher.java oak-benchmarks-lucene/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/MultiFilterOrderByKeysetPageSearcher.java
new file mode 100644
index 0000000..c633c7c
--- /dev/null
+++ oak-benchmarks-lucene/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/MultiFilterOrderByKeysetPageSearcher.java
@@ -0,0 +1,35 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ *  or more contributor license agreements.  See the NOTICE file
+ *  distributed with this work for additional information
+ *  regarding copyright ownership.  The ASF licenses this file
+ *  to you under the Apache License, Version 2.0 (the
+ *  "License"); you may not use this file except in compliance
+ *  with the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ *  Unless required by applicable law or agreed to in writing,
+ *  software distributed under the License is distributed on an
+ *  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ *  KIND, either express or implied.  See the License for the
+ *  specific language governing permissions and limitations
+ *  under the License.
+ */
+package org.apache.jackrabbit.oak.scalability.benchmarks.search;
+
+import javax.jcr.RepositoryException;
+import javax.jcr.query.QueryManager;
+
+import org.apache.jackrabbit.oak.scalability.suites.ScalabilityAbstractSuite.ExecutionContext;
+
+/**
+ * Simulates keyset pagination over the search {@link org.apache.jackrabbit.oak.scalability.benchmarks.search.MultiFilterOrderBySearcher}
+ */
+public class MultiFilterOrderByKeysetPageSearcher extends MultiFilterOrderBySearcher {
+    @Override
+    protected void search(QueryManager qm, ExecutionContext context) throws RepositoryException {
+        processResultsKeysetPagination(qm, context);
+    }
+}
+
diff --git oak-benchmarks-lucene/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/MultiFilterOrderByOffsetPageSearcher.java oak-benchmarks-lucene/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/MultiFilterOrderByOffsetPageSearcher.java
new file mode 100644
index 0000000..20bbf9a
--- /dev/null
+++ oak-benchmarks-lucene/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/MultiFilterOrderByOffsetPageSearcher.java
@@ -0,0 +1,35 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ *  or more contributor license agreements.  See the NOTICE file
+ *  distributed with this work for additional information
+ *  regarding copyright ownership.  The ASF licenses this file
+ *  to you under the Apache License, Version 2.0 (the
+ *  "License"); you may not use this file except in compliance
+ *  with the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ *  Unless required by applicable law or agreed to in writing,
+ *  software distributed under the License is distributed on an
+ *  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ *  KIND, either express or implied.  See the License for the
+ *  specific language governing permissions and limitations
+ *  under the License.
+ */
+package org.apache.jackrabbit.oak.scalability.benchmarks.search;
+
+import javax.jcr.RepositoryException;
+import javax.jcr.query.QueryManager;
+
+import org.apache.jackrabbit.oak.scalability.suites.ScalabilityAbstractSuite.ExecutionContext;
+
+/**
+ * Simulates offset pagination over the search {@link org.apache.jackrabbit.oak.scalability.benchmarks.search.MultiFilterOrderBySearcher}
+ */
+public class MultiFilterOrderByOffsetPageSearcher extends MultiFilterOrderBySearcher {
+    @Override
+    protected void search(QueryManager qm, ExecutionContext context) throws RepositoryException {
+        processResultsOffsetPagination(qm, context);
+    }
+}
+
diff --git oak-benchmarks-lucene/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/MultiFilterOrderBySearcher.java oak-benchmarks-lucene/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/MultiFilterOrderBySearcher.java
new file mode 100644
index 0000000..e2808db
--- /dev/null
+++ oak-benchmarks-lucene/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/MultiFilterOrderBySearcher.java
@@ -0,0 +1,66 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ *  or more contributor license agreements.  See the NOTICE file
+ *  distributed with this work for additional information
+ *  regarding copyright ownership.  The ASF licenses this file
+ *  to you under the Apache License, Version 2.0 (the
+ *  "License"); you may not use this file except in compliance
+ *  with the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ *  Unless required by applicable law or agreed to in writing,
+ *  software distributed under the License is distributed on an
+ *  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ *  KIND, either express or implied.  See the License for the
+ *  specific language governing permissions and limitations
+ *  under the License.
+ */
+package org.apache.jackrabbit.oak.scalability.benchmarks.search;
+
+import java.util.Calendar;
+
+import javax.jcr.RepositoryException;
+import javax.jcr.query.Query;
+import javax.jcr.query.QueryManager;
+
+import org.apache.jackrabbit.oak.benchmark.util.Date;
+import org.apache.jackrabbit.oak.scalability.suites.ScalabilityBlobSearchSuite;
+import org.apache.jackrabbit.oak.scalability.suites.ScalabilityNodeSuite;
+import org.apache.jackrabbit.oak.scalability.suites.ScalabilityAbstractSuite.ExecutionContext;
+import org.jetbrains.annotations.NotNull;
+
+/**
+ * Searches on node with a filter property and orders the results by 2 properties 
+ *
+ */
+public class MultiFilterOrderBySearcher extends PaginationEnabledSearcher {
+    @SuppressWarnings("deprecation")
+    @Override
+    protected Query getQuery(@NotNull QueryManager qm, ExecutionContext context)
+        throws RepositoryException {
+        // /jcr:root/LongevitySearchAssets/12345//element(*, ParentType)[(@filter = 'true' or not
+        // (@filter)] order by @viewed descending, @added descending
+        StringBuilder statement = new StringBuilder("/jcr:root/");
+
+        statement.append(
+            ((String) context.getMap().get(ScalabilityBlobSearchSuite.CTX_ROOT_NODE_NAME_PROP)))
+            .append("//element(*, ")
+            .append(context.getMap().get(ScalabilityNodeSuite.CTX_ACT_NODE_TYPE_PROP)).append(")");
+        statement.append("[((").append("@").append(ScalabilityNodeSuite.FILTER_PROP)
+            .append(" = 'true'").append(" or").append(" not(@")
+            .append(ScalabilityNodeSuite.FILTER_PROP).append("))");
+        if (context.getMap().containsKey(KEYSET_VAL_PROP)) {
+            statement.append(" and @").append(ScalabilityNodeSuite.CTX_PAGINATION_KEY_PROP)
+                .append(" < xs:dateTime('").append(
+                Date.convertToISO_8601_2000((Calendar) context.getMap().get(KEYSET_VAL_PROP)))
+                .append("')");
+        }
+        statement.append(")]").append(getOrderByClause());
+
+        LOG.debug("{}", statement);
+
+        return qm.createQuery(statement.toString(), Query.XPATH);
+    }
+}
+
diff --git oak-benchmarks-lucene/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/MultiFilterSplitOrderByKeysetPageSearcher.java oak-benchmarks-lucene/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/MultiFilterSplitOrderByKeysetPageSearcher.java
new file mode 100644
index 0000000..7765914
--- /dev/null
+++ oak-benchmarks-lucene/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/MultiFilterSplitOrderByKeysetPageSearcher.java
@@ -0,0 +1,36 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ *  or more contributor license agreements.  See the NOTICE file
+ *  distributed with this work for additional information
+ *  regarding copyright ownership.  The ASF licenses this file
+ *  to you under the Apache License, Version 2.0 (the
+ *  "License"); you may not use this file except in compliance
+ *  with the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ *  Unless required by applicable law or agreed to in writing,
+ *  software distributed under the License is distributed on an
+ *  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ *  KIND, either express or implied.  See the License for the
+ *  specific language governing permissions and limitations
+ *  under the License.
+ */
+package org.apache.jackrabbit.oak.scalability.benchmarks.search;
+
+import org.apache.jackrabbit.oak.scalability.suites.ScalabilityAbstractSuite.ExecutionContext;
+
+import javax.jcr.RepositoryException;
+import javax.jcr.query.QueryManager;
+
+/**
+ * Simulates keyset pagination over the search {@link org.apache.jackrabbit.oak.scalability.benchmarks.search.MultiFilterSplitOrderBySearcher}
+ */
+public class MultiFilterSplitOrderByKeysetPageSearcher extends MultiFilterSplitOrderBySearcher {
+    @Override
+    protected void search(QueryManager qm, ExecutionContext context) throws RepositoryException {
+        searchCommon(qm, context);
+        processResultsKeysetPagination(qm, context);
+    }
+}
+
diff --git oak-benchmarks-lucene/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/MultiFilterSplitOrderByOffsetPageSearcher.java oak-benchmarks-lucene/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/MultiFilterSplitOrderByOffsetPageSearcher.java
new file mode 100644
index 0000000..4ad5cef
--- /dev/null
+++ oak-benchmarks-lucene/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/MultiFilterSplitOrderByOffsetPageSearcher.java
@@ -0,0 +1,37 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ *  or more contributor license agreements.  See the NOTICE file
+ *  distributed with this work for additional information
+ *  regarding copyright ownership.  The ASF licenses this file
+ *  to you under the Apache License, Version 2.0 (the
+ *  "License"); you may not use this file except in compliance
+ *  with the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ *  Unless required by applicable law or agreed to in writing,
+ *  software distributed under the License is distributed on an
+ *  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ *  KIND, either express or implied.  See the License for the
+ *  specific language governing permissions and limitations
+ *  under the License.
+ */
+
+package org.apache.jackrabbit.oak.scalability.benchmarks.search;
+
+import javax.jcr.RepositoryException;
+import javax.jcr.query.QueryManager;
+
+import org.apache.jackrabbit.oak.scalability.suites.ScalabilityAbstractSuite;
+
+/**
+ * Simulates offset pagination over the search {@link org.apache.jackrabbit.oak.scalability.benchmarks.search.MultiFilterSplitOrderBySearcher}
+ */
+public class MultiFilterSplitOrderByOffsetPageSearcher extends MultiFilterSplitOrderBySearcher {
+    @Override
+    protected void search(QueryManager qm, ScalabilityAbstractSuite.ExecutionContext context)
+        throws RepositoryException {
+        searchCommon(qm, context);
+        processResultsOffsetPagination(qm, context);
+    }
+}
diff --git oak-benchmarks-lucene/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/MultiFilterSplitOrderBySearcher.java oak-benchmarks-lucene/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/MultiFilterSplitOrderBySearcher.java
new file mode 100644
index 0000000..062590d
--- /dev/null
+++ oak-benchmarks-lucene/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/MultiFilterSplitOrderBySearcher.java
@@ -0,0 +1,89 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ *  or more contributor license agreements.  See the NOTICE file
+ *  distributed with this work for additional information
+ *  regarding copyright ownership.  The ASF licenses this file
+ *  to you under the Apache License, Version 2.0 (the
+ *  "License"); you may not use this file except in compliance
+ *  with the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ *  Unless required by applicable law or agreed to in writing,
+ *  software distributed under the License is distributed on an
+ *  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ *  KIND, either express or implied.  See the License for the
+ *  specific language governing permissions and limitations
+ *  under the License.
+ */
+
+package org.apache.jackrabbit.oak.scalability.benchmarks.search;
+
+import javax.jcr.Node;
+import javax.jcr.RepositoryException;
+import javax.jcr.query.*;
+
+import org.apache.jackrabbit.oak.scalability.suites.ScalabilityBlobSearchSuite;
+import org.apache.jackrabbit.oak.scalability.suites.ScalabilityNodeSuite;
+import org.apache.jackrabbit.oak.scalability.suites.ScalabilityAbstractSuite.ExecutionContext;
+import org.jetbrains.annotations.NotNull;
+
+/**
+ * Splits the query in {@link org.apache.jackrabbit.oak.scalability.benchmarks.search.MultiFilterOrderBySearcher}
+ * into multiple queries and unions the results.
+ */
+public class MultiFilterSplitOrderBySearcher extends MultiFilterOrderBySearcher {
+    @Override
+    protected void search(QueryManager qm, ExecutionContext context)
+        throws RepositoryException {
+        searchCommon(qm, context);
+
+        Query q = getQuery(qm, context);
+        QueryResult r = q.execute();
+        RowIterator it = r.getRows();
+
+        for (int rows = 0; it.hasNext() && rows < LIMIT; rows++) {
+            Node node = it.nextRow().getNode();
+            LOG.debug(node.getPath());
+        }
+    }
+
+    protected void searchCommon(QueryManager qm, ExecutionContext
+        context) throws RepositoryException {
+        /** Execute standard query */
+        Query stdQuery = getStandardQuery(qm, context);
+        stdQuery.setLimit(LIMIT);
+        QueryResult stdResult = stdQuery.execute();
+        RowIterator stdIt = stdResult.getRows();
+
+        // Iterate the standard shown first
+        for (int rows = 0; stdIt.hasNext() && rows < LIMIT; rows++) {
+            Node node = stdIt.nextRow().getNode();
+            LOG.debug(node.getPath());
+        }
+    }
+
+    protected Query getStandardQuery(@NotNull final QueryManager qm, ExecutionContext context)
+        throws RepositoryException {
+        // /jcr:root/LongevitySearchAssets/12345//element(*, ParentType)[(@viewed = 'true')] order
+        // by @viewed descending
+        StringBuilder statement = new StringBuilder("/jcr:root/");
+
+        statement.append(
+            ((String) context.getMap().get(ScalabilityBlobSearchSuite.CTX_ROOT_NODE_NAME_PROP)))
+            .append("//element(*, ")
+            .append(context.getMap().get(ScalabilityNodeSuite.CTX_ACT_NODE_TYPE_PROP)).append(")");
+        statement.append("[(").append("@").append(ScalabilityNodeSuite.SORT_PROP)
+            .append("= 'true'");
+        statement.append(")]");
+
+        LOG.debug("{}", statement);
+
+        return qm.createQuery(statement.toString(), Query.XPATH);
+    }
+
+    @Override
+    protected String getOrderByClause() {
+        return " order by" + " @" + ScalabilityNodeSuite.DATE_PROP + " descending";
+    }
+}
diff --git oak-benchmarks-lucene/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/NodeTypeSearcher.java oak-benchmarks-lucene/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/NodeTypeSearcher.java
new file mode 100644
index 0000000..7e8748a
--- /dev/null
+++ oak-benchmarks-lucene/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/NodeTypeSearcher.java
@@ -0,0 +1,43 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+package org.apache.jackrabbit.oak.scalability.benchmarks.search;
+
+import javax.jcr.RepositoryException;
+import javax.jcr.query.Query;
+import javax.jcr.query.QueryManager;
+import org.apache.jackrabbit.oak.scalability.suites.ScalabilityBlobSearchSuite;
+import org.apache.jackrabbit.oak.scalability.suites.ScalabilityAbstractSuite.ExecutionContext;
+import org.jetbrains.annotations.NotNull;
+
+/**
+ * Searches on the NodeType 
+ *
+ */
+public class NodeTypeSearcher extends SearchScalabilityBenchmark {
+    
+    @SuppressWarnings("deprecation")
+    @Override
+    protected Query getQuery(@NotNull final QueryManager qm, ExecutionContext context) throws RepositoryException {
+        return qm.createQuery(
+                "/jcr:root/" + ((String) context.getMap().get(ScalabilityBlobSearchSuite.CTX_ROOT_NODE_NAME_PROP)) + "//element(*, "
+                        + context.getMap().get(ScalabilityBlobSearchSuite.CTX_FILE_NODE_TYPE_PROP) + ")",
+                Query.XPATH);
+    }
+}
+
diff --git oak-benchmarks-lucene/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/OrderByDate.java oak-benchmarks-lucene/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/OrderByDate.java
new file mode 100644
index 0000000..3b2c281
--- /dev/null
+++ oak-benchmarks-lucene/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/OrderByDate.java
@@ -0,0 +1,43 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.jackrabbit.oak.scalability.benchmarks.search;
+
+import javax.jcr.RepositoryException;
+import javax.jcr.query.Query;
+import javax.jcr.query.QueryManager;
+import org.apache.jackrabbit.oak.scalability.suites.ScalabilityBlobSearchSuite;
+import org.apache.jackrabbit.oak.scalability.suites.ScalabilityAbstractSuite.ExecutionContext;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+public class OrderByDate extends SearchScalabilityBenchmark {
+    private static final Logger LOG = LoggerFactory.getLogger(OrderByDate.class);
+    
+    @Override
+    protected Query getQuery(final QueryManager qm, final ExecutionContext context) throws RepositoryException {
+        final String path = (String) context.getMap().get(
+            ScalabilityBlobSearchSuite.CTX_ROOT_NODE_NAME_PROP);
+        final String statement = String.format(
+            "SELECT * FROM [%s] WHERE ISDESCENDANTNODE('/%s') ORDER BY [jcr:content/jcr:lastModified]",
+            context.getMap().get(ScalabilityBlobSearchSuite.CTX_FILE_NODE_TYPE_PROP),
+            path);
+        
+        LOG.debug("statement: {}", statement);
+        
+        return qm.createQuery(statement, Query.JCR_SQL2);
+    }
+}
diff --git oak-benchmarks-lucene/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/OrderByKeysetPageSearcher.java oak-benchmarks-lucene/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/OrderByKeysetPageSearcher.java
new file mode 100644
index 0000000..e5c7b0c
--- /dev/null
+++ oak-benchmarks-lucene/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/OrderByKeysetPageSearcher.java
@@ -0,0 +1,35 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ *  or more contributor license agreements.  See the NOTICE file
+ *  distributed with this work for additional information
+ *  regarding copyright ownership.  The ASF licenses this file
+ *  to you under the Apache License, Version 2.0 (the
+ *  "License"); you may not use this file except in compliance
+ *  with the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ *  Unless required by applicable law or agreed to in writing,
+ *  software distributed under the License is distributed on an
+ *  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ *  KIND, either express or implied.  See the License for the
+ *  specific language governing permissions and limitations
+ *  under the License.
+ */
+package org.apache.jackrabbit.oak.scalability.benchmarks.search;
+
+import javax.jcr.RepositoryException;
+import javax.jcr.query.QueryManager;
+
+import org.apache.jackrabbit.oak.scalability.suites.ScalabilityAbstractSuite.ExecutionContext;
+
+/**
+ * Simulates keyset pagination over the search {@link org.apache.jackrabbit.oak.scalability.benchmarks.search.OrderBySearcher}
+ */
+public class OrderByKeysetPageSearcher extends OrderBySearcher {
+    @Override
+    protected void search(QueryManager qm, ExecutionContext context) throws RepositoryException {
+        processResultsKeysetPagination(qm, context);
+    }
+}
+
diff --git oak-benchmarks-lucene/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/OrderByOffsetPageSearcher.java oak-benchmarks-lucene/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/OrderByOffsetPageSearcher.java
new file mode 100644
index 0000000..c91223b
--- /dev/null
+++ oak-benchmarks-lucene/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/OrderByOffsetPageSearcher.java
@@ -0,0 +1,35 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ *  or more contributor license agreements.  See the NOTICE file
+ *  distributed with this work for additional information
+ *  regarding copyright ownership.  The ASF licenses this file
+ *  to you under the Apache License, Version 2.0 (the
+ *  "License"); you may not use this file except in compliance
+ *  with the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ *  Unless required by applicable law or agreed to in writing,
+ *  software distributed under the License is distributed on an
+ *  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ *  KIND, either express or implied.  See the License for the
+ *  specific language governing permissions and limitations
+ *  under the License.
+ */
+package org.apache.jackrabbit.oak.scalability.benchmarks.search;
+
+import javax.jcr.RepositoryException;
+import javax.jcr.query.QueryManager;
+
+import org.apache.jackrabbit.oak.scalability.suites.ScalabilityAbstractSuite.ExecutionContext;
+
+/**
+ * Simulates offset pagination over the search {@link org.apache.jackrabbit.oak.scalability.benchmarks.search.OrderBySearcher}
+ */
+public class OrderByOffsetPageSearcher extends OrderBySearcher {
+    @Override
+    protected void search(QueryManager qm, ExecutionContext context) throws RepositoryException {
+        processResultsOffsetPagination(qm, context);
+    }
+}
+
diff --git oak-benchmarks-lucene/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/OrderBySearcher.java oak-benchmarks-lucene/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/OrderBySearcher.java
new file mode 100644
index 0000000..2bf9c13
--- /dev/null
+++ oak-benchmarks-lucene/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/OrderBySearcher.java
@@ -0,0 +1,62 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ *  or more contributor license agreements.  See the NOTICE file
+ *  distributed with this work for additional information
+ *  regarding copyright ownership.  The ASF licenses this file
+ *  to you under the Apache License, Version 2.0 (the
+ *  "License"); you may not use this file except in compliance
+ *  with the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ *  Unless required by applicable law or agreed to in writing,
+ *  software distributed under the License is distributed on an
+ *  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ *  KIND, either express or implied.  See the License for the
+ *  specific language governing permissions and limitations
+ *  under the License.
+ */
+package org.apache.jackrabbit.oak.scalability.benchmarks.search;
+
+import java.util.Calendar;
+
+import javax.jcr.RepositoryException;
+import javax.jcr.query.Query;
+import javax.jcr.query.QueryManager;
+
+import org.apache.jackrabbit.oak.benchmark.util.Date;
+import org.apache.jackrabbit.oak.scalability.suites.ScalabilityBlobSearchSuite;
+import org.apache.jackrabbit.oak.scalability.suites.ScalabilityNodeSuite;
+import org.apache.jackrabbit.oak.scalability.suites.ScalabilityAbstractSuite.ExecutionContext;
+import org.jetbrains.annotations.NotNull;
+
+/**
+ * Searches on path and orders the results by 2 properties
+ */
+public class OrderBySearcher extends PaginationEnabledSearcher {
+    @SuppressWarnings("deprecation") @Override
+    protected Query getQuery(@NotNull QueryManager qm, ExecutionContext context)
+        throws RepositoryException {
+        // /jcr:root/LongevitySearchAssets/12345//element(*, ParentType) order by @viewed
+        // descending, @added descending
+        StringBuilder statement = new StringBuilder("/jcr:root/");
+
+        statement.append(
+            ((String) context.getMap().get(ScalabilityBlobSearchSuite.CTX_ROOT_NODE_NAME_PROP)))
+            .append("//element(*, ")
+            .append(context.getMap().get(ScalabilityNodeSuite.CTX_ACT_NODE_TYPE_PROP)).append(")");
+        if (context.getMap().containsKey(KEYSET_VAL_PROP)) {
+            statement.append("[(").append("@").append(ScalabilityNodeSuite.CTX_PAGINATION_KEY_PROP)
+                .append(" < xs:dateTime('").append(
+                Date.convertToISO_8601_2000((Calendar) context.getMap().get(KEYSET_VAL_PROP)))
+                .append("'))]");
+        }
+
+        statement.append(getOrderByClause());
+
+        LOG.debug("{}", statement);
+
+        return qm.createQuery(statement.toString(), Query.XPATH);
+    }
+}
+
diff --git oak-benchmarks-lucene/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/PaginationEnabledSearcher.java oak-benchmarks-lucene/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/PaginationEnabledSearcher.java
new file mode 100644
index 0000000..81ff698
--- /dev/null
+++ oak-benchmarks-lucene/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/PaginationEnabledSearcher.java
@@ -0,0 +1,101 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ *  or more contributor license agreements.  See the NOTICE file
+ *  distributed with this work for additional information
+ *  regarding copyright ownership.  The ASF licenses this file
+ *  to you under the Apache License, Version 2.0 (the
+ *  "License"); you may not use this file except in compliance
+ *  with the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ *  Unless required by applicable law or agreed to in writing,
+ *  software distributed under the License is distributed on an
+ *  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ *  KIND, either express or implied.  See the License for the
+ *  specific language governing permissions and limitations
+ *  under the License.
+ */
+package org.apache.jackrabbit.oak.scalability.benchmarks.search;
+
+import java.util.Calendar;
+import java.util.TimeZone;
+
+import javax.jcr.Node;
+import javax.jcr.Property;
+import javax.jcr.RepositoryException;
+import javax.jcr.query.Query;
+import javax.jcr.query.QueryManager;
+import javax.jcr.query.QueryResult;
+import javax.jcr.query.RowIterator;
+import org.apache.jackrabbit.oak.scalability.suites.ScalabilityNodeSuite;
+import org.apache.jackrabbit.oak.scalability.suites.ScalabilityAbstractSuite.ExecutionContext;
+import org.jetbrains.annotations.NotNull;
+
+/**
+ * Abstract class which defines utility methods for processing results like 
+ * pagination and no pagination. 
+ *
+ */
+public abstract class PaginationEnabledSearcher extends SearchScalabilityBenchmark {
+    /**
+     * Pagination limit for one page
+     */
+    protected static final int LIMIT = Integer.getInteger("limit", 25);
+
+    /**
+     * Number of page accesses
+     */
+    protected static final int PAGES = Integer.getInteger("pages", 5);
+
+    protected static final String KEYSET_VAL_PROP = "keysetval";
+
+    protected void processResultsOffsetPagination(@NotNull final QueryManager qm,
+            ExecutionContext context) throws RepositoryException {
+        for (int page = 0; page < PAGES; page++) {
+            Query query = getQuery(qm, context);
+            query.setLimit(LIMIT);
+            query.setOffset(page * LIMIT);
+
+            iterate(query);
+        }
+    }
+
+    private Node iterate(Query query) throws RepositoryException {
+        QueryResult r = query.execute();
+        RowIterator it = r.getRows();
+        Node last = null;
+
+        while (it.hasNext()) {
+            last = it.nextRow().getNode();
+            LOG.debug(last.getPath());
+        }
+        return last;
+    }
+
+    protected void processResultsKeysetPagination(@NotNull final QueryManager qm,
+            ExecutionContext context) throws RepositoryException {
+        Calendar now = Calendar.getInstance();
+        now.setTimeZone(TimeZone.getTimeZone("GMT"));
+        context.getMap().put(KEYSET_VAL_PROP, now);
+
+        for (int page = 0; page < PAGES; page++) {
+            Query query = getQuery(qm, context);
+            query.setLimit(LIMIT);
+
+            Node lastNode = iterate(query);
+            if (lastNode != null) {
+                Property prop =
+                        lastNode.getProperty(ScalabilityNodeSuite.CTX_PAGINATION_KEY_PROP);
+                context.getMap().put(KEYSET_VAL_PROP, prop.getDate());
+            }
+        }
+        context.getMap().remove(KEYSET_VAL_PROP);
+    }
+
+    protected String getOrderByClause() {
+        return " order by" + " @" + ScalabilityNodeSuite.SORT_PROP + " descending," + " @"
+            + ScalabilityNodeSuite.DATE_PROP + " descending";
+    }
+}
+
diff --git oak-benchmarks-lucene/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/SearchScalabilityBenchmark.java oak-benchmarks-lucene/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/SearchScalabilityBenchmark.java
new file mode 100644
index 0000000..4355a10
--- /dev/null
+++ oak-benchmarks-lucene/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/SearchScalabilityBenchmark.java
@@ -0,0 +1,74 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+package org.apache.jackrabbit.oak.scalability.benchmarks.search;
+
+import javax.jcr.Credentials;
+import javax.jcr.Node;
+import javax.jcr.Repository;
+import javax.jcr.RepositoryException;
+import javax.jcr.Session;
+import javax.jcr.query.Query;
+import javax.jcr.query.QueryManager;
+import javax.jcr.query.QueryResult;
+import javax.jcr.query.RowIterator;
+import org.apache.jackrabbit.oak.scalability.benchmarks.ScalabilityBenchmark;
+import org.apache.jackrabbit.oak.scalability.suites.ScalabilityAbstractSuite.ExecutionContext;
+import org.jetbrains.annotations.NotNull;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+/**
+ * Abstract class for search scalability benchmarks.
+ *
+ */
+public abstract class SearchScalabilityBenchmark extends ScalabilityBenchmark {
+    protected static final Logger LOG = LoggerFactory.getLogger(SearchScalabilityBenchmark.class);    
+
+    /**
+     * Controls the max results retrieved after search
+     */
+    private static final int MAX_RESULTS = Integer.getInteger("maxResults", 100);
+
+    @Override
+    public void execute(Repository repository, Credentials credentials, ExecutionContext context) 
+            throws Exception {
+        Session session = repository.login(credentials);
+        QueryManager qm;
+        try {
+            qm = session.getWorkspace().getQueryManager();
+            search(qm, context);
+        } catch (RepositoryException e) {
+            e.printStackTrace();
+        }
+    }
+
+    protected void search(QueryManager qm, ExecutionContext context) throws RepositoryException {
+        Query q = getQuery(qm, context);
+        QueryResult r = q.execute();
+        RowIterator it = r.getRows();
+        for (int rows = 0; it.hasNext() && rows < MAX_RESULTS; rows++) {
+            Node node = it.nextRow().getNode();
+            LOG.debug(node.getPath());
+        }
+    }
+
+    protected abstract Query getQuery(@NotNull final QueryManager qm, ExecutionContext context) 
+            throws RepositoryException;
+}
+
diff --git oak-benchmarks-lucene/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/SplitOrderByKeysetPageSearcher.java oak-benchmarks-lucene/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/SplitOrderByKeysetPageSearcher.java
new file mode 100644
index 0000000..5ca65be
--- /dev/null
+++ oak-benchmarks-lucene/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/SplitOrderByKeysetPageSearcher.java
@@ -0,0 +1,35 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ *  or more contributor license agreements.  See the NOTICE file
+ *  distributed with this work for additional information
+ *  regarding copyright ownership.  The ASF licenses this file
+ *  to you under the Apache License, Version 2.0 (the
+ *  "License"); you may not use this file except in compliance
+ *  with the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ *  Unless required by applicable law or agreed to in writing,
+ *  software distributed under the License is distributed on an
+ *  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ *  KIND, either express or implied.  See the License for the
+ *  specific language governing permissions and limitations
+ *  under the License.
+ */
+package org.apache.jackrabbit.oak.scalability.benchmarks.search;
+
+import org.apache.jackrabbit.oak.scalability.suites.ScalabilityAbstractSuite.ExecutionContext;
+
+import javax.jcr.RepositoryException;
+import javax.jcr.query.QueryManager;
+
+/**
+ * Simulates keyset pagination over the search {@link org.apache.jackrabbit.oak.scalability.benchmarks.search.SplitOrderBySearcher}
+ */
+public class SplitOrderByKeysetPageSearcher extends SplitOrderBySearcher {
+    @Override
+    protected void search(QueryManager qm, ExecutionContext context) throws RepositoryException {
+        searchCommon(qm, context);
+        processResultsKeysetPagination(qm, context);
+    }
+}
diff --git oak-benchmarks-lucene/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/SplitOrderByOffsetPageSearcher.java oak-benchmarks-lucene/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/SplitOrderByOffsetPageSearcher.java
new file mode 100644
index 0000000..765b90c
--- /dev/null
+++ oak-benchmarks-lucene/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/SplitOrderByOffsetPageSearcher.java
@@ -0,0 +1,36 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ *  or more contributor license agreements.  See the NOTICE file
+ *  distributed with this work for additional information
+ *  regarding copyright ownership.  The ASF licenses this file
+ *  to you under the Apache License, Version 2.0 (the
+ *  "License"); you may not use this file except in compliance
+ *  with the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ *  Unless required by applicable law or agreed to in writing,
+ *  software distributed under the License is distributed on an
+ *  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ *  KIND, either express or implied.  See the License for the
+ *  specific language governing permissions and limitations
+ *  under the License.
+ */
+package org.apache.jackrabbit.oak.scalability.benchmarks.search;
+
+import org.apache.jackrabbit.oak.scalability.suites.ScalabilityAbstractSuite.ExecutionContext;
+
+import javax.jcr.RepositoryException;
+import javax.jcr.query.QueryManager;
+
+/**
+ * Simulates offset pagination over the search {@link org.apache.jackrabbit.oak.scalability.benchmarks.search.SplitOrderBySearcher}
+ */
+public class SplitOrderByOffsetPageSearcher extends SplitOrderBySearcher {
+    @Override
+    protected void search(QueryManager qm, ExecutionContext context) throws RepositoryException {
+        searchCommon(qm, context);
+        processResultsOffsetPagination(qm, context);
+    }
+}
+
diff --git oak-benchmarks-lucene/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/SplitOrderBySearcher.java oak-benchmarks-lucene/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/SplitOrderBySearcher.java
new file mode 100644
index 0000000..deb118d
--- /dev/null
+++ oak-benchmarks-lucene/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/SplitOrderBySearcher.java
@@ -0,0 +1,92 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ *  or more contributor license agreements.  See the NOTICE file
+ *  distributed with this work for additional information
+ *  regarding copyright ownership.  The ASF licenses this file
+ *  to you under the Apache License, Version 2.0 (the
+ *  "License"); you may not use this file except in compliance
+ *  with the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ *  Unless required by applicable law or agreed to in writing,
+ *  software distributed under the License is distributed on an
+ *  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ *  KIND, either express or implied.  See the License for the
+ *  specific language governing permissions and limitations
+ *  under the License.
+ */
+package org.apache.jackrabbit.oak.scalability.benchmarks.search;
+
+import org.apache.jackrabbit.oak.scalability.suites.ScalabilityBlobSearchSuite;
+import org.apache.jackrabbit.oak.scalability.suites.ScalabilityNodeSuite;
+import org.apache.jackrabbit.oak.scalability.suites.ScalabilityAbstractSuite.ExecutionContext;
+import org.jetbrains.annotations.NotNull;
+
+import javax.jcr.Node;
+import javax.jcr.RepositoryException;
+import javax.jcr.query.Query;
+import javax.jcr.query.QueryManager;
+import javax.jcr.query.QueryResult;
+import javax.jcr.query.RowIterator;
+
+/**
+ * Splits the search in {@link org.apache.jackrabbit.oak.scalability.benchmarks.search.OrderBySearcher} to multiple
+ * queries and unions the results.
+ *
+ */
+public class SplitOrderBySearcher extends OrderBySearcher {
+    @Override
+    protected void search(QueryManager qm, ExecutionContext context)
+        throws RepositoryException {
+        searchCommon(qm, context);
+
+        Query q = getQuery(qm, context);
+        QueryResult r = q.execute();
+        RowIterator it = r.getRows();
+
+        for (int rows = 0; it.hasNext() && rows < LIMIT; rows++) {
+            Node node = it.nextRow().getNode();
+            LOG.debug(node.getPath());
+        }
+    }
+
+    protected void searchCommon(QueryManager qm, ExecutionContext context)
+        throws RepositoryException {
+        /** Execute standard query */
+        Query stdQuery = getStandardQuery(qm, context);
+        stdQuery.setLimit(LIMIT);
+        QueryResult stdResult = stdQuery.execute();
+        RowIterator stdIt = stdResult.getRows();
+
+        // Iterate the standard shown first
+        for (int rows = 0; stdIt.hasNext() && rows < LIMIT; rows++) {
+            Node node = stdIt.nextRow().getNode();
+            LOG.debug(node.getPath());
+        }
+    }
+
+    protected Query getStandardQuery(@NotNull final QueryManager qm,
+        ExecutionContext context)
+        throws RepositoryException {
+        // /jcr:root/LongevitySearchAssets/12345//element(*, ParentType)[(@viewed = 'true')]
+        StringBuilder statement = new StringBuilder("/jcr:root/");
+
+        statement.append(
+            ((String) context.getMap().get(ScalabilityBlobSearchSuite.CTX_ROOT_NODE_NAME_PROP)))
+            .append("//element(*, ")
+            .append(context.getMap().get(ScalabilityNodeSuite.CTX_ACT_NODE_TYPE_PROP)).append(")");
+        statement.append("[(").append("@").append(ScalabilityNodeSuite.SORT_PROP).append("= 'true'")
+            .append(")]");
+
+        LOG.debug("{}", statement);
+
+        return qm.createQuery(statement.toString(), Query.XPATH);
+    }
+
+    @Override
+    protected String getOrderByClause() {
+        return " order by" + " @" + ScalabilityNodeSuite.DATE_PROP + " descending";
+    }
+}
+
diff --git oak-benchmarks-lucene/src/main/java/org/apache/jackrabbit/oak/scalability/suites/ScalabilityBlobSearchSuite.java oak-benchmarks-lucene/src/main/java/org/apache/jackrabbit/oak/scalability/suites/ScalabilityBlobSearchSuite.java
new file mode 100644
index 0000000..77bfa2b
--- /dev/null
+++ oak-benchmarks-lucene/src/main/java/org/apache/jackrabbit/oak/scalability/suites/ScalabilityBlobSearchSuite.java
@@ -0,0 +1,445 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+package org.apache.jackrabbit.oak.scalability.suites;
+
+import static com.google.common.collect.Lists.newArrayList;
+import static com.google.common.collect.Lists.newArrayListWithCapacity;
+
+import java.util.List;
+import java.util.Random;
+import java.util.concurrent.TimeUnit;
+
+import javax.jcr.Binary;
+import javax.jcr.Node;
+import javax.jcr.Property;
+import javax.jcr.PropertyType;
+import javax.jcr.RepositoryException;
+import javax.jcr.Session;
+import javax.jcr.UnsupportedRepositoryOperationException;
+import javax.jcr.ValueFormatException;
+import javax.jcr.lock.LockException;
+import javax.jcr.nodetype.ConstraintViolationException;
+import javax.jcr.nodetype.NodeType;
+import javax.jcr.version.VersionException;
+
+import com.google.common.base.Stopwatch;
+import com.google.common.base.Strings;
+import com.google.common.collect.Lists;
+
+import org.apache.commons.io.output.NullOutputStream;
+import org.apache.commons.math.stat.descriptive.SynchronizedDescriptiveStatistics;
+import org.apache.jackrabbit.commons.JcrUtils;
+import org.apache.jackrabbit.oak.benchmark.TestInputStream;
+import org.apache.jackrabbit.oak.benchmark.util.Date;
+import org.apache.jackrabbit.oak.benchmark.util.MimeType;
+import org.apache.jackrabbit.oak.benchmark.util.OakIndexUtils;
+import org.apache.jackrabbit.oak.spi.nodetype.NodeTypeConstants;
+import org.apache.jackrabbit.oak.scalability.util.NodeTypeUtils;
+
+
+/**
+ * The suite test will incrementally increase the load and execute searches.
+ * Each test run thus adds blobs and executes different searches. This way we measure time taken for
+ * search(es) execution.
+ *
+ * <p>
+ * The following system JVM properties can be defined to configure the suite.
+ * <ul>
+ * <li>
+ *     <code>fileWriters</code> - Controls the number of concurrent background threads for writing blobs.
+ *     Defaults to 0.
+ * </li>
+ * <li>
+ *     <code>fileReaders</code> - Controls the number of concurrent background threads for reading blobs.
+ *     Defaults to 1.
+ * </li>
+ * <li>
+ *     <code>fileSize</code> - Controls the size in KB of the blobs. Defaults to 1.
+ * </li>
+ * <li>
+ *     <code>maxAssets</code> - Controls the max child nodes created under a node. Defaults to 500.
+ * </li>
+ * </ul>
+ */
+public class ScalabilityBlobSearchSuite extends ScalabilityNodeSuite {
+    private static final int FILE_SIZE = Integer.getInteger("fileSize", 1);
+
+    /**
+     * Controls the number of concurrent threads for writing blobs
+     */
+    private static final int WRITERS = Integer.getInteger("fileWriters", 0);
+
+    /**
+     * Controls the number of concurrent thread for reading blobs
+     */
+    private static final int READERS = Integer.getInteger("fileReaders", 0);
+
+    /**
+     * Controls the max child nodes created under a node.
+     */
+    private static final int MAX_ASSETS_PER_LEVEL = Integer.getInteger("maxAssets", 500);
+
+    public static final String CTX_FILE_NODE_TYPE_PROP = "nodeType";
+
+    private static final String CUSTOM_PATH_PROP = "contentPath";
+
+    private static final String CUSTOM_REF_PROP = "references";
+
+    private static final String CUSTOM_NODE_TYPE = "Asset";
+
+    private static final String CUSTOM_INDEX_TYPE = "AssetIndex";
+
+    private final Random random = new Random(29);
+
+    private List<String> searchPaths;
+
+    private List<String> readPaths;
+    private String nodeType;
+    private String indexType;
+
+    public ScalabilityBlobSearchSuite(Boolean storageEnabled) {
+        super(storageEnabled);
+    }
+
+
+    @Override
+    protected void beforeSuite() throws Exception {
+        Session session = loginWriter();
+        Node root = session.getRootNode();
+        root.addNode(ROOT_NODE_NAME);
+        session.save();
+
+        if (CUSTOM_TYPE) {
+            indexType =
+                    NodeTypeUtils.createNodeType(session, CUSTOM_INDEX_TYPE, null, null, null,
+                            null, null, true);
+            setNodeType(NodeTypeUtils.createNodeType(
+                    session, CUSTOM_NODE_TYPE,
+                    new String[] {CUSTOM_PATH_PROP, CUSTOM_REF_PROP},
+                    new int[] {PropertyType.STRING, PropertyType.STRING},                    
+                    new String[] {indexType}, null, NodeTypeConstants.NT_FILE, false));
+        } else {
+            String type = NodeTypeConstants.NT_UNSTRUCTURED;
+            if (session.getWorkspace().getNodeTypeManager().hasNodeType(
+                    NodeTypeConstants.NT_OAK_UNSTRUCTURED)) {
+                type = NodeTypeConstants.NT_OAK_UNSTRUCTURED;
+            }
+            setNodeType(type);
+        }
+
+        // defining indexes
+        if (INDEX) {
+            OakIndexUtils.propertyIndexDefinition(session, NodeTypeConstants.JCR_MIMETYPE,
+                new String[] {NodeTypeConstants.JCR_MIMETYPE}, false,
+                (Strings.isNullOrEmpty(indexType) ? new String[0] : new String[] {indexType}));
+            OakIndexUtils
+                .orderedIndexDefinition(session, NodeTypeConstants.JCR_LASTMODIFIED, ASYNC_INDEX,
+                    new String[] {NodeTypeConstants.JCR_LASTMODIFIED}, false,
+                    (Strings.isNullOrEmpty(indexType) ? new String[0] : new String[] {indexType}),
+                    null);
+        }
+    }
+
+    /**
+     * Executes before each test run
+     */
+    @Override
+    public void beforeIteration(ExecutionContext context) throws RepositoryException {
+        if (LOG.isDebugEnabled()) {
+            LOG.debug("Started beforeIteration()");
+        }
+
+        // recreate paths created in this run
+        searchPaths = newArrayList();
+        readPaths = newArrayListWithCapacity(READERS);
+
+        // create the blob load for this iteration
+        createLoad(context);
+
+        // Add background jobs to simulate workload
+        for (int i = 0; i < WRITERS; i++) {
+            /* Each writer will write to a directory of the form load-b-i */
+            addBackgroundJob(new BlobWriter(String.valueOf(context.getIncrement() + "-b-" + i), 1,
+                    null));
+        }
+        for (int i = 0; i < READERS; i++) {
+            addBackgroundJob(new Reader());
+        }
+
+        if (LOG.isDebugEnabled()) {
+            LOG.debug("Finish beforeIteration()");
+        }
+
+        context.getMap().put(CTX_ROOT_NODE_NAME_PROP, ROOT_NODE_NAME);
+        context.getMap().put(CTX_SEARCH_PATHS_PROP, searchPaths);
+    }
+
+    @Override
+    protected Writer getWriter(ExecutionContext context,
+            SynchronizedDescriptiveStatistics writeStats, int idx) throws RepositoryException {
+        return new BlobWriter((context.getIncrement() + "-" + idx),
+                context.getIncrement() / LOADERS, writeStats);
+    }
+
+    private synchronized String getRandomReadPath() {
+        if (readPaths.isEmpty()) {
+            return "";
+        } else {
+            return readPaths.get(random.nextInt(readPaths.size()));
+        }
+    }
+
+    private synchronized void addReadPath(String file) {
+        // Limit the number of paths added to be no more than the number of readers to limit the
+        // heap used.
+        int limit = 1000;
+        if (readPaths.size() < limit) {
+            readPaths.add(file);
+        } else if (random.nextDouble() < 0.5) {
+            readPaths.set(random.nextInt(limit), file);
+        }
+    }
+
+    private synchronized void addSearchPath(String path) {
+        if (!searchPaths.contains(path)) {
+            searchPaths.add(path);
+        }
+    }
+
+    public String getNodeType() {
+        return nodeType;
+    }
+
+    protected void setNodeType(String nodeType) {
+        this.nodeType = nodeType;
+    }
+
+    private class Reader implements Runnable {
+
+        private final Session session = loginWriter();
+
+        @Override
+        public void run() {
+            try {
+                String path = getRandomReadPath();
+                session.refresh(false);
+                JcrUtils.readFile(
+                        session.getNode(path), new NullOutputStream());
+            } catch (Exception e) {
+                LOG.error("Exception in reader execution ", e);
+            }
+        }
+
+    }
+
+    /**
+     * Creates a node hierarchy similar to the below structure. Here a file Level0Level1Level2File0 is created
+     * which has a reference to Leve0Level1Level3File10:
+     *
+     * <pre>
+     * {@code
+     *  /LongevitySearchAssets<ID>
+     *      /writer<ID>
+     *          /0
+     *              /1
+     *                  /2
+     *                      /Level0Level1Level2File0
+     *                          jcr:primaryType : <oak:Unstructured|Asset|nt:unstructured>
+     *                          /jcr:content
+     *                              jcr:mimeType : <MIMETYPE>
+     *                              jcr:lastModified : <DATE>
+     *                              jcr:data : <BINARY>
+     *                              customPathProp : /LongevitySearchAssets<ID>/writer<ID>/0/1/2/Leve0Level1Level2File0
+     *                              references : /LongevitySearchAssets<ID>/writer<ID>/0/1/3/Leve0Level1Level3File10
+     * }
+     * </pre>
+     */
+    private class BlobWriter extends Writer implements Runnable {
+        BlobWriter(String id, int maxAssets, SynchronizedDescriptiveStatistics writeStats)
+                throws RepositoryException {
+            super(id, maxAssets, writeStats);
+        }
+
+        @Override
+        public void run() {
+            try {
+                int count = 0;
+                while (count < maxAssets) {
+                    session.refresh(false);
+
+                    List<String> levels = Lists.newArrayList();
+                    getParentLevels(count, maxAssets, levels);
+
+                    String fileNamePrefix = getFileNamePrefix(levels);
+                    String parentDir = getParentSuffix(levels);
+
+                    Stopwatch watch = Stopwatch.createStarted();
+
+                    Node file = putFile(fileNamePrefix, parentDir);
+                    session.save();
+
+                    if (stats != null) {
+                        stats.addValue(watch.elapsed(TimeUnit.MILLISECONDS));
+                    }
+
+                    // record for searching and reading
+                    addReadPath(file.getPath());
+                    addSearchPath(fileNamePrefix);
+
+                    if (LOG.isDebugEnabled() && (count + 1) % 1000 == 0) {
+                        LOG.debug("Thread " + id + " - Added assets : " + (count + 1));
+                    }
+                    count++;
+                }
+            } catch (Exception e) {
+                LOG.error("Exception in load creation ", e);
+            }
+        }
+
+        /**
+         * Puts the file at the given path with the given prefix.
+         * 
+         * @param fileNamePrefix the prefix for the filename
+         * @param parentDir the parent dir of the file
+         * @return the node
+         * @throws RepositoryException
+         * @throws UnsupportedRepositoryOperationException
+         * @throws ValueFormatException
+         * @throws VersionException
+         * @throws LockException
+         * @throws ConstraintViolationException
+         */
+        private Node putFile(String fileNamePrefix, String parentDir) throws RepositoryException {
+            Node filepath = JcrUtils.getOrAddNode(parent, parentDir, getParentType());
+            Node file =
+                    JcrUtils.getOrAddNode(filepath,
+                            (fileNamePrefix + "File" + counter++),
+                            getType());
+
+            Binary binary =
+                    parent.getSession().getValueFactory().createBinary(
+                            new TestInputStream(FILE_SIZE * 1024));
+            try {
+                Node content =
+                        JcrUtils.getOrAddNode(file, Node.JCR_CONTENT, NodeType.NT_RESOURCE);
+                if (indexType != null) {
+                    content.addMixin(CUSTOM_INDEX_TYPE);
+                    file.addMixin(CUSTOM_INDEX_TYPE);
+                }
+                content.setProperty(Property.JCR_MIMETYPE, MimeType.randomMimeType().getValue());
+                content.setProperty(Property.JCR_LAST_MODIFIED, Date.randomDate().getCalendar());
+                content.setProperty(Property.JCR_DATA, binary);
+
+                file.setProperty(CUSTOM_PATH_PROP, file.getPath());
+                String reference = getRandomReadPath();
+                if (!Strings.isNullOrEmpty(reference)) {
+                    file.setProperty(CUSTOM_REF_PROP, reference);
+                }
+            } finally {
+                binary.dispose();
+            }
+            return file;
+        }
+
+        /**
+         * Gets the node type of the parent.
+         * 
+         * @return the parent type
+         * @throws RepositoryException the repository exception
+         */
+        protected String getParentType() throws RepositoryException {
+            String type = NodeTypeConstants.NT_UNSTRUCTURED;
+            if (parent.getSession().getWorkspace().getNodeTypeManager().hasNodeType(
+                    NodeTypeConstants.NT_OAK_UNSTRUCTURED)) {
+                type = NodeTypeConstants.NT_OAK_UNSTRUCTURED;
+            }
+            return type;
+        }
+
+        /**
+         * Order of precedence is customNodeType, oak:Unstructured, nt:unstructured
+         * 
+         * @return the type
+         * @throws RepositoryException
+         */
+        protected String getType() throws RepositoryException {
+            String type = NodeTypeConstants.NT_UNSTRUCTURED;
+            if (!context.getMap().containsKey(CTX_FILE_NODE_TYPE_PROP)) {
+                if (getNodeType() != null) {
+                    type = getNodeType();
+                } else if (parent.getSession().getWorkspace().getNodeTypeManager().hasNodeType(
+                        NodeTypeConstants.NT_OAK_UNSTRUCTURED)) {
+                    type = NodeTypeConstants.NT_OAK_UNSTRUCTURED;
+                }
+                context.getMap().put(CTX_FILE_NODE_TYPE_PROP, type);
+            } else {
+                type = (String) context.getMap().get(CTX_FILE_NODE_TYPE_PROP);
+            }
+            return type;
+        }
+
+
+        /**
+         * Create a handy filename to search known files.
+         * 
+         * @param levels the levels for the file
+         * @return the prefix
+         */
+        private String getFileNamePrefix(List<String> levels) {
+            StringBuilder name = new StringBuilder();
+            for (String level : levels) {
+                name.append("Level").append(level);
+            }
+            return name.toString();
+        }
+
+        private String getParentSuffix(List<String> levels) {
+            StringBuilder parentSuffix = new StringBuilder();
+            for (String level : levels) {
+                parentSuffix.append(level).append("/");
+            }
+            return parentSuffix.toString();
+        }
+
+        /**
+         * Assigns the asset to it appropriate folder. The folder hierarchy is constructed such that
+         * each
+         * folder has only MAX_ASSETS_PER_LEVEL children.
+         * 
+         * @param assetNum the asset number
+         * @param maxAssets the max no. of assets to be created
+         * @param levels the no. of levels to create
+         */
+        private void getParentLevels(long assetNum, long maxAssets,
+                List<String> levels) {
+
+            int maxAssetsNextLevel =
+                    (int) Math.ceil((double) maxAssets / (double) MAX_ASSETS_PER_LEVEL);
+            long nextAssetBucket = assetNum / maxAssetsNextLevel;
+
+            levels.add(String.valueOf(nextAssetBucket));
+            if (maxAssetsNextLevel > MAX_ASSETS_PER_LEVEL) {
+                getParentLevels((assetNum - nextAssetBucket * maxAssetsNextLevel),
+                        maxAssetsNextLevel,
+                        levels);
+            }
+        }
+    }
+}
+
diff --git oak-benchmarks-lucene/src/main/java/org/apache/jackrabbit/oak/scalability/suites/ScalabilityNodeRelationshipSuite.java oak-benchmarks-lucene/src/main/java/org/apache/jackrabbit/oak/scalability/suites/ScalabilityNodeRelationshipSuite.java
new file mode 100644
index 0000000..c433ffb
--- /dev/null
+++ oak-benchmarks-lucene/src/main/java/org/apache/jackrabbit/oak/scalability/suites/ScalabilityNodeRelationshipSuite.java
@@ -0,0 +1,554 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ *  or more contributor license agreements.  See the NOTICE file
+ *  distributed with this work for additional information
+ *  regarding copyright ownership.  The ASF licenses this file
+ *  to you under the Apache License, Version 2.0 (the
+ *  "License"); you may not use this file except in compliance
+ *  with the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ *  Unless required by applicable law or agreed to in writing,
+ *  software distributed under the License is distributed on an
+ *  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ *  KIND, either express or implied.  See the License for the
+ *  specific language governing permissions and limitations
+ *  under the License.
+ */
+package org.apache.jackrabbit.oak.scalability.suites;
+
+import java.util.Calendar;
+import java.util.List;
+import java.util.Map;
+import java.util.Random;
+import java.util.UUID;
+
+import javax.jcr.Node;
+import javax.jcr.NodeIterator;
+import javax.jcr.PropertyType;
+import javax.jcr.RepositoryException;
+import javax.jcr.Session;
+
+import com.google.common.collect.ImmutableList;
+import org.apache.commons.math.stat.descriptive.SynchronizedDescriptiveStatistics;
+import org.apache.jackrabbit.api.JackrabbitSession;
+import org.apache.jackrabbit.api.security.user.Authorizable;
+import org.apache.jackrabbit.api.security.user.Group;
+import org.apache.jackrabbit.api.security.user.User;
+import org.apache.jackrabbit.api.security.user.UserManager;
+import org.apache.jackrabbit.commons.JcrUtils;
+import org.apache.jackrabbit.oak.benchmark.util.OakIndexUtils;
+import org.apache.jackrabbit.oak.benchmark.util.OakLuceneIndexUtils;
+import org.apache.jackrabbit.oak.plugins.index.property.OrderedIndex;
+import org.apache.jackrabbit.oak.plugins.index.search.FulltextIndexConstants;
+import org.apache.jackrabbit.oak.spi.nodetype.NodeTypeConstants;
+import org.apache.jackrabbit.oak.scalability.util.NodeTypeUtils;
+import org.apache.jackrabbit.util.Text;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import com.google.common.base.Splitter;
+import com.google.common.base.StandardSystemProperty;
+import com.google.common.collect.Lists;
+import com.google.common.collect.Maps;
+
+/**
+ * The suite test will incrementally increase the load and execute searches.
+ * Each test run thus adds nodes and executes different benchmarks. This way we measure time
+ * taken for benchmark execution.
+ *
+ * <p>
+ * The following system JVM properties can be defined to configure the suite.
+ * <ul>
+ * <li>
+ *     <code>nodeLevels</code> - Comma separated string property that governs the number of number of
+ *     different node relationships in the following order:
+ *      <ul>
+ *          <li>Users</li>
+ *          <li>Groups</li>
+ *          <li>User Relationships</li>
+ *          <li>Activities</li>
+ *      </ul>
+ *
+ *     Defaults to 10,5,2,1.
+ * </li>
+ * </ul>
+ *
+ */
+public class ScalabilityNodeRelationshipSuite extends ScalabilityNodeSuite {
+    private static final Logger LOG =
+        LoggerFactory.getLogger(ScalabilityNodeRelationshipSuite.class);
+
+    public static final String CUSTOM_ACT_NODE_TYPE = "ActivityType";
+
+    public static final String CUSTOM_REL_NODE_TYPE = "RelationshipType";
+
+    public static final String ACTIVITIES = "Activities";
+
+    public static final String RELATIONSHIPS = "Relationships";
+
+    /**
+     * Node properties
+     */
+    public static final String CTX_USER = "User";
+    public static final String CTX_GROUP = "Group";
+    public static final String CREATED = "jcr:created";
+    public static final String SOURCE_ID = "sourceId";
+    public static final String TARGET_ID = "targetId";
+    public static final String ACTION = "action";
+    public static final String SOURCE = "source";
+    public static final String OBJECT = "object";
+    public static final String OBJECT_ID = "objectId";
+    public static final String TARGET = "target";
+
+    protected static final List<String> NODE_LEVELS = Splitter.on(",").trimResults()
+        .omitEmptyStrings().splitToList(System.getProperty("nodeLevels", "10,5,2,1"));
+
+    protected static final List<String> NODE_LEVELS_DEFAULT = ImmutableList.of("10","5","2","1");
+
+    private static final int NUM_USERS =
+        (NODE_LEVELS.size() >= 1 ? Integer.parseInt(NODE_LEVELS.get(0)) : Integer.parseInt(NODE_LEVELS_DEFAULT.get(0)));
+
+    private static final int NUM_GROUPS =
+        (NODE_LEVELS.size() >= 2 ? Integer.parseInt(NODE_LEVELS.get(1)) : Integer.parseInt(NODE_LEVELS_DEFAULT.get(1)));
+
+    private static final int NUM_RELATIONSHIPS =
+        (NODE_LEVELS.size() >= 3 ? Integer.parseInt(NODE_LEVELS.get(2)) : Integer.parseInt(NODE_LEVELS_DEFAULT.get(2)));
+
+    private static final int NUM_ACTIVITIES =
+        (NODE_LEVELS.size() >= 4 ? Integer.parseInt(NODE_LEVELS.get(3)) : Integer.parseInt(NODE_LEVELS_DEFAULT.get(3)));
+
+
+    private static final long BUCKET_SIZE = 100;
+
+    private static final List<String> actions = Lists
+        .newArrayList("act1", "act2", "act3", "act4", "act5", "act6", "act7", "act8", "act9",
+            "act10");
+    private static final List<String> objects = Lists
+        .newArrayList("obj1", "obj2", "obj3", "obj4", "obj5", "obj6", "obj7", "obj8", "obj9",
+            "obj10");
+
+    private final Random random = new Random(29);
+
+    private List<Authorizable> users;
+    private List<Authorizable> groups;
+
+    public ScalabilityNodeRelationshipSuite(Boolean storageEnabled) {
+        super(storageEnabled);
+    }
+
+    @Override
+    protected void beforeSuite() throws Exception {
+        Session session = loginWriter();
+        Node root = session.getRootNode();
+        root.addNode(ROOT_NODE_NAME);
+        session.save();
+
+        users = Lists.newArrayList();
+        groups = Lists.newArrayList();
+
+        if (CUSTOM_TYPE) {
+            NodeTypeUtils.createNodeType(session, CUSTOM_ACT_NODE_TYPE,
+                new String[] {TITLE_PROP, CREATED, ACTION, SOURCE_ID},
+                new int[] {PropertyType.STRING, PropertyType.DATE, PropertyType.STRING,
+                    PropertyType.STRING}, new String[0],
+                new String[] {NodeTypeConstants.NT_OAK_UNSTRUCTURED}, null, false);
+            NodeTypeUtils.createNodeType(session, CUSTOM_REL_NODE_TYPE,
+                new String[] {CREATED, SOURCE_ID, TARGET_ID},
+                new int[] {PropertyType.DATE, PropertyType.STRING, PropertyType.STRING},
+                new String[0], null, null, false);
+            nodeTypes.add(CUSTOM_ACT_NODE_TYPE);
+            nodeTypes.add(CUSTOM_REL_NODE_TYPE);
+        }
+
+        if (INDEX) {
+            createIndexes(session);
+        }
+    }
+
+    protected void createIndexes(Session session) throws RepositoryException {
+        Map<String, Map<String, String>> orderedMap = Maps.newHashMap();
+        String persistencePath = "";
+
+        // define indexes on properties
+        switch (INDEX_TYPE) {
+            case PROPERTY:
+                OakIndexUtils.propertyIndexDefinition(session, "customIndexActivity",
+                    new String[] {SOURCE_ID}, false,
+                    (!CUSTOM_TYPE ? new String[0] : new String[] {CUSTOM_ACT_NODE_TYPE}));
+                OakIndexUtils.propertyIndexDefinition(session, "customIndexRelationship",
+                    new String[] {SOURCE_ID}, false,
+                    (!CUSTOM_TYPE ? new String[0] : new String[] {CUSTOM_REL_NODE_TYPE}));
+                break;
+            // define ordered indexes on properties
+            case ORDERED:
+                OakIndexUtils.orderedIndexDefinition(session, "customIndexActivity", ASYNC_INDEX,
+                    new String[] {CREATED}, false,
+                    (!CUSTOM_TYPE ? new String[0] : new String[] {CUSTOM_ACT_NODE_TYPE}),
+                    OrderedIndex.OrderDirection.DESC.getDirection());
+                OakIndexUtils
+                    .orderedIndexDefinition(session, "customIndexRelationship", ASYNC_INDEX,
+                        new String[] {CREATED}, false,
+                        (!CUSTOM_TYPE ? new String[0] : new String[] {CUSTOM_REL_NODE_TYPE}),
+                        OrderedIndex.OrderDirection.DESC.getDirection());
+                break;
+            // define lucene index on properties
+            case LUCENE_FILE:
+                persistencePath =
+                    "target" + StandardSystemProperty.FILE_SEPARATOR.value() + "lucene" + String
+                        .valueOf(System.currentTimeMillis());
+                OakLuceneIndexUtils.luceneIndexDefinition(session, "customIndexActivity", ASYNC_INDEX,
+                        new String[]{SOURCE_ID, CREATED},
+                        new String[]{PropertyType.TYPENAME_STRING, PropertyType.TYPENAME_DATE},
+                        orderedMap, persistencePath);
+                break;
+            case LUCENE_FILE_DOC:
+                persistencePath =
+                    "target" + StandardSystemProperty.FILE_SEPARATOR.value() + "lucene" + String
+                        .valueOf(System.currentTimeMillis());
+            case LUCENE_DOC:
+                Map<String, String> propMap = Maps.newHashMap();
+                propMap.put(FulltextIndexConstants.PROP_TYPE, PropertyType.TYPENAME_DATE);
+                orderedMap.put(CREATED, propMap);
+            case LUCENE:
+                OakLuceneIndexUtils.luceneIndexDefinition(session, "customIndexActivity", ASYNC_INDEX,
+                    new String[] {SOURCE_ID, CREATED},
+                    new String[] {PropertyType.TYPENAME_STRING, PropertyType.TYPENAME_DATE},
+                    orderedMap, persistencePath);
+                break;
+        }
+    }
+
+    /**
+     * Executes before each test run
+     */
+    @Override
+    public void beforeIteration(ExecutionContext context) throws RepositoryException {
+        if (LOG.isDebugEnabled()) {
+            LOG.debug("Started beforeIteration()");
+        }
+
+        // Contextualize the node types being used
+        if (nodeTypes != null && !nodeTypes.isEmpty()) {
+            context.getMap().put(CTX_ACT_NODE_TYPE_PROP, nodeTypes.get(0));
+            context.getMap().put(CTX_REL_NODE_TYPE_PROP, nodeTypes.get(1));
+        }
+
+        Session session = loginWriter();
+        UserManager userMgr = ((JackrabbitSession) session).getUserManager();
+
+        context.getMap().put("PREV_ITER_USERS", users.size());
+
+        // Create Users and Groups based on the load for this iteration (cumulatively)
+        // Add users
+        for (int idx = 0; idx < NUM_USERS * context.getIncrement(); idx++) {
+            String name = String.valueOf((char) (random.nextInt(26) + 'a')) + CTX_USER + context
+                .getIncrement() + "_" + idx;
+            User user = userMgr.createUser(name, name);
+            LOG.debug("User created : " + name);
+            users.add(user);
+        }
+
+        // Add groups and include random number of members
+        for (int idx = 0; idx < NUM_GROUPS * context.getIncrement(); idx++) {
+            String name = String.valueOf((char) (random.nextInt(26) + 'a')) + CTX_GROUP + context
+                .getIncrement() + idx;
+            Group group = userMgr.createGroup(name);
+            groups.add(group);
+            int groupMembers = random.nextInt(users.size());
+            for (int i = 0; i < groupMembers; i++) {
+                group.addMember(users.get(random.nextInt(users.size())));
+            }
+        }
+        session.save();
+        // create the load for this iteration
+        createLoad(context);
+        long loadFinish = System.currentTimeMillis();
+
+        context.getMap().put(CTX_ROOT_NODE_NAME_PROP, ROOT_NODE_NAME);
+        context.getMap().put(CTX_USER, users);
+        context.getMap().put(CTX_GROUP, groups);
+
+        waitBeforeIterationFinish(loadFinish);
+
+        if (LOG.isDebugEnabled()) {
+            LOG.debug("Finished beforeIteration()");
+        }
+    }
+
+    @Override
+    protected Writer getWriter(ExecutionContext context,
+        SynchronizedDescriptiveStatistics writeStats, int idx) throws RepositoryException {
+        int numUsers = (context.getIncrement() * NUM_USERS) / LOADERS;
+        return new ActivityWriter((context.getIncrement() + "-" + idx), numUsers, idx * numUsers,
+            writeStats);
+    }
+
+    /**
+     * The users are created with the nomenclature {@code [a-z]User<INCREMENT>_<ID>}
+     *
+     * <p>
+     *
+     * Creates a node hierarchy similar to the node structure below.
+     * Here for example aUser0_1 and cUser0_5 are 2 users and aUser0_1 has a relationship structure to user cUser0_5.
+     *
+     * <pre>
+     * {@code
+     * /home
+     *  /a
+     *      /aUser0_1
+     *          /Relationships
+     *              /cUser0_5
+     *                  jcr:primaryType : <oak:Unstructured|descendantType|nt:unstructured>
+     *                  jcr:created : <DATE>
+     *                  sourceId : aUser0_1
+     *                  targetId : cUser0_5
+     *          /Activities
+     *             /2015
+     *                 /06
+     *                     /03
+     *                         /@1
+     *                             /<UUID>
+     *                                 jcr:primaryType : <oak:Unstructured|descendantType|nt:unstructured>
+     *                                 title : <sourceId targetId>
+     *                                 action : <act*>
+     *                                 sourceId : aUser0_1
+     *                                 /source
+     *                                     sourceId : aUser0_1
+     *                                 /object
+     *                                     objectId: <obj*>
+     *                                 /target
+     *                                     targetId: cUser0_5
+     * }
+     * </pre>
+     * </p>
+     */
+    class ActivityWriter extends Writer {
+        private int startIdx;
+
+        ActivityWriter(String id, int numUsers, int startIdx,
+            SynchronizedDescriptiveStatistics writeStats) throws RepositoryException {
+            super(id, numUsers, writeStats);
+            this.startIdx = startIdx;
+        }
+
+        @Override
+        public void run() {
+            try {
+                int idx = startIdx;
+                while (idx < (maxAssets + startIdx)) {
+                    session.refresh(false);
+
+                    // Current User
+                    int userIdx = (Integer) context.getMap().get("PREV_ITER_USERS") + idx;
+                    Authorizable user = users.get(userIdx);
+
+                    Node activitiesParentNode = JcrUtils
+                        .getOrAddNode(session.getNode(user.getPath()), ACTIVITIES,
+                            NodeTypeConstants.NT_OAK_UNSTRUCTURED);
+                    Node relationshipsParentNode = JcrUtils
+                        .getOrAddNode(session.getNode(user.getPath()), RELATIONSHIPS,
+                            NodeTypeConstants.NT_OAK_UNSTRUCTURED);
+                    createRelationships(user, relationshipsParentNode, activitiesParentNode);
+                    createActivities(user, activitiesParentNode);
+
+                    if ((counter + 1) % 100 == 0) {
+                        LOG.info("Thread " + id + " - Processed Users : " + (counter + 1));
+                    }
+                    idx++;
+                    counter++;
+                }
+            } catch (Exception e) {
+                LOG.error("Exception in load creation ", e);
+            }
+        }
+
+        /**
+         * Create activities for a use. The number of activities is governed by
+         * {# NODE_LEVELS.get(3)}
+         *
+         * @param user                 the user for who activities are to be created
+         * @param activitiesParentNode the parent node for all the user activities
+         * @throws RepositoryException
+         */
+        private void createActivities(Authorizable user, Node activitiesParentNode)
+            throws RepositoryException {
+            for (int i = 0; i < NUM_ACTIVITIES; i++) {
+                timer.start();
+
+                createActivity(activitiesParentNode, user.getID() + " " + i,
+                    actions.get(random.nextInt(actions.size())), user.getID(),
+                    objects.get(random.nextInt(objects.size())),
+                    objects.get(random.nextInt(objects.size())));
+
+                session.save();
+
+                // Record time taken for creation
+                timer.stop();
+            }
+        }
+
+        private void createActivity(Node activitiesParentNode, String title,
+                                    String action, String source, String object, String target) throws RepositoryException {
+            Node activityNode = getActivityParentNode(activitiesParentNode);
+
+            Map<String, String> activityMap = Maps.newHashMap();
+            activityMap.put(TITLE_PROP, title);
+            activityMap.put(ACTION, action);
+            activityMap.put(SOURCE_ID, source);
+            activityMap.put(OBJECT_ID, object);
+            activityMap.put(TARGET_ID, target);
+
+            createActivityNode(activityNode, activityMap);
+        }
+
+        /**
+         * Creates the activity node structure.
+         */
+        private void createActivityNode(Node activityParent, Map<String, String> props)
+            throws RepositoryException {
+            activityParent.setProperty(TITLE_PROP, props.get(TITLE_PROP));
+            activityParent.setProperty(CREATED, generateDate());
+            activityParent.setProperty(ACTION, props.get(ACTION));
+            activityParent.setProperty(SOURCE_ID, props.get(SOURCE_ID));
+            Node sourceNode = JcrUtils
+                .getOrAddNode(activityParent, SOURCE, NodeTypeConstants.NT_OAK_UNSTRUCTURED);
+            sourceNode.setProperty(SOURCE_ID, props.get(SOURCE_ID));
+
+            Node objNode = JcrUtils
+                .getOrAddNode(activityParent, OBJECT, NodeTypeConstants.NT_OAK_UNSTRUCTURED);
+            objNode.setProperty(OBJECT_ID, props.get(OBJECT_ID));
+
+            Node targetNode = JcrUtils
+                .getOrAddNode(activityParent, TARGET, NodeTypeConstants.NT_OAK_UNSTRUCTURED);
+            targetNode.setProperty(TARGET_ID, props.get(TARGET_ID));
+
+            LOG.debug(
+                "Activity created for User : " + props.get(SOURCE_ID) + " " + activityParent.getPath());
+        }
+
+        /**
+         * Creates bucketed parent node for the activity.
+         */
+        private Node getActivityParentNode(Node activitiesParentNode) throws RepositoryException {
+            Calendar c = Calendar.getInstance();
+            Node yearNode = JcrUtils
+                .getOrAddNode(activitiesParentNode, String.valueOf(c.get(Calendar.YEAR)),
+                    NodeTypeConstants.NT_OAK_UNSTRUCTURED);
+            String month = String.valueOf(c.get(Calendar.MONTH) + 1);
+            month = month.length() > 1 ? month : "0" + month;
+            Node monthNode =
+                JcrUtils.getOrAddNode(yearNode, month, NodeTypeConstants.NT_OAK_UNSTRUCTURED);
+            String day = String.valueOf(c.get(Calendar.DATE));
+            day = day.length() > 1 ? day : "0" + day;
+            Node dayNode =
+                JcrUtils.getOrAddNode(monthNode, day, NodeTypeConstants.NT_OAK_UNSTRUCTURED);
+
+            // find bucket
+            Node parentNode = dayNode;
+            NodeIterator iterator = dayNode.getNodes();
+            long size = iterator.getSize();
+            if (size < 0 || size > BUCKET_SIZE) {
+                size = 0;
+                int maxNum = -1;
+                while (iterator.hasNext()) {
+                    size++;
+                    Node child = iterator.nextNode();
+                    String name = child.getName();
+                    if (name.charAt(0) == '@') {
+                        int buckNum = Integer.parseInt(name.substring(1));
+                        if (buckNum > maxNum) {
+                            maxNum = buckNum;
+                            parentNode = child;
+                        }
+                    }
+                }
+                if (size > BUCKET_SIZE) {
+                    // check if last bucket has enough space
+                    if (maxNum < 0 || numChildNodes(parentNode) >= BUCKET_SIZE) {
+                        parentNode = dayNode.addNode("@" + String.valueOf(maxNum + 1),
+                            NodeTypeConstants.NT_OAK_UNSTRUCTURED);
+                    }
+                }
+            }
+            // create activity node
+            return JcrUtils
+                .getOrCreateUniqueByPath(parentNode, UUID.randomUUID().toString(), getType(0));
+        }
+
+        private long numChildNodes(Node node) throws RepositoryException {
+            NodeIterator iterator = node.getNodes();
+            if (iterator.getSize() >= 0) {
+                return iterator.getSize();
+            } else {
+                int num = 0;
+                while (iterator.hasNext() && num < BUCKET_SIZE) {
+                    iterator.nextNode();
+                    num++;
+                }
+                return num;
+            }
+        }
+
+        /**
+         * Create relationships to other users. The number of relationships is governed by
+         * {# NODE_LEVELS.get(2)}
+         *
+         * @param user                    the source user of the relationships
+         * @param relationshipsParentNode the node where the relationships are recorded  @throws
+         *                                RepositoryException
+         * @param activitiesParentNode the parent node for all the user activities
+         */
+        private void createRelationships(Authorizable user, Node relationshipsParentNode,
+            Node activitiesParentNode) throws RepositoryException {
+            List<Integer> usersIdx = Lists.newArrayList();
+            for (int count = 0; count < users.size(); count++) {
+                usersIdx.add(count);
+            }
+
+            for (int i = 0; i < NUM_RELATIONSHIPS; i++) {
+                if (usersIdx.size() > 0) {
+                    String otherUser =
+                        users.get(usersIdx.remove(random.nextInt(usersIdx.size()))).getID();
+                    timer.start();
+
+                    String nameHint = Text.getName(otherUser);
+                    Node rNode = relationshipsParentNode.addNode(nameHint, getType(1));
+                    rNode.setProperty(CREATED, generateDate());
+                    rNode.setProperty(SOURCE_ID, user.getID());
+                    rNode.setProperty(TARGET_ID, otherUser);
+
+                    LOG.debug(
+                        "Relationship created for User : " + user.getID() + " " + rNode.getPath());
+                    createActivity(activitiesParentNode, user.getID() + " " + otherUser,
+                        actions.get(random.nextInt(actions.size())), user.getID(),
+                        objects.get(random.nextInt(objects.size())), otherUser);
+
+                    session.save();
+
+                    timer.stop();
+                }
+            }
+        }
+
+        /**
+         * Order of precedence is custom type or oak:Unstructured
+         *
+         * @return the type
+         * @throws RepositoryException the repository exception
+         */
+        protected String getType(int typeIdx) throws RepositoryException {
+            String typeOfNode = (typeIdx == 0 ? CTX_ACT_NODE_TYPE_PROP : CTX_REL_NODE_TYPE_PROP);
+
+            String type = NodeTypeConstants.NT_OAK_UNSTRUCTURED;
+            if (context.getMap().containsKey(typeOfNode)) {
+                type = (String) context.getMap().get(typeOfNode);
+            } else {
+                context.getMap().put(typeOfNode, type);
+            }
+            return type;
+        }
+    }
+}
+
diff --git oak-benchmarks-lucene/src/main/java/org/apache/jackrabbit/oak/scalability/suites/ScalabilityNodeSuite.java oak-benchmarks-lucene/src/main/java/org/apache/jackrabbit/oak/scalability/suites/ScalabilityNodeSuite.java
new file mode 100644
index 0000000..4c5f8a6
--- /dev/null
+++ oak-benchmarks-lucene/src/main/java/org/apache/jackrabbit/oak/scalability/suites/ScalabilityNodeSuite.java
@@ -0,0 +1,697 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ *  or more contributor license agreements.  See the NOTICE file
+ *  distributed with this work for additional information
+ *  regarding copyright ownership.  The ASF licenses this file
+ *  to you under the Apache License, Version 2.0 (the
+ *  "License"); you may not use this file except in compliance
+ *  with the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ *  Unless required by applicable law or agreed to in writing,
+ *  software distributed under the License is distributed on an
+ *  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ *  KIND, either express or implied.  See the License for the
+ *  specific language governing permissions and limitations
+ *  under the License.
+ */
+package org.apache.jackrabbit.oak.scalability.suites;
+
+import static com.google.common.collect.Lists.newArrayList;
+import static com.google.common.collect.Lists.newArrayListWithCapacity;
+
+import java.util.Calendar;
+import java.util.List;
+import java.util.Map;
+import java.util.Random;
+import java.util.TimeZone;
+import java.util.concurrent.TimeUnit;
+
+import javax.jcr.Node;
+import javax.jcr.PropertyType;
+import javax.jcr.Repository;
+import javax.jcr.RepositoryException;
+import javax.jcr.Session;
+
+import com.google.common.base.Splitter;
+import com.google.common.base.StandardSystemProperty;
+import com.google.common.base.Stopwatch;
+import com.google.common.base.Strings;
+import com.google.common.collect.Maps;
+
+import org.apache.commons.math.stat.descriptive.SynchronizedDescriptiveStatistics;
+import org.apache.jackrabbit.commons.JcrUtils;
+import org.apache.jackrabbit.oak.Oak;
+import org.apache.jackrabbit.oak.api.jmx.IndexStatsMBean;
+import org.apache.jackrabbit.oak.benchmark.util.OakIndexUtils;
+import org.apache.jackrabbit.oak.benchmark.util.OakLuceneIndexUtils;
+import org.apache.jackrabbit.oak.fixture.JcrCreator;
+import org.apache.jackrabbit.oak.fixture.OakRepositoryFixture;
+import org.apache.jackrabbit.oak.fixture.RepositoryFixture;
+import org.apache.jackrabbit.oak.jcr.Jcr;
+import org.apache.jackrabbit.oak.plugins.index.IndexConstants;
+import org.apache.jackrabbit.oak.plugins.index.lucene.LuceneIndexEditorProvider;
+import org.apache.jackrabbit.oak.plugins.index.lucene.LuceneIndexProvider;
+import org.apache.jackrabbit.oak.plugins.index.lucene.util.LuceneInitializerHelper;
+import org.apache.jackrabbit.oak.plugins.index.property.OrderedIndex;
+import org.apache.jackrabbit.oak.plugins.index.search.FulltextIndexConstants;
+import org.apache.jackrabbit.oak.scalability.ScalabilitySuite;
+import org.apache.jackrabbit.oak.spi.nodetype.NodeTypeConstants;
+import org.apache.jackrabbit.oak.scalability.benchmarks.ScalabilityBenchmark;
+import org.apache.jackrabbit.oak.scalability.util.NodeTypeUtils;
+import org.apache.jackrabbit.oak.spi.commit.Observer;
+import org.apache.jackrabbit.oak.spi.query.QueryIndexProvider;
+import org.apache.jackrabbit.oak.spi.whiteboard.Whiteboard;
+import org.apache.jackrabbit.oak.spi.whiteboard.WhiteboardUtils;
+import org.apache.jackrabbit.util.ISO8601;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+/**
+ * The suite test will incrementally increase the load and execute searches.
+ * Each test run thus adds nodes and executes different benchmarks. This way we measure time taken for
+ * benchmark execution.
+ *
+ * <p>
+ * The following system JVM properties can be defined to configure the suite.
+ * <ul>
+ * <li>
+ *     <code>loaders</code> - Controls the number of concurrent threads for loading blobs initially.
+ *     Defaults to 1.
+ * </li>
+ * <li>
+ *     <code>testers</code> - Controls the number of concurrent tester threads. Defaults to 1.
+ * </li>
+ * <li>
+ *     <code>nodeLevels</code> - Comma separated string property that governs the depth and the number of
+ *     nodes in the hierarchy. Defaults to 10, 5, 2.
+ * </li>
+ * <li>
+ *     <code>densityLevel</code> - Controls the percentage of root nodes which will have sub nodes created.
+ *     Defaults to 100.
+ * </li>
+ * <li>
+ *     <code>index</code> - Controls if the index definitions are to be created. Defaults to false.
+ * </li>
+ * <li>
+ *      <code>asyncIndex</code> - Controls whether the indexing is async. Defaults to false.
+ * </li>
+ * <li>
+ *     <code>noFullIndex</code> - Controls whether fulltext indexing is enabled or disabled. Defaults to false.
+ * </li>
+ * <li>
+ *     <code>randDate</code> - Controls whether to generate random dates in a range. Defaults to false.
+ * </li>
+ * <li>
+ *     <code>customType</code> - Controls if nodes created in the load have a custom node type. Defaults to false.
+ * </li>
+ * </ul>
+ *
+ */
+public class ScalabilityNodeSuite extends ScalabilityAbstractSuite {
+    protected static final Logger LOG = LoggerFactory.getLogger(ScalabilityNodeSuite.class);
+
+    /**
+     * Controls the number of concurrent threads for loading blobs initially
+     */
+    protected static final int LOADERS = Integer.getInteger("loaders", 1);
+
+    /**
+     * Controls the number of nodes at each level
+     */
+    protected static final List<String> NODE_LEVELS = Splitter.on(",").trimResults()
+            .omitEmptyStrings().splitToList(System.getProperty("nodeLevels", "10,5,2"));
+
+    /**
+     * Controls the number of concurrent tester threads
+     */
+    protected static final int TESTERS = Integer.getInteger("testers", 1);
+
+    /**
+     * Controls the percentage of root nodes which will have sub nodes created.
+     * Value ranges from [0, 100]
+     */
+    protected static final int DENSITY_LEVEL = Integer.getInteger("densityLevel", 100);
+
+    /**
+     * Controls if the index definitions are to be created.
+     */
+    protected static final boolean INDEX = Boolean.getBoolean("index");
+
+    /**
+     * Controls whether the indexing is async
+     */
+    protected static final String ASYNC_INDEX = System.getProperty("asyncIndex");
+
+    /**
+     * Controls whether fulltext indexing is enabled or disabled. Enabled by default.
+     */
+    protected static final boolean FULL_TEXT = !Boolean.getBoolean("noFullIndex");
+
+    /**
+     * Controls whether to generate random dates in a range
+     */
+    protected static final boolean RAND_DATE = Boolean.getBoolean("randDate");
+
+    /**
+     * Controls if a customType is to be created
+     */
+    protected static final boolean CUSTOM_TYPE = Boolean.getBoolean("customType");
+
+    public static final String CTX_DESC_SEARCH_PATHS_PROP = "descPaths";
+
+    public static final String CTX_ROOT_NODE_NAME_PROP = "rootNodeName";
+
+    public static final String CTX_ACT_NODE_TYPE_PROP = "rootType";
+
+    public static final String CTX_REL_NODE_TYPE_PROP = "descendantType";
+
+    public static final String CUSTOM_ROOT_NODE_TYPE = "ParentType";
+
+    public static final String CUSTOM_DESC_NODE_TYPE = "DescendantType";
+
+    public static final String DATE_PROP = "added";
+
+    public static final String CTX_PAGINATION_KEY_PROP = DATE_PROP;
+
+    public static final String FILTER_PROP = "filter";
+
+    public static final String SORT_PROP = "viewed";
+
+    public static final String TITLE_PROP = "title";
+
+    public static final String ROOT_NODE_NAME =
+            "LongevitySearchAssets" + TEST_ID;
+
+    public enum Index {
+        PROPERTY, ORDERED, LUCENE, LUCENE_DOC, LUCENE_FILE, LUCENE_FILE_DOC
+    }
+
+    /** Type of index to be created */
+    public final Index INDEX_TYPE =
+        Index.valueOf(System.getProperty("indexType", Index.PROPERTY.toString()));
+
+    protected final Boolean storageEnabled;
+
+    protected Whiteboard whiteboard;
+
+    protected final List<String> nodeTypes;
+
+    private final Random random = new Random(29);
+
+    private List<String> searchRootPaths;
+
+    private List<String> searchDescPaths;
+
+    public ScalabilityNodeSuite(Boolean storageEnabled) {
+        this.storageEnabled = storageEnabled;
+        this.nodeTypes = newArrayList();
+    }
+
+    @Override
+    public ScalabilitySuite addBenchmarks(ScalabilityBenchmark... tests) {
+        for (ScalabilityBenchmark test : tests) {
+            benchmarks.put(test.toString(), test);
+        }
+        return this;
+    }
+
+    @Override
+    protected void beforeSuite() throws Exception {
+        Session session = loginWriter();
+        Node root = session.getRootNode();
+        root.addNode(ROOT_NODE_NAME);
+        session.save();
+
+        if (CUSTOM_TYPE) {
+            NodeTypeUtils.createNodeType(session, CUSTOM_DESC_NODE_TYPE,
+                    new String[] {DATE_PROP, SORT_PROP, FILTER_PROP, TITLE_PROP},
+                    new int[] {PropertyType.DATE, PropertyType.BOOLEAN, PropertyType.STRING,
+                            PropertyType.STRING},
+                    new String[0], new String[] {CUSTOM_DESC_NODE_TYPE}, null, false);
+            NodeTypeUtils.createNodeType(session, CUSTOM_ROOT_NODE_TYPE,
+                    new String[] {DATE_PROP, SORT_PROP, FILTER_PROP, TITLE_PROP},
+                    new int[] {PropertyType.DATE, PropertyType.BOOLEAN, PropertyType.STRING,
+                            PropertyType.STRING},
+                    new String[0], new String[] {CUSTOM_DESC_NODE_TYPE}, null, false);
+            nodeTypes.add(CUSTOM_ROOT_NODE_TYPE);
+            nodeTypes.add(CUSTOM_DESC_NODE_TYPE);
+        }
+
+        if (INDEX) {
+            createIndexes(session);
+        }
+    }
+
+    protected void createIndexes(Session session) throws RepositoryException {
+        Map<String, Map<String, String>> orderedMap = Maps.newHashMap();
+        String persistencePath = "";
+
+        switch (INDEX_TYPE) {
+            case ORDERED:
+                // define ordered indexes on properties
+                OakIndexUtils.orderedIndexDefinition(session, "customIndexParent", ASYNC_INDEX,
+                    new String[] {DATE_PROP}, false,
+                    (nodeTypes.isEmpty() ? new String[0] : new String[] {nodeTypes.get(0)}),
+                    OrderedIndex.OrderDirection.DESC.getDirection());
+                OakIndexUtils.orderedIndexDefinition(session, "customIndexDescendant", ASYNC_INDEX,
+                        new String[]{DATE_PROP}, false,
+                        (nodeTypes.isEmpty() ? new String[0]: new String[] {nodeTypes.get(1)}),
+                        OrderedIndex.OrderDirection.DESC.getDirection());
+                break;
+            // define lucene index on properties
+            case LUCENE_FILE:
+                persistencePath =
+                    "target" + StandardSystemProperty.FILE_SEPARATOR.value() + "lucene" + String
+                        .valueOf(System.currentTimeMillis());
+                OakLuceneIndexUtils.luceneIndexDefinition(session, "customIndex", ASYNC_INDEX,
+                        new String[]{FILTER_PROP, DATE_PROP},
+                        new String[]{PropertyType.TYPENAME_STRING, PropertyType.TYPENAME_DATE},
+                        null, persistencePath);
+                break;
+            case LUCENE_FILE_DOC:
+                persistencePath =
+                    "target" + StandardSystemProperty.FILE_SEPARATOR.value() + "lucene" + String
+                        .valueOf(System.currentTimeMillis());
+            case LUCENE_DOC:
+                Map<String, String> propMap = Maps.newHashMap();
+                propMap.put(FulltextIndexConstants.PROP_TYPE, PropertyType.TYPENAME_DATE);
+                orderedMap.put(DATE_PROP, propMap);
+            case LUCENE:
+                OakLuceneIndexUtils.luceneIndexDefinition(session, "customIndex", ASYNC_INDEX,
+                    new String[] {FILTER_PROP, DATE_PROP},
+                    new String[] {PropertyType.TYPENAME_STRING, PropertyType.TYPENAME_DATE},
+                    orderedMap, persistencePath);
+                break;
+            case PROPERTY:
+                break;
+        }
+    }
+
+    /**
+     * Executes before each test run
+     */
+    @Override
+    public void beforeIteration(ExecutionContext context) throws RepositoryException {
+        if (LOG.isDebugEnabled()) {
+            LOG.debug("Started beforeIteration()");
+        }
+
+        // Contextualize the node types being used
+        if (nodeTypes != null && !nodeTypes.isEmpty()) {
+            context.getMap().put(CTX_ACT_NODE_TYPE_PROP, nodeTypes.get(0));
+            context.getMap().put(CTX_REL_NODE_TYPE_PROP, nodeTypes.get(1));
+        }
+
+        // recreate paths created in this run
+        searchRootPaths = newArrayList();
+        searchDescPaths = newArrayList();
+
+        // create the blob load for this iteration
+        createLoad(context);
+        long loadFinish = System.currentTimeMillis();
+
+        context.getMap().put(CTX_ROOT_NODE_NAME_PROP, ROOT_NODE_NAME);
+        context.getMap().put(CTX_SEARCH_PATHS_PROP, searchRootPaths);
+        context.getMap().put(CTX_DESC_SEARCH_PATHS_PROP, searchDescPaths);
+
+        waitBeforeIterationFinish(loadFinish);
+
+        if (LOG.isDebugEnabled()) {
+            LOG.debug("Finished beforeIteration()");
+        }
+    }
+
+    protected void waitBeforeIterationFinish(long loadFinish) {
+        IndexStatsMBean indexStatsMBean = WhiteboardUtils.getService(whiteboard, IndexStatsMBean.class);
+
+        if (indexStatsMBean != null) {
+            String lastIndexedTime = indexStatsMBean.getLastIndexedTime();
+            while (((lastIndexedTime == null)
+                || ISO8601.parse(lastIndexedTime).getTimeInMillis() < loadFinish)) {
+                try {
+                    if (LOG.isDebugEnabled()) {
+                        LOG.debug("Waiting for async indexing to finish");
+                    }
+                    Thread.sleep(5000);
+                } catch (InterruptedException e) {
+                    LOG.error("Error waiting for async index to finish", e);
+                }
+                lastIndexedTime = indexStatsMBean.getLastIndexedTime();
+            }
+
+            LOG.info("Execution Count {}", indexStatsMBean.getExecutionCount());
+            LOG.info("Execution Time {}", indexStatsMBean.getExecutionTime());
+            LOG.info("Consolidated Execution Stats {}", indexStatsMBean.getConsolidatedExecutionStats());
+        }
+    }
+
+    /**
+     * Creates the load for the search.
+     *
+     * @param context the context
+     * @throws RepositoryException the repository exception
+     */
+    protected void createLoad(ExecutionContext context) throws RepositoryException {
+        // Creates assets for this run
+
+        SynchronizedDescriptiveStatistics writeStats = new SynchronizedDescriptiveStatistics();
+
+        List<Thread> loadThreads = newArrayList();
+        for (int idx = 0; idx < LOADERS; idx++) {
+            /* Each loader will write to a directory of the form load-idx */
+            Thread t =
+                    new Thread(getWriter(context, writeStats, idx),
+                            "LoadThread-" + idx);
+            loadThreads.add(t);
+            t.start();
+        }
+
+        // wait for the load threads to finish
+        for (Thread t : loadThreads) {
+            try {
+                t.join();
+            } catch (InterruptedException e) {
+                LOG.error("Exception waiting for join ", e);
+            }
+        }
+        
+        LOG.info("Write stats");
+        LOG.info(String.format(
+            "# min     10%%     50%%     90%%     max       N%n"));
+        LOG.info(String.format(
+            "%6.0f  %6.0f  %6.0f  %6.0f  %6.0f  %6d%n",
+            writeStats.getMin(),
+            writeStats.getPercentile(10.0),
+            writeStats.getPercentile(50.0),
+            writeStats.getPercentile(90.0),
+            writeStats.getMax(),
+            writeStats.getN()));
+    }
+
+    protected Writer getWriter(ExecutionContext context,
+            SynchronizedDescriptiveStatistics writeStats, int idx) throws RepositoryException {
+        return new Writer((context.getIncrement() + "-" + idx),
+                (context.getIncrement() * Integer.parseInt(NODE_LEVELS.get(0)))
+                        / LOADERS,
+                writeStats);
+    }
+
+    @Override
+    protected void executeBenchmark(final ScalabilityBenchmark benchmark,
+            final ExecutionContext context) throws Exception {
+
+        LOG.info("Started pre benchmark hook : {}", benchmark);
+        benchmark.beforeExecute(getRepository(), CREDENTIALS, context);
+
+        LOG.info("Started execution : {}", benchmark);
+        if (PROFILE) {
+            context.startProfiler();
+        }
+        //Execute the benchmark with the number threads configured 
+        List<Thread> threads = newArrayListWithCapacity(TESTERS);
+        for (int idx = 0; idx < TESTERS; idx++) {
+            Thread t = new Thread("Tester-" + idx) {
+                @Override
+                public void run() {
+                    try {
+                        benchmark.execute(getRepository(), CREDENTIALS, context);
+                    } catch (Exception e) {
+                        LOG.error("Exception in benchmark execution ", e);
+                    }
+                }
+            };
+            threads.add(t);
+            t.start();
+        }
+
+        for (Thread t : threads) {
+            try {
+                t.join();
+            } catch (Exception e) {
+                LOG.error("Exception in search thread join ", e);
+            }
+        }
+        context.stopProfiler();
+
+        LOG.info("Started post benchmark hook : {}", benchmark);
+        benchmark.afterExecute(getRepository(), CREDENTIALS, context);
+    }
+
+    @Override
+    protected Repository[] createRepository(RepositoryFixture fixture) throws Exception {
+        if (fixture instanceof OakRepositoryFixture) {
+            return ((OakRepositoryFixture) fixture).setUpCluster(1, new JcrCreator() {
+                @Override
+                public Jcr customize(Oak oak) {
+                    LuceneIndexProvider provider = new LuceneIndexProvider();
+                    oak.with((QueryIndexProvider) provider)
+                            .with((Observer) provider)
+                            .with(new LuceneIndexEditorProvider());
+
+                    if (!Strings.isNullOrEmpty(ASYNC_INDEX) && ASYNC_INDEX
+                        .equals(IndexConstants.ASYNC_PROPERTY_NAME)) {
+                        oak.withAsyncIndexing();
+                    }
+
+                    if (FULL_TEXT) {
+                        oak.with(new LuceneInitializerHelper("luceneGlobal", storageEnabled));
+                    }
+
+                    whiteboard = oak.getWhiteboard();
+                    return new Jcr(oak);
+                }
+            });
+        }
+        return super.createRepository(fixture);
+    }
+
+    private synchronized void addRootSearchPath(String path) {
+        int limit = 1000;
+        if (searchRootPaths.size() < limit) {
+            searchRootPaths.add(path);
+        } else if (random.nextDouble() < 0.5) {
+            searchRootPaths.set(random.nextInt(limit), path);
+        }
+    }
+
+    private synchronized void addDescSearchPath(String path) {
+        int limit = 1000;
+        if (searchDescPaths.size() < limit) {
+            searchDescPaths.add(path);
+        } else if (random.nextDouble() < 0.5) {
+            searchDescPaths.set(random.nextInt(limit), path);
+        }
+    }
+
+    /**
+     * Creates a node hierarchy as follows:
+     *
+     * <pre>
+     * {@code
+     *  /LongevitySearchAssets<ID>
+     *      /writer<ID>
+     *          /Node<ID>
+     *              jcr:primaryType : <oak:Unstructured|rootType|nt:unstructured>
+     *              added : <DATE>
+     *              viewed : <true|false>
+     *              filter : <true|false>
+     *              title : Node<ID>
+     *              /SubNode<ID>
+     *                  jcr:primaryType : <oak:Unstructured|descendantTypeType|nt:unstructured>
+     *                  added : <DATE>
+     *                  viewed : <true|false>
+     *                  filter : <true|false>
+     *                  title : SubNode<ID>
+     * }
+     * </pre>
+     */
+    class Writer implements Runnable {
+
+        final Node parent;
+
+        final Session session;
+
+        final String id;
+
+        final SynchronizedDescriptiveStatistics stats;
+
+        long counter;
+
+        int secsIn2Years = 31622400;
+
+        Calendar start;
+
+        long startMillis;
+
+        Timer timer;
+
+        /** The maximum number of assets to be written by this thread. */
+        final int maxAssets;
+
+        Writer(String id, int maxAssets, SynchronizedDescriptiveStatistics writeStats)
+                throws RepositoryException {
+            this.id = id;
+            this.maxAssets = maxAssets;
+            this.stats = writeStats;
+            this.session = loginWriter();
+            this.parent = session
+                    .getRootNode()
+                    .getNode(ROOT_NODE_NAME)
+                    .addNode("writer-" + id);
+            start = Calendar.getInstance();
+            start.add(Calendar.YEAR, -2);
+            start.setTimeZone(TimeZone.getTimeZone("GMT"));
+            startMillis = start.getTimeInMillis();
+
+            session.save();
+
+            timer = new Timer(writeStats);
+        }
+
+        protected Calendar generateDate() {
+            if (RAND_DATE) {
+                start.setTimeInMillis(startMillis + random.nextInt(secsIn2Years));
+            } else {
+                start.add(Calendar.SECOND, 1);
+            }
+            return start;
+        }
+
+        @Override
+        public void run() {
+            try {
+                int count = 1;
+                while (count <= maxAssets) {
+                    session.refresh(false);
+
+                    // skip creation of child nodes based on the defined DENSITY_LEVEL
+                    Node node =
+                            createParent(parent, (random.nextInt(100) <= DENSITY_LEVEL), "Node"
+                                    + count);
+
+                    // record for searching and reading
+                    addRootSearchPath(node.getPath());
+
+                    if ((counter + 1) % 1000 == 0) {
+                        LOG.info("Thread " + id + " - Added nodes : " + (counter));
+                    }
+                    count++;
+                }
+            } catch (Exception e) {
+                LOG.error("Exception in load creation ", e);
+            }
+            LOG.info("Max Assets created by " + id + " - " + counter);
+        }
+
+        private Node createParent(Node parent, boolean createChildren, String name) throws Exception {
+            Node node = createNode(parent, 0, name);
+
+            if (createChildren) {
+                createChildren(node, 1);
+            }
+
+            return node;
+        }
+
+        private void createChildren(Node parent, int levelIdx) throws Exception {
+            if (levelIdx > NODE_LEVELS.size() - 1) {
+                return;
+            }
+
+            // Recursively create sub nodes
+            for (int idx = 0; idx < Integer.parseInt(NODE_LEVELS.get(levelIdx)); idx++) {
+                Node subNode =
+                        createNode(parent, levelIdx, "SubNode-" + levelIdx + "-" + idx);
+                addDescSearchPath(subNode.getPath());
+
+                createChildren(subNode, (levelIdx + 1));
+            }
+        }
+
+        /**
+         * Creates the node.
+         *
+         * @param parent the parent
+         * @param levelIdx the level idx
+         * @param name the name
+         * @return the node
+         * @throws Exception the exception
+         */
+        private Node createNode(Node parent, int levelIdx, String name)
+                throws Exception {
+
+            timer.start();
+            Node node =
+                    JcrUtils.getOrAddNode(parent, name, getType(levelIdx));
+            // Add relevant properties
+            node.setProperty(DATE_PROP, generateDate());
+            node.setProperty(SORT_PROP, toss());
+            node.setProperty(FILTER_PROP, toss());
+            node.setProperty(TITLE_PROP, name);
+
+            session.save();
+            counter++;
+            if (LOG.isDebugEnabled()) {
+                LOG.debug(node.getPath());
+            }
+
+            // Record time taken for creation
+            timer.stop();
+
+            return node;
+        }
+
+        /**
+         * Order of precedence is customNodeType, oak:Unstructured, nt:unstructured.
+         *
+         * @param levelIdx the hierarchy level of node (root or descendant)
+         * @return the type
+         * @throws RepositoryException the repository exception
+         */
+        protected String getType(int levelIdx) throws RepositoryException {
+            String typeOfNode = (levelIdx == 0 ? CTX_ACT_NODE_TYPE_PROP : CTX_REL_NODE_TYPE_PROP);
+
+            String type = NodeTypeConstants.NT_UNSTRUCTURED;
+            if (context.getMap().containsKey(typeOfNode)) {
+                type = (String) context.getMap().get(typeOfNode);
+            } else if (parent.getSession().getWorkspace().getNodeTypeManager().hasNodeType(
+                    NodeTypeConstants.NT_OAK_UNSTRUCTURED)) {
+                type = NodeTypeConstants.NT_OAK_UNSTRUCTURED;
+                context.getMap().put(typeOfNode, type);
+            }
+            return type;
+        }
+
+        private boolean toss() {
+            int tossOutcome = random.nextInt(2);
+            return tossOutcome == 0;
+        }
+    }
+
+    static class Timer {
+        private final Stopwatch watch;
+        private final SynchronizedDescriptiveStatistics stats;
+
+        public Timer(SynchronizedDescriptiveStatistics stats) {
+            watch = Stopwatch.createUnstarted();
+            this.stats = stats;
+        }
+
+        public void start() {
+            if (watch.isRunning()) {
+                watch.stop();
+                watch.reset();
+            }
+            watch.start();
+        }
+
+        public void stop() {
+            watch.stop();
+            stats.addValue(watch.elapsed(TimeUnit.MILLISECONDS));
+            watch.reset();
+        }
+    }
+}
+
diff --git oak-benchmarks-solr/pom.xml oak-benchmarks-solr/pom.xml
new file mode 100644
index 0000000..d2b9b4e
--- /dev/null
+++ oak-benchmarks-solr/pom.xml
@@ -0,0 +1,60 @@
+<?xml version="1.0" encoding="UTF-8"?>
+<project xmlns="http://maven.apache.org/POM/4.0.0"
+         xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
+         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
+    <parent>
+        <groupId>org.apache.jackrabbit</groupId>
+        <artifactId>oak-parent</artifactId>
+        <version>1.27-SNAPSHOT</version>
+        <relativePath>../oak-parent/pom.xml</relativePath>
+    </parent>
+    <modelVersion>4.0.0</modelVersion>
+
+    <artifactId>oak-benchmarks-solr</artifactId>
+
+    <properties>
+        <skip.deployment>true</skip.deployment>
+    </properties>
+
+    <dependencies>
+        <dependency>
+            <groupId>org.apache.jackrabbit</groupId>
+            <artifactId>oak-benchmarks</artifactId>
+            <version>${project.version}</version>
+        </dependency>
+        <dependency>
+            <groupId>org.apache.jackrabbit</groupId>
+            <artifactId>oak-solr-core</artifactId>
+            <version>${project.version}</version>
+        </dependency>
+        <dependency>
+            <groupId>org.jetbrains</groupId>
+            <artifactId>annotations</artifactId>
+        </dependency>
+        <dependency>
+            <groupId>org.apache.solr</groupId>
+            <artifactId>solr-core</artifactId>
+            <version>${solr.version}</version>
+            <exclusions>
+                <exclusion>
+                    <groupId>org.apache.lucene</groupId>
+                    <artifactId>lucene-core</artifactId>
+                </exclusion>
+                <exclusion>
+                    <groupId>org.apache.hadoop</groupId>
+                    <artifactId>hadoop-annotations</artifactId>
+                </exclusion>
+                <exclusion>
+                    <groupId>com.googlecode.concurrentlinkedhashmap</groupId>
+                    <artifactId>concurrentlinkedhashmap-lru</artifactId>
+                </exclusion>
+                <exclusion>
+                    <groupId>commons-fileupload</groupId>
+                    <artifactId>commons-fileupload</artifactId>
+                </exclusion>
+            </exclusions>
+        </dependency>
+    </dependencies>
+
+
+</project>
\ No newline at end of file
diff --git oak-benchmarks-solr/src/main/java/org/apache/jackrabbit/oak/benchmark/FullTextSolrSearchTest.java oak-benchmarks-solr/src/main/java/org/apache/jackrabbit/oak/benchmark/FullTextSolrSearchTest.java
new file mode 100644
index 0000000..c807706
--- /dev/null
+++ oak-benchmarks-solr/src/main/java/org/apache/jackrabbit/oak/benchmark/FullTextSolrSearchTest.java
@@ -0,0 +1,139 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+package org.apache.jackrabbit.oak.benchmark;
+
+import java.io.File;
+import java.io.FileOutputStream;
+import java.io.InputStream;
+import java.io.StringReader;
+import javax.jcr.Repository;
+
+import org.apache.commons.io.FileUtils;
+import org.apache.commons.io.IOUtils;
+import org.apache.jackrabbit.oak.Oak;
+import org.apache.jackrabbit.oak.fixture.JcrCreator;
+import org.apache.jackrabbit.oak.fixture.OakRepositoryFixture;
+import org.apache.jackrabbit.oak.fixture.RepositoryFixture;
+import org.apache.jackrabbit.oak.jcr.Jcr;
+import org.apache.jackrabbit.oak.plugins.index.solr.configuration.DefaultSolrConfiguration;
+import org.apache.jackrabbit.oak.plugins.index.solr.configuration.EmbeddedSolrServerConfiguration;
+import org.apache.jackrabbit.oak.plugins.index.solr.configuration.OakSolrConfiguration;
+import org.apache.jackrabbit.oak.plugins.index.solr.configuration.OakSolrConfigurationProvider;
+import org.apache.jackrabbit.oak.plugins.index.solr.configuration.RemoteSolrServerConfiguration;
+import org.apache.jackrabbit.oak.plugins.index.solr.configuration.nodestate.NodeStateSolrServersObserver;
+import org.apache.jackrabbit.oak.plugins.index.solr.index.SolrIndexEditorProvider;
+import org.apache.jackrabbit.oak.plugins.index.solr.query.SolrQueryIndexProvider;
+import org.apache.jackrabbit.oak.plugins.index.solr.server.EmbeddedSolrServerProvider;
+import org.apache.jackrabbit.oak.plugins.index.solr.server.SolrServerProvider;
+import org.apache.jackrabbit.oak.plugins.index.solr.util.SolrIndexInitializer;
+import org.apache.solr.client.solrj.SolrClient;
+import org.apache.solr.client.solrj.embedded.EmbeddedSolrServer;
+import org.jetbrains.annotations.NotNull;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+public class FullTextSolrSearchTest extends FullTextSearchTest {
+
+    private final Logger log = LoggerFactory.getLogger(getClass());
+
+    private SolrServerProvider serverProvider;
+    private String server;
+
+    public FullTextSolrSearchTest(File dump, boolean flat, boolean doReport, Boolean storageEnabled, String server) {
+        super(dump, flat, doReport, storageEnabled);
+        this.server = server;
+    }
+
+    @Override
+    protected Repository[] createRepository(RepositoryFixture fixture) throws Exception {
+        initializeProvider();
+        if (fixture instanceof OakRepositoryFixture) {
+            return ((OakRepositoryFixture) fixture).setUpCluster(1, new JcrCreator() {
+                @Override
+                public Jcr customize(Oak oak) {
+                    OakSolrConfigurationProvider configurationProvider = new OakSolrConfigurationProvider() {
+                        @NotNull
+                        public OakSolrConfiguration getConfiguration() {
+                            return new DefaultSolrConfiguration() {
+                                @Override
+                                public int getRows() {
+                                    return 50;
+                                }
+                            };
+                        }
+                    };
+                    oak.with(new SolrQueryIndexProvider(serverProvider, configurationProvider))
+                        .with(new NodeStateSolrServersObserver())
+                        .with(new SolrIndexEditorProvider(serverProvider, configurationProvider))
+                        .with(new SolrIndexInitializer(false));
+                    return new Jcr(oak);
+                }
+            });
+        }
+        return super.createRepository(fixture);
+    }
+
+    private void initializeProvider() throws Exception {
+        if (server == null || "default".equals(server)) {
+            log.info("spawning Solr locally");
+            serverProvider = createEmbeddedSolrServerProvider(true);
+        } else if (server != null && "embedded".equals(server)) {
+            log.info("using embedded Solr");
+            serverProvider = createEmbeddedSolrServerProvider(false);
+        } else if (server != null && (server.startsWith("http") || server.matches("\\w+\\:\\d{3,5}"))) {
+            log.info("using remote Solr {}", server);
+            RemoteSolrServerConfiguration remoteSolrServerConfiguration = new RemoteSolrServerConfiguration(
+                    server, "oak", 2, 2, null, 10, 10, server);
+            serverProvider = remoteSolrServerConfiguration.getProvider();
+        } else {
+            throw new IllegalArgumentException("server parameter value must be either 'embedded', 'default', an URL or an host:port String");
+        }
+    }
+
+    private EmbeddedSolrServerProvider createEmbeddedSolrServerProvider(boolean http) throws Exception {
+        String tempDirectoryPath = FileUtils.getTempDirectoryPath();
+        File solrHome = new File(tempDirectoryPath, "solr" + System.nanoTime());
+        EmbeddedSolrServerConfiguration embeddedSolrServerConfiguration = new EmbeddedSolrServerConfiguration(solrHome.getAbsolutePath(), "oak");
+        if (http) {
+            embeddedSolrServerConfiguration = embeddedSolrServerConfiguration.withHttpConfiguration("/solr", 8983);
+        }
+        EmbeddedSolrServerProvider embeddedSolrServerProvider = embeddedSolrServerConfiguration.getProvider();
+        SolrClient solrServer = embeddedSolrServerProvider.getSolrServer();
+        if (storageEnabled != null && !storageEnabled) {
+            // change schema.xml and reload the core
+            File schemaXML = new File(solrHome.getAbsolutePath() + "/oak/conf", "schema.xml");
+            InputStream inputStream = getClass().getResourceAsStream("/solr/oak/conf/schema.xml");
+            String schemaString = IOUtils.toString(inputStream).replace("<dynamicField name=\"*\" type=\"text_general\" indexed=\"true\" stored=\"true\" multiValued=\"true\"/>",
+                    "<dynamicField name=\"*\" type=\"text_general\" indexed=\"true\" stored=\"false\" multiValued=\"true\"/>");
+            FileOutputStream fileOutputStream = new FileOutputStream(schemaXML);
+            IOUtils.copy(new StringReader(schemaString), fileOutputStream);
+            fileOutputStream.flush();
+            ((EmbeddedSolrServer) solrServer).getCoreContainer().reload("oak");
+        }
+        return embeddedSolrServerProvider;
+    }
+
+    @Override
+    protected void afterSuite() throws Exception {
+        SolrClient solrServer = serverProvider.getSolrServer();
+        if (solrServer != null) {
+            solrServer.close();
+        }
+    }
+}
diff --git oak-benchmarks/pom.xml oak-benchmarks/pom.xml
index 73287f6..81a3836 100644
--- oak-benchmarks/pom.xml
+++ oak-benchmarks/pom.xml
@@ -124,11 +124,6 @@
         </dependency>
         <dependency>
             <groupId>org.apache.jackrabbit</groupId>
-            <artifactId>oak-lucene</artifactId>
-            <version>${project.version}</version>
-        </dependency>
-        <dependency>
-            <groupId>org.apache.jackrabbit</groupId>
             <artifactId>oak-core</artifactId>
             <version>${project.version}</version>
         </dependency>
@@ -140,11 +135,6 @@
         </dependency>
         <dependency>
             <groupId>org.apache.jackrabbit</groupId>
-            <artifactId>oak-solr-core</artifactId>
-            <version>${project.version}</version>
-        </dependency>
-        <dependency>
-            <groupId>org.apache.jackrabbit</groupId>
             <artifactId>oak-authorization-cug</artifactId>
             <version>${project.version}</version>
         </dependency>
@@ -178,27 +168,9 @@
             <artifactId>annotations</artifactId>
         </dependency>
         <dependency>
-            <groupId>org.apache.solr</groupId>
-            <artifactId>solr-core</artifactId>
-            <version>${solr.version}</version>
-            <exclusions>
-                <exclusion>
-                    <groupId>org.apache.lucene</groupId>
-                    <artifactId>lucene-core</artifactId>
-                </exclusion>
-                <exclusion>
-                    <groupId>org.apache.hadoop</groupId>
-                    <artifactId>hadoop-annotations</artifactId>
-                </exclusion>
-                <exclusion>
-                    <groupId>com.googlecode.concurrentlinkedhashmap</groupId>
-                    <artifactId>concurrentlinkedhashmap-lru</artifactId>
-                </exclusion>
-                <exclusion>
-                    <groupId>commons-fileupload</groupId>
-                    <artifactId>commons-fileupload</artifactId>
-                </exclusion>
-            </exclusions>
+            <groupId>org.apache.commons</groupId>
+            <artifactId>commons-lang3</artifactId>
+            <version>3.9</version>
         </dependency>
         <dependency>
             <groupId>org.apache.commons</groupId>
diff --git oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/benchmark/AbstractTest.java oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/benchmark/AbstractTest.java
index 4a3e7ef..d2ce80a 100644
--- oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/benchmark/AbstractTest.java
+++ oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/benchmark/AbstractTest.java
@@ -34,7 +34,7 @@ import javax.jcr.SimpleCredentials;
 import javax.security.auth.Subject;
 
 import com.google.common.base.Joiner;
-import org.apache.commons.lang.ArrayUtils;
+import org.apache.commons.lang3.ArrayUtils;
 import org.apache.commons.math.stat.descriptive.DescriptiveStatistics;
 import org.apache.commons.math.stat.descriptive.SynchronizedDescriptiveStatistics;
 import org.apache.jackrabbit.oak.commons.Profiler;
diff --git oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/benchmark/BenchmarkOptions.java oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/benchmark/BenchmarkOptions.java
new file mode 100644
index 0000000..8b9e450
--- /dev/null
+++ oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/benchmark/BenchmarkOptions.java
@@ -0,0 +1,486 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+package org.apache.jackrabbit.oak.benchmark;
+
+
+import joptsimple.OptionParser;
+import joptsimple.OptionSpec;
+import org.apache.jackrabbit.oak.benchmark.authorization.AceCreationTest;
+import org.apache.jackrabbit.oak.security.authorization.composite.CompositeAuthorizationConfiguration;
+import org.apache.jackrabbit.oak.spi.xml.ImportBehavior;
+
+import static java.util.Arrays.asList;
+import static org.apache.jackrabbit.oak.benchmark.ReadDeepTreeTest.DEFAULT_ITEMS_TD_READ;
+import static org.apache.jackrabbit.oak.benchmark.ReadDeepTreeTest.DEFAULT_REPEATED_READ;
+
+import java.io.File;
+
+public class BenchmarkOptions {
+
+    private final OptionSpec<File> base;
+    private final OptionSpec<String> host;
+    private final OptionSpec<Integer> port;
+    private final OptionSpec<String> dbName;
+    private final OptionSpec<String> mongouri;
+    private final OptionSpec<Boolean> dropDBAfterTest;
+    private final OptionSpec<String> rdbjdbcuri;
+    private final OptionSpec<String> rdbjdbcuser;
+    private final OptionSpec<String> rdbjdbcpasswd;
+    private final OptionSpec<String> rdbjdbctableprefix;
+    private final OptionSpec<String> azureConnectionString;
+    private final OptionSpec<String> azureContainerName;
+    private final OptionSpec<String> azureRootPath;
+    private final OptionSpec<Boolean> mmap;
+    private final OptionSpec<Integer> cache;
+    private final OptionSpec<Integer> fdsCache;
+    private final OptionSpec<File> wikipedia;
+    private final OptionSpec<Long> expiration;
+    private final OptionSpec<Boolean> metrics;
+    private final OptionSpec<Boolean> withStorage;
+    private final OptionSpec<String> withServer;
+    private final OptionSpec<Boolean> runAsAdmin;
+    private final OptionSpec<String> runAsUser;
+    private final OptionSpec<Boolean> runWithToken;
+    private final OptionSpec<Integer> noIterations;
+    private final OptionSpec<Boolean> luceneIndexOnFS;
+    private final OptionSpec<Integer> numberOfGroups;
+    private final OptionSpec<Integer> queryMaxCount;
+    private final OptionSpec<Boolean> declaredMembership;
+    private final OptionSpec<Integer> numberOfInitialAce;
+    private final OptionSpec<Boolean> nestedGroups;
+    private final OptionSpec<String> compositionType;
+    private final OptionSpec<String> autoMembership;
+    private final OptionSpec<Integer> roundtripDelay;
+    private final OptionSpec<Boolean> transientWrites;
+    private final OptionSpec<Integer> vgcMaxAge;
+    private final OptionSpec<Boolean> coldUseDataStore;
+    private final OptionSpec<Boolean> coldShareDataStore;
+    private final OptionSpec<Boolean> entriesForEachPrincipal;
+    private final OptionSpec<Integer> coldSyncInterval;
+    private final OptionSpec<Boolean> dynamicMembership;
+    private final OptionSpec<Boolean> reverseOrder;
+    private final OptionSpec<String> supportedPaths;
+    private final OptionSpec<Boolean> setScope;
+    private final OptionSpec<Integer> numberOfUsers;
+    private final OptionSpec<Boolean> flatStructure;
+    private final OptionSpec<Boolean> randomUser;
+    private final OptionSpec<File> csvFile;
+    private final OptionSpec<Boolean> report;
+    private final OptionSpec<Integer> concurrency;
+    private final OptionSpec<Integer> repeatedRead;
+    private final OptionSpec<Integer> itemsToRead;
+    private final OptionSpec<String> importBehavior;
+    private final OptionSpec<Integer> batchSize;
+    private final OptionSpec<Boolean> coldOneShotRun;
+    private final OptionSpec<Boolean> coldSecure;
+    private final OptionSpec<?> verbose;
+    private final OptionSpec<String> nonOption;
+    private final OptionSpec<?> help;
+    private final OptionSpec<Boolean> useAggregationFilter;
+
+    public OptionSpec<File> getBase() {
+        return base;
+    }
+
+    public OptionSpec<String> getHost() {
+        return host;
+    }
+
+    public OptionSpec<Integer> getPort() {
+        return port;
+    }
+
+    public OptionSpec<String> getDbName() {
+        return dbName;
+    }
+
+    public OptionSpec<String> getMongouri() {
+        return mongouri;
+    }
+
+    public OptionSpec<Boolean> getDropDBAfterTest() {
+        return dropDBAfterTest;
+    }
+
+    public OptionSpec<String> getRdbjdbcuri() {
+        return rdbjdbcuri;
+    }
+
+    public OptionSpec<String> getRdbjdbcuser() {
+        return rdbjdbcuser;
+    }
+
+    public OptionSpec<String> getRdbjdbcpasswd() {
+        return rdbjdbcpasswd;
+    }
+
+    public OptionSpec<String> getRdbjdbctableprefix() {
+        return rdbjdbctableprefix;
+    }
+
+    public OptionSpec<String> getAzureConnectionString() {
+        return azureConnectionString;
+    }
+
+    public OptionSpec<String> getAzureContainerName() {
+        return azureContainerName;
+    }
+
+    public OptionSpec<String> getAzureRootPath() {
+        return azureRootPath;
+    }
+
+    public OptionSpec<Boolean> getMmap() {
+        return mmap;
+    }
+
+    public OptionSpec<Integer> getCache() {
+        return cache;
+    }
+
+    public OptionSpec<Integer> getFdsCache() {
+        return fdsCache;
+    }
+
+    public OptionSpec<File> getWikipedia() {
+        return wikipedia;
+    }
+
+    public OptionSpec<Long> getExpiration() {
+        return expiration;
+    }
+
+    public OptionSpec<Boolean> getMetrics() {
+        return metrics;
+    }
+
+    public OptionSpec<Boolean> getWithStorage() {
+        return withStorage;
+    }
+
+    public OptionSpec<String> getWithServer() {
+        return withServer;
+    }
+
+    public OptionSpec<Boolean> getRunAsAdmin() {
+        return runAsAdmin;
+    }
+
+    public OptionSpec<String> getRunAsUser() {
+        return runAsUser;
+    }
+
+    public OptionSpec<Boolean> getRunWithToken() {
+        return runWithToken;
+    }
+
+    public OptionSpec<Integer> getNoIterations() {
+        return noIterations;
+    }
+
+    public OptionSpec<Boolean> getLuceneIndexOnFS() {
+        return luceneIndexOnFS;
+    }
+
+    public OptionSpec<Integer> getNumberOfGroups() {
+        return numberOfGroups;
+    }
+
+    public OptionSpec<Integer> getQueryMaxCount() {
+        return queryMaxCount;
+    }
+
+    public OptionSpec<Boolean> getDeclaredMembership() {
+        return declaredMembership;
+    }
+
+    public OptionSpec<Integer> getNumberOfInitialAce() {
+        return numberOfInitialAce;
+    }
+
+    public OptionSpec<Boolean> getNestedGroups() {
+        return nestedGroups;
+    }
+
+    public OptionSpec<String> getCompositionType() {
+        return compositionType;
+    }
+
+    public OptionSpec<String> getAutoMembership() {
+        return autoMembership;
+    }
+
+    public OptionSpec<Integer> getRoundtripDelay() {
+        return roundtripDelay;
+    }
+
+    public OptionSpec<Boolean> getTransientWrites() {
+        return transientWrites;
+    }
+
+    public OptionSpec<Integer> getVgcMaxAge() {
+        return vgcMaxAge;
+    }
+
+    public OptionSpec<Boolean> getColdUseDataStore() {
+        return coldUseDataStore;
+    }
+
+    public OptionSpec<Boolean> getColdShareDataStore() {
+        return coldShareDataStore;
+    }
+
+    public OptionSpec<Boolean> getEntriesForEachPrincipal() {
+        return entriesForEachPrincipal;
+    }
+
+    public OptionSpec<Integer> getColdSyncInterval() {
+        return coldSyncInterval;
+    }
+
+    public OptionSpec<Boolean> getDynamicMembership() {
+        return dynamicMembership;
+    }
+
+    public OptionSpec<Boolean> getReverseOrder() {
+        return reverseOrder;
+    }
+
+    public OptionSpec<String> getSupportedPaths() {
+        return supportedPaths;
+    }
+
+    public OptionSpec<Boolean> getSetScope() {
+        return setScope;
+    }
+
+    public OptionSpec<Integer> getNumberOfUsers() {
+        return numberOfUsers;
+    }
+
+    public OptionSpec<Boolean> getFlatStructure() {
+        return flatStructure;
+    }
+
+    public OptionSpec<Boolean> getRandomUser() {
+        return randomUser;
+    }
+
+    public OptionSpec<File> getCsvFile() {
+        return csvFile;
+    }
+
+    public OptionSpec<Boolean> getReport() {
+        return report;
+    }
+
+    public OptionSpec<Integer> getConcurrency() {
+        return concurrency;
+    }
+
+    public OptionSpec<Integer> getRepeatedRead() {
+        return repeatedRead;
+    }
+
+    public OptionSpec<Integer> getItemsToRead() {
+        return itemsToRead;
+    }
+
+    public OptionSpec<String> getImportBehavior() {
+        return importBehavior;
+    }
+
+    public OptionSpec<Integer> getBatchSize() {
+        return batchSize;
+    }
+
+    public OptionSpec<Boolean> getColdOneShotRun() {
+        return coldOneShotRun;
+    }
+
+    public OptionSpec<Boolean> getColdSecure() {
+        return coldSecure;
+    }
+
+    public OptionSpec<?> getVerbose() {
+        return verbose;
+    }
+
+    public OptionSpec<String> getNonOption() {
+        return nonOption;
+    }
+
+    public OptionSpec<?> getHelp() {
+        return help;
+    }
+
+    public OptionSpec<Boolean> getUseAggregationFilter() {
+        return useAggregationFilter;
+    }
+
+
+    public BenchmarkOptions(OptionParser parser) {
+        base = parser.accepts("base", "Base directory")
+                .withRequiredArg().ofType(File.class)
+                .defaultsTo(new File("target"));
+        host = parser.accepts("host", "MongoDB host")
+                .withRequiredArg().defaultsTo("localhost");
+        port = parser.accepts("port", "MongoDB port")
+                .withRequiredArg().ofType(Integer.class).defaultsTo(27017);
+        dbName = parser.accepts("db", "MongoDB database")
+                .withRequiredArg();
+        mongouri = parser.accepts("mongouri", "MongoDB URI")
+                .withRequiredArg();
+        dropDBAfterTest = parser.accepts("dropDBAfterTest", "Whether to drop the MongoDB database after the test")
+                .withOptionalArg().ofType(Boolean.class).defaultsTo(true);
+        rdbjdbcuri = parser.accepts("rdbjdbcuri", "RDB JDBC URI")
+                .withOptionalArg().defaultsTo("jdbc:h2:target/benchmark");
+        rdbjdbcuser = parser.accepts("rdbjdbcuser", "RDB JDBC user")
+                .withOptionalArg().defaultsTo("");
+        rdbjdbcpasswd = parser.accepts("rdbjdbcpasswd", "RDB JDBC password")
+                .withOptionalArg().defaultsTo("");
+        rdbjdbctableprefix = parser.accepts("rdbjdbctableprefix", "RDB JDBC table prefix")
+                .withOptionalArg().defaultsTo("");
+
+        azureConnectionString = parser.accepts("azure", "Azure Connection String")
+                .withOptionalArg().defaultsTo("DefaultEndpointsProtocol=http;AccountName=devstoreaccount1;AccountKey=Eby8vdM02xNOcqFlqUwJPLlmEtlCDXJ1OUzFT50uSRZ6IFsuFq2UVErCz4I6tq/K1SZFPTOtr/KBHBeksoGMGw==;BlobEndpoint=http://127.0.0.1:10000/devstoreaccount1;");
+        azureContainerName = parser.accepts("azureContainerName", "Azure container name")
+                .withOptionalArg().defaultsTo("oak");
+        azureRootPath = parser.accepts("azureRootPath", "Azure root path")
+                .withOptionalArg().defaultsTo("/oak");
+
+        mmap = parser.accepts("mmap", "TarMK memory mapping")
+                .withOptionalArg().ofType(Boolean.class)
+                .defaultsTo("64".equals(System.getProperty("sun.arch.data.model")));
+        cache = parser.accepts("cache", "cache size (MB)")
+                .withRequiredArg().ofType(Integer.class).defaultsTo(100);
+        fdsCache = parser.accepts("blobCache", "cache size (MB)")
+                .withRequiredArg().ofType(Integer.class).defaultsTo(32);
+        wikipedia = parser
+                .accepts("wikipedia", "Wikipedia dump").withRequiredArg()
+                .ofType(File.class);
+        luceneIndexOnFS = parser
+                .accepts("luceneIndexOnFS", "Store Lucene index on file system")
+                .withOptionalArg()
+                .ofType(Boolean.class).defaultsTo(false);
+        metrics = parser
+                .accepts("metrics", "Enable Metrics collection")
+                .withOptionalArg()
+                .ofType(Boolean.class).defaultsTo(false);
+        withStorage = parser
+                .accepts("storage", "Index storage enabled").withOptionalArg()
+                .ofType(Boolean.class);
+        withServer = parser
+                .accepts("server", "Solr server host").withOptionalArg()
+                .ofType(String.class);
+        runAsAdmin = parser.accepts("runAsAdmin", "Run test using admin session")
+                .withRequiredArg().ofType(Boolean.class).defaultsTo(Boolean.FALSE);
+        runAsUser = parser.accepts("runAsUser", "Run test using admin, anonymous or a test user")
+                .withOptionalArg().ofType(String.class).defaultsTo("admin");
+        runWithToken = parser.accepts("runWithToken", "Run test using a login token vs. simplecredentials")
+                .withOptionalArg().ofType(Boolean.class).defaultsTo(Boolean.FALSE);
+        noIterations = parser.accepts("noIterations", "Change default 'passwordHashIterations' parameter.")
+                .withOptionalArg().ofType(Integer.class).defaultsTo(AbstractLoginTest.DEFAULT_ITERATIONS);
+        expiration = parser.accepts("expiration", "Expiration time (e.g. principal cache.")
+                .withOptionalArg().ofType(Long.class).defaultsTo(AbstractLoginTest.NO_CACHE);
+        numberOfGroups = parser.accepts("numberOfGroups", "Number of groups to create.")
+                .withOptionalArg().ofType(Integer.class).defaultsTo(LoginWithMembershipTest.NUMBER_OF_GROUPS_DEFAULT);
+        queryMaxCount = parser.accepts("queryMaxCount", "Max number of query results.")
+                .withOptionalArg().ofType(Integer.class).defaultsTo(Integer.MAX_VALUE);
+        declaredMembership = parser.accepts("declaredMembership", "Only look for declared membership.")
+                .withOptionalArg().ofType(Boolean.class).defaultsTo(true);
+        numberOfInitialAce = parser.accepts("numberOfInitialAce", "Number of ACE to create before running the test.")
+                .withOptionalArg().ofType(Integer.class).defaultsTo(AceCreationTest.NUMBER_OF_INITIAL_ACE_DEFAULT);
+        nestedGroups = parser.accepts("nestedGroups", "Use nested groups.")
+                .withOptionalArg().ofType(Boolean.class).defaultsTo(false);
+        entriesForEachPrincipal = parser.accepts("entriesForEachPrincipal", "Create ACEs for each principal (vs rotating).")
+                .withOptionalArg().ofType(Boolean.class).defaultsTo(false);
+        compositionType = parser.accepts("compositionType", "Defines composition type for benchmarks with multiple authorization models.")
+                .withOptionalArg().ofType(String.class)
+                .defaultsTo(CompositeAuthorizationConfiguration.CompositionType.AND.name());
+        useAggregationFilter = parser.accepts("useAggregationFilter", "Run principal-based tests with 'AggregationFilter'")
+                .withOptionalArg().ofType(Boolean.class)
+                .defaultsTo(Boolean.FALSE);
+        batchSize = parser.accepts("batchSize", "Batch size before persisting operations.")
+                .withOptionalArg().ofType(Integer.class).defaultsTo(AddMembersTest.DEFAULT_BATCH_SIZE);
+        importBehavior = parser.accepts("importBehavior", "Protected Item Import Behavior")
+                .withOptionalArg().ofType(String.class).defaultsTo(ImportBehavior.NAME_BESTEFFORT);
+        itemsToRead = parser.accepts("itemsToRead", "Number of items to read")
+                .withRequiredArg().ofType(Integer.class).defaultsTo(DEFAULT_ITEMS_TD_READ);
+        repeatedRead = parser.accepts("repeatedRead", "Number of repetitions")
+                .withRequiredArg().ofType(Integer.class).defaultsTo(DEFAULT_REPEATED_READ);
+        concurrency = parser.accepts("concurrency", "Number of test threads.")
+                .withRequiredArg().ofType(Integer.class).withValuesSeparatedBy(',');
+        report = parser.accepts("report", "Whether to output intermediate results")
+                .withOptionalArg().ofType(Boolean.class)
+                .defaultsTo(Boolean.FALSE);
+        randomUser = parser.accepts("randomUser", "Whether to use a random user to read.")
+                .withOptionalArg().ofType(Boolean.class)
+                .defaultsTo(Boolean.FALSE);
+        csvFile = parser.accepts("csvFile", "File to write a CSV version of the benchmark data.")
+                .withOptionalArg().ofType(File.class);
+        flatStructure = parser.accepts("flatStructure", "Whether the test should use a flat structure or not.")
+                .withOptionalArg().ofType(Boolean.class).defaultsTo(Boolean.FALSE);
+        numberOfUsers = parser.accepts("numberOfUsers")
+                .withOptionalArg().ofType(Integer.class).defaultsTo(10000);
+        setScope = parser.accepts("setScope", "Whether to use include setScope in the user query.")
+                .withOptionalArg().ofType(Boolean.class)
+                .defaultsTo(Boolean.FALSE);
+        reverseOrder = parser.accepts("reverseOrder", "Invert order of configurations in composite setup.")
+                .withOptionalArg().ofType(Boolean.class)
+                .defaultsTo(Boolean.FALSE);
+        supportedPaths = parser.accepts("supportedPaths", "Supported paths in composite setup.")
+                .withOptionalArg().ofType(String.class).withValuesSeparatedBy(',');
+        dynamicMembership = parser.accepts("dynamicMembership", "Enable dynamic membership handling during synchronisation of external users.")
+                .withOptionalArg().ofType(Boolean.class).defaultsTo(Boolean.FALSE);
+        autoMembership = parser.accepts("autoMembership", "Ids of those groups a given external identity automatically become member of.")
+                .withOptionalArg().ofType(String.class).withValuesSeparatedBy(',');
+        roundtripDelay = parser.accepts("roundtripDelay", "Use simplified principal name lookup from ExtIdRef by specifying roundtrip delay of value < 0.")
+                .withOptionalArg().ofType(Integer.class).defaultsTo(0);
+        transientWrites = parser.accepts("transient", "Do not save data.")
+                .withOptionalArg().ofType(Boolean.class)
+                .defaultsTo(Boolean.FALSE);
+        vgcMaxAge = parser.accepts("vgcMaxAge", "Continuous DocumentNodeStore VersionGC max age in sec (RDB only)")
+                .withRequiredArg().ofType(Integer.class).defaultsTo(-1);
+        coldSyncInterval = parser.accepts("coldSyncInterval", "interval between sync cycles in sec (Segment-Tar-Cold only)")
+                .withRequiredArg().ofType(Integer.class).defaultsTo(5);
+        coldUseDataStore = parser
+                .accepts("useDataStore", "Whether to use a datastore in the cold standby topology (Segment-Tar-Cold only)")
+                .withOptionalArg().ofType(Boolean.class)
+                .defaultsTo(Boolean.TRUE);
+        coldShareDataStore = parser
+                .accepts("shareDataStore", "Whether to share the datastore for primary and standby in the cold standby topology (Segment-Tar-Cold only)")
+                .withOptionalArg().ofType(Boolean.class)
+                .defaultsTo(Boolean.FALSE);
+        coldOneShotRun = parser
+                .accepts("oneShotRun", "Whether to do a continuous sync between client and server or sync only once (Segment-Tar-Cold only)")
+                .withOptionalArg().ofType(Boolean.class)
+                .defaultsTo(Boolean.FALSE);
+        coldSecure = parser
+                .accepts("secure", "Whether to enable secure communication between primary and standby in the cold standby topology (Segment-Tar-Cold only)")
+                .withOptionalArg().ofType(Boolean.class)
+                .defaultsTo(Boolean.FALSE);
+
+        verbose = parser.accepts("verbose", "Enable verbose output");
+        nonOption = parser.nonOptions();
+        help = parser.acceptsAll(asList("h", "?", "help"), "show help").forHelp();
+    }
+
+}
diff --git oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/benchmark/BenchmarkRunner.java oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/benchmark/BenchmarkRunner.java
index a0b4491..0c25142 100644
--- oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/benchmark/BenchmarkRunner.java
+++ oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/benchmark/BenchmarkRunner.java
@@ -16,11 +16,8 @@
  */
 package org.apache.jackrabbit.oak.benchmark;
 
-import static java.util.Arrays.asList;
-import static org.apache.jackrabbit.oak.benchmark.ReadDeepTreeTest.DEFAULT_ITEMS_TD_READ;
-import static org.apache.jackrabbit.oak.benchmark.ReadDeepTreeTest.DEFAULT_REPEATED_READ;
 
-import java.io.File;
+import java.io.IOException;
 import java.io.PrintStream;
 import java.util.ArrayList;
 import java.util.Arrays;
@@ -41,7 +38,6 @@ import com.google.common.collect.Sets;
 import com.google.common.util.concurrent.MoreExecutors;
 import joptsimple.OptionParser;
 import joptsimple.OptionSet;
-import joptsimple.OptionSpec;
 import org.apache.commons.io.FileUtils;
 import org.apache.jackrabbit.oak.benchmark.authentication.external.ExternalLoginTest;
 import org.apache.jackrabbit.oak.benchmark.authentication.external.ListIdentitiesTest;
@@ -61,218 +57,87 @@ import org.apache.jackrabbit.oak.fixture.OakFixture;
 import org.apache.jackrabbit.oak.fixture.OakRepositoryFixture;
 import org.apache.jackrabbit.oak.fixture.RepositoryFixture;
 import org.apache.jackrabbit.oak.plugins.metric.MetricStatisticsProvider;
-import org.apache.jackrabbit.oak.security.authorization.composite.CompositeAuthorizationConfiguration;
-import org.apache.jackrabbit.oak.spi.xml.ImportBehavior;
 import org.apache.jackrabbit.oak.stats.StatisticsProvider;
 
 public class BenchmarkRunner {
 
     private static final int MB = 1024 * 1024;
 
+    protected static List<Benchmark> allBenchmarks = Lists.newArrayList();
+    protected static StatisticsProvider statsProvider = null;
+
+    private static OptionParser parser = new OptionParser();
+    protected static BenchmarkOptions benchmarkOptions = null;
+    protected static OptionSet options;
+    private static boolean initFlag = false;
+
+
     public static void main(String[] args) throws Exception {
-        OptionParser parser = new OptionParser();
-        OptionSpec<File> base = parser.accepts("base", "Base directory")
-                .withRequiredArg().ofType(File.class)
-                .defaultsTo(new File("target"));
-        OptionSpec<String> host = parser.accepts("host", "MongoDB host")
-                .withRequiredArg().defaultsTo("localhost");
-        OptionSpec<Integer> port = parser.accepts("port", "MongoDB port")
-                .withRequiredArg().ofType(Integer.class).defaultsTo(27017);
-        OptionSpec<String> dbName = parser.accepts("db", "MongoDB database")
-                .withRequiredArg();
-        OptionSpec<String> mongouri = parser.accepts("mongouri", "MongoDB URI")
-                .withRequiredArg();
-        OptionSpec<Boolean> dropDBAfterTest = parser.accepts("dropDBAfterTest", "Whether to drop the MongoDB database after the test")
-                .withOptionalArg().ofType(Boolean.class).defaultsTo(true);
-        OptionSpec<String> rdbjdbcuri = parser.accepts("rdbjdbcuri", "RDB JDBC URI")
-                .withOptionalArg().defaultsTo("jdbc:h2:target/benchmark");
-        OptionSpec<String> rdbjdbcuser = parser.accepts("rdbjdbcuser", "RDB JDBC user")
-                .withOptionalArg().defaultsTo("");
-        OptionSpec<String> rdbjdbcpasswd = parser.accepts("rdbjdbcpasswd", "RDB JDBC password")
-                .withOptionalArg().defaultsTo("");
-        OptionSpec<String> rdbjdbctableprefix = parser.accepts("rdbjdbctableprefix", "RDB JDBC table prefix")
-                .withOptionalArg().defaultsTo("");
-
-        OptionSpec<String> azureConnectionString = parser.accepts("azure", "Azure Connection String")
-                .withOptionalArg().defaultsTo("DefaultEndpointsProtocol=http;AccountName=devstoreaccount1;AccountKey=Eby8vdM02xNOcqFlqUwJPLlmEtlCDXJ1OUzFT50uSRZ6IFsuFq2UVErCz4I6tq/K1SZFPTOtr/KBHBeksoGMGw==;BlobEndpoint=http://127.0.0.1:10000/devstoreaccount1;");
-        OptionSpec<String> azureContainerName = parser.accepts("azureContainerName", "Azure container name")
-                .withOptionalArg().defaultsTo("oak");
-        OptionSpec<String> azureRootPath = parser.accepts("azureRootPath", "Azure root path")
-                .withOptionalArg().defaultsTo("/oak");
-
-        OptionSpec<Boolean> mmap = parser.accepts("mmap", "TarMK memory mapping")
-                .withOptionalArg().ofType(Boolean.class)
-                .defaultsTo("64".equals(System.getProperty("sun.arch.data.model")));
-        OptionSpec<Integer> cache = parser.accepts("cache", "cache size (MB)")
-                .withRequiredArg().ofType(Integer.class).defaultsTo(100);
-        OptionSpec<Integer> fdsCache = parser.accepts("blobCache", "cache size (MB)")
-                .withRequiredArg().ofType(Integer.class).defaultsTo(32);
-        OptionSpec<File> wikipedia = parser
-                .accepts("wikipedia", "Wikipedia dump").withRequiredArg()
-                .ofType(File.class);
-        OptionSpec<Boolean> luceneIndexOnFS = parser
-                .accepts("luceneIndexOnFS", "Store Lucene index on file system")
-                .withOptionalArg()
-                .ofType(Boolean.class).defaultsTo(false);
-        OptionSpec<Boolean> metrics = parser
-                .accepts("metrics", "Enable Metrics collection")
-                .withOptionalArg()
-                .ofType(Boolean.class).defaultsTo(false);
-        OptionSpec<Boolean> withStorage = parser
-                .accepts("storage", "Index storage enabled").withOptionalArg()
-                .ofType(Boolean.class);
-        OptionSpec<String> withServer = parser
-                .accepts("server", "Solr server host").withOptionalArg()
-                .ofType(String.class);
-        OptionSpec<Boolean> runAsAdmin = parser.accepts("runAsAdmin", "Run test using admin session")
-                .withRequiredArg().ofType(Boolean.class).defaultsTo(Boolean.FALSE);
-        OptionSpec<String> runAsUser = parser.accepts("runAsUser", "Run test using admin, anonymous or a test user")
-                .withOptionalArg().ofType(String.class).defaultsTo("admin");
-        OptionSpec<Boolean> runWithToken = parser.accepts("runWithToken", "Run test using a login token vs. simplecredentials")
-                .withOptionalArg().ofType(Boolean.class).defaultsTo(Boolean.FALSE);
-        OptionSpec<Integer> noIterations = parser.accepts("noIterations", "Change default 'passwordHashIterations' parameter.")
-                .withOptionalArg().ofType(Integer.class).defaultsTo(AbstractLoginTest.DEFAULT_ITERATIONS);
-        OptionSpec<Long> expiration = parser.accepts("expiration", "Expiration time (e.g. principal cache.")
-                .withOptionalArg().ofType(Long.class).defaultsTo(AbstractLoginTest.NO_CACHE);
-        OptionSpec<Integer> numberOfGroups = parser.accepts("numberOfGroups", "Number of groups to create.")
-                .withOptionalArg().ofType(Integer.class).defaultsTo(LoginWithMembershipTest.NUMBER_OF_GROUPS_DEFAULT);
-        OptionSpec<Integer> queryMaxCount = parser.accepts("queryMaxCount", "Max number of query results.")
-                .withOptionalArg().ofType(Integer.class).defaultsTo(Integer.MAX_VALUE);
-        OptionSpec<Boolean> declaredMembership = parser.accepts("declaredMembership", "Only look for declared membership.")
-                .withOptionalArg().ofType(Boolean.class).defaultsTo(true);
-        OptionSpec<Integer> numberOfInitialAce = parser.accepts("numberOfInitialAce", "Number of ACE to create before running the test.")
-                .withOptionalArg().ofType(Integer.class).defaultsTo(AceCreationTest.NUMBER_OF_INITIAL_ACE_DEFAULT);
-        OptionSpec<Boolean> nestedGroups = parser.accepts("nestedGroups", "Use nested groups.")
-                .withOptionalArg().ofType(Boolean.class).defaultsTo(false);
-        OptionSpec<Boolean> entriesForEachPrincipal = parser.accepts("entriesForEachPrincipal", "Create ACEs for each principal (vs rotating).")
-                .withOptionalArg().ofType(Boolean.class).defaultsTo(false);
-        OptionSpec<String> compositionType = parser.accepts("compositionType", "Defines composition type for benchmarks with multiple authorization models.")
-                .withOptionalArg().ofType(String.class)
-                .defaultsTo(CompositeAuthorizationConfiguration.CompositionType.AND.name());
-        OptionSpec<Boolean> useAggregationFilter = parser.accepts("useAggregationFilter", "Run principal-based tests with 'AggregationFilter'")
-                .withOptionalArg().ofType(Boolean.class)
-                .defaultsTo(Boolean.FALSE);
-        OptionSpec<Integer> batchSize = parser.accepts("batchSize", "Batch size before persisting operations.")
-                .withOptionalArg().ofType(Integer.class).defaultsTo(AddMembersTest.DEFAULT_BATCH_SIZE);
-        OptionSpec<String> importBehavior = parser.accepts("importBehavior", "Protected Item Import Behavior")
-                .withOptionalArg().ofType(String.class).defaultsTo(ImportBehavior.NAME_BESTEFFORT);
-        OptionSpec<Integer> itemsToRead = parser.accepts("itemsToRead", "Number of items to read")
-                .withRequiredArg().ofType(Integer.class).defaultsTo(DEFAULT_ITEMS_TD_READ);
-        OptionSpec<Integer> repeatedRead = parser.accepts("repeatedRead", "Number of repetitions")
-                .withRequiredArg().ofType(Integer.class).defaultsTo(DEFAULT_REPEATED_READ);
-        OptionSpec<Integer> concurrency = parser.accepts("concurrency", "Number of test threads.")
-                .withRequiredArg().ofType(Integer.class).withValuesSeparatedBy(',');
-        OptionSpec<Boolean> report = parser.accepts("report", "Whether to output intermediate results")
-                .withOptionalArg().ofType(Boolean.class)
-                .defaultsTo(Boolean.FALSE);
-        OptionSpec<Boolean> randomUser = parser.accepts("randomUser", "Whether to use a random user to read.")
-                .withOptionalArg().ofType(Boolean.class)
-                .defaultsTo(Boolean.FALSE);
-        OptionSpec<File> csvFile = parser.accepts("csvFile", "File to write a CSV version of the benchmark data.")
-                .withOptionalArg().ofType(File.class);
-        OptionSpec<Boolean> flatStructure = parser.accepts("flatStructure", "Whether the test should use a flat structure or not.")
-                .withOptionalArg().ofType(Boolean.class).defaultsTo(Boolean.FALSE);
-        OptionSpec<Integer> numberOfUsers = parser.accepts("numberOfUsers")
-                .withOptionalArg().ofType(Integer.class).defaultsTo(10000);
-        OptionSpec<Boolean> setScope = parser.accepts("setScope", "Whether to use include setScope in the user query.")
-                .withOptionalArg().ofType(Boolean.class)
-                .defaultsTo(Boolean.FALSE);
-        OptionSpec<Boolean> reverseOrder = parser.accepts("reverseOrder", "Invert order of configurations in composite setup.")
-                .withOptionalArg().ofType(Boolean.class)
-                .defaultsTo(Boolean.FALSE);
-        OptionSpec<String> supportedPaths = parser.accepts("supportedPaths", "Supported paths in composite setup.")
-                .withOptionalArg().ofType(String.class).withValuesSeparatedBy(',');
-        OptionSpec<Boolean> dynamicMembership = parser.accepts("dynamicMembership", "Enable dynamic membership handling during synchronisation of external users.")
-                .withOptionalArg().ofType(Boolean.class).defaultsTo(Boolean.FALSE);
-        OptionSpec<String> autoMembership = parser.accepts("autoMembership", "Ids of those groups a given external identity automatically become member of.")
-                .withOptionalArg().ofType(String.class).withValuesSeparatedBy(',');
-        OptionSpec<Integer> roundtripDelay = parser.accepts("roundtripDelay", "Use simplified principal name lookup from ExtIdRef by specifying roundtrip delay of value < 0.")
-                .withOptionalArg().ofType(Integer.class).defaultsTo(0);
-        OptionSpec<Boolean> transientWrites = parser.accepts("transient", "Do not save data.")
-                .withOptionalArg().ofType(Boolean.class)
-                .defaultsTo(Boolean.FALSE);
-        OptionSpec<Integer> vgcMaxAge = parser.accepts("vgcMaxAge", "Continuous DocumentNodeStore VersionGC max age in sec (RDB only)")
-                .withRequiredArg().ofType(Integer.class).defaultsTo(-1);
-        OptionSpec<Integer> coldSyncInterval = parser.accepts("coldSyncInterval", "interval between sync cycles in sec (Segment-Tar-Cold only)")
-                .withRequiredArg().ofType(Integer.class).defaultsTo(5);
-        OptionSpec<Boolean> coldUseDataStore = parser
-                .accepts("useDataStore", "Whether to use a datastore in the cold standby topology (Segment-Tar-Cold only)")
-                .withOptionalArg().ofType(Boolean.class)
-                .defaultsTo(Boolean.TRUE);
-        OptionSpec<Boolean> coldShareDataStore = parser
-                .accepts("shareDataStore", "Whether to share the datastore for primary and standby in the cold standby topology (Segment-Tar-Cold only)")
-                .withOptionalArg().ofType(Boolean.class)
-                .defaultsTo(Boolean.FALSE);
-        OptionSpec<Boolean> coldOneShotRun = parser
-                .accepts("oneShotRun", "Whether to do a continuous sync between client and server or sync only once (Segment-Tar-Cold only)")
-                .withOptionalArg().ofType(Boolean.class)
-                .defaultsTo(Boolean.FALSE);
-        OptionSpec<Boolean> coldSecure = parser
-                .accepts("secure", "Whether to enable secure communication between primary and standby in the cold standby topology (Segment-Tar-Cold only)")
-                .withOptionalArg().ofType(Boolean.class)
-                .defaultsTo(Boolean.FALSE);
-        
-        OptionSpec<?> verbose = parser.accepts("verbose", "Enable verbose output");
-        OptionSpec<String> nonOption = parser.nonOptions();
-        OptionSpec<?> help = parser.acceptsAll(asList("h", "?", "help"), "show help").forHelp();
-        OptionSet options = parser.parse(args);
-
-        if(options.has(help)){
+
+        initOptionSet(args);
+
+        if (options.has(benchmarkOptions.getHelp())) {
             parser.printHelpOn(System.out);
             System.exit(0);
         }
 
-        String uri = mongouri.value(options);
+        String uri = benchmarkOptions.getMongouri().value(options);
         if (uri == null) {
-            String db = dbName.value(options);
+            String db = benchmarkOptions.getDbName().value(options);
             if (db == null) {
                 db = OakFixture.getUniqueDatabaseName(OakFixture.OAK_MONGO);
             }
-            uri = "mongodb://" + host.value(options) + ":" + port.value(options) + "/" + db;
+            uri = "mongodb://" + benchmarkOptions.getHost().value(options) + ":"
+                    + benchmarkOptions.getPort().value(options) + "/" + db;
         }
-        StatisticsProvider statsProvider = options.has(metrics) ? getStatsProvider() : StatisticsProvider.NOOP;
-        int cacheSize = cache.value(options);
+
+        statsProvider = options.has(benchmarkOptions.getMetrics()) ? getStatsProvider() : StatisticsProvider.NOOP;
+        int cacheSize = benchmarkOptions.getCache().value(options);
         RepositoryFixture[] allFixtures = new RepositoryFixture[]{
-                new JackrabbitRepositoryFixture(base.value(options), cacheSize),
+                new JackrabbitRepositoryFixture(benchmarkOptions.getBase().value(options), cacheSize),
                 OakRepositoryFixture.getMemoryNS(cacheSize * MB),
                 OakRepositoryFixture.getMongo(uri,
-                        dropDBAfterTest.value(options), cacheSize * MB),
+                        benchmarkOptions.getDropDBAfterTest().value(options), cacheSize * MB),
                 OakRepositoryFixture.getMongoWithDS(uri,
-                        dropDBAfterTest.value(options),
+                        benchmarkOptions.getDropDBAfterTest().value(options),
                         cacheSize * MB,
-                        base.value(options),
-                        fdsCache.value(options)),
+                        benchmarkOptions.getBase().value(options),
+                        benchmarkOptions.getFdsCache().value(options)),
                 OakRepositoryFixture.getMongoNS(uri,
-                        dropDBAfterTest.value(options),
+                        benchmarkOptions.getDropDBAfterTest().value(options),
                         cacheSize * MB),
-                OakRepositoryFixture.getSegmentTar(base.value(options), 256, cacheSize,
-                        mmap.value(options)),
-                OakRepositoryFixture.getSegmentTarWithDataStore(base.value(options), 256, cacheSize,
-                        mmap.value(options), fdsCache.value(options)),
-                OakRepositoryFixture.getSegmentTarWithColdStandby(base.value(options), 256, cacheSize,
-                        mmap.value(options), coldUseDataStore.value(options), fdsCache.value(options), 
-                        coldSyncInterval.value(options), coldShareDataStore.value(options), coldSecure.value(options), 
-                        coldOneShotRun.value(options)),
-                OakRepositoryFixture.getSegmentTarWithAzureSegmentStore(base.value(options),
-                        azureConnectionString.value(options),
-                        azureContainerName.value(options),
-                        azureRootPath.value(options),
-                        256, cacheSize, true, fdsCache.value(options)),
-                OakRepositoryFixture.getRDB(rdbjdbcuri.value(options), rdbjdbcuser.value(options),
-                        rdbjdbcpasswd.value(options), rdbjdbctableprefix.value(options), 
-                        dropDBAfterTest.value(options), cacheSize * MB, vgcMaxAge.value(options)),
-                OakRepositoryFixture.getRDBWithDS(rdbjdbcuri.value(options), rdbjdbcuser.value(options),
-                        rdbjdbcpasswd.value(options), rdbjdbctableprefix.value(options),
-                        dropDBAfterTest.value(options), cacheSize * MB, base.value(options),
-                        fdsCache.value(options), vgcMaxAge.value(options)),
-                OakRepositoryFixture.getCompositeStore(base.value(options), 256, cacheSize,
-                        mmap.value(options)),
+                OakRepositoryFixture.getSegmentTar(benchmarkOptions.getBase().value(options), 256, cacheSize,
+                        benchmarkOptions.getMmap().value(options)),
+                OakRepositoryFixture.getSegmentTarWithDataStore(benchmarkOptions.getBase().value(options), 256, cacheSize,
+                        benchmarkOptions.getMmap().value(options), benchmarkOptions.getFdsCache().value(options)),
+                OakRepositoryFixture.getSegmentTarWithColdStandby(benchmarkOptions.getBase().value(options), 256, cacheSize,
+                        benchmarkOptions.getMmap().value(options), benchmarkOptions.getColdUseDataStore().value(options),
+                        benchmarkOptions.getFdsCache().value(options),
+                        benchmarkOptions.getColdSyncInterval().value(options),
+                        benchmarkOptions.getColdShareDataStore().value(options), benchmarkOptions.getColdSecure().value(options),
+                        benchmarkOptions.getColdOneShotRun().value(options)),
+                OakRepositoryFixture.getSegmentTarWithAzureSegmentStore(benchmarkOptions.getBase().value(options),
+                        benchmarkOptions.getAzureConnectionString().value(options),
+                        benchmarkOptions.getAzureContainerName().value(options),
+                        benchmarkOptions.getAzureRootPath().value(options),
+                        256, cacheSize, true, benchmarkOptions.getFdsCache().value(options)),
+                OakRepositoryFixture.getRDB(benchmarkOptions.getRdbjdbcuri().value(options),
+                        benchmarkOptions.getRdbjdbcuser().value(options),
+                        benchmarkOptions.getRdbjdbcpasswd().value(options), benchmarkOptions.getRdbjdbctableprefix().value(options),
+                        benchmarkOptions.getDropDBAfterTest().value(options), cacheSize * MB, benchmarkOptions.getVgcMaxAge().value(options)),
+                OakRepositoryFixture.getRDBWithDS(benchmarkOptions.getRdbjdbcuri().value(options),
+                        benchmarkOptions.getRdbjdbcuser().value(options),
+                        benchmarkOptions.getRdbjdbcpasswd().value(options), benchmarkOptions.getRdbjdbctableprefix().value(options),
+                        benchmarkOptions.getDropDBAfterTest().value(options), cacheSize * MB, benchmarkOptions.getBase().value(options),
+                        benchmarkOptions.getFdsCache().value(options), benchmarkOptions.getVgcMaxAge().value(options)),
+                OakRepositoryFixture.getCompositeStore(benchmarkOptions.getBase().value(options), 256, cacheSize,
+                        benchmarkOptions.getMmap().value(options)),
                 OakRepositoryFixture.getCompositeMemoryStore(),
                 OakRepositoryFixture.getCompositeMongoStore(uri, cacheSize * MB,
-                        dropDBAfterTest.value(options))
+                        benchmarkOptions.getDropDBAfterTest().value(options))
         };
 
-        Benchmark[] allBenchmarks = new Benchmark[] {
+        addToBenchMarkList(Arrays.asList(
                         new OrderedIndexQueryOrderedIndexTest(),
                         new OrderedIndexQueryStandardIndexTest(),
                         new OrderedIndexQueryNoIndexTest(),
@@ -280,31 +145,31 @@ public class BenchmarkRunner {
                         new OrderedIndexInsertStandardPropertyTest(),
                         new OrderedIndexInsertNoIndexTest(),
                         new LoginTest(
-                    runAsUser.value(options),
-                    runWithToken.value(options),
-                    noIterations.value(options)),
+                                benchmarkOptions.getRunAsUser().value(options),
+                                benchmarkOptions.getRunWithToken().value(options),
+                                benchmarkOptions.getNoIterations().value(options)),
                         new LoginLogoutTest(
-                    runAsUser.value(options),
-                    runWithToken.value(options),
-                    noIterations.value(options)),
+                                benchmarkOptions.getRunAsUser().value(options),
+                                benchmarkOptions.getRunWithToken().value(options),
+                                benchmarkOptions.getNoIterations().value(options)),
                         new LoginGetRootLogoutTest(
-                    runAsUser.value(options),
-                    runWithToken.value(options),
-                    noIterations.value(options)),
-            new LoginWithTokensTest(numberOfUsers.value(options)),
+                                benchmarkOptions.getRunAsUser().value(options),
+                                benchmarkOptions.getRunWithToken().value(options),
+                                benchmarkOptions.getNoIterations().value(options)),
+                        new LoginWithTokensTest(benchmarkOptions.getNumberOfUsers().value(options)),
                         new LoginSystemTest(),
                         new LoginImpersonateTest(),
                         new LoginWithMembershipTest(
-                    runWithToken.value(options),
-                    noIterations.value(options),
-                    numberOfGroups.value(options),
-                    nestedGroups.value(options),
-                    expiration.value(options)),
+                                benchmarkOptions.getRunWithToken().value(options),
+                                benchmarkOptions.getNoIterations().value(options),
+                                benchmarkOptions.getNumberOfGroups().value(options),
+                                benchmarkOptions.getNestedGroups().value(options),
+                                benchmarkOptions.getExpiration().value(options)),
                         new LoginWithMembersTest(
-                    runWithToken.value(options),
-                    noIterations.value(options),
-                    numberOfGroups.value(options),
-                    expiration.value(options)),
+                                benchmarkOptions.getRunWithToken().value(options),
+                                benchmarkOptions.getNoIterations().value(options),
+                                benchmarkOptions.getNumberOfGroups().value(options),
+                                benchmarkOptions.getExpiration().value(options)),
                         new NamespaceTest(),
                         new NamespaceRegistryTest(),
                         new ReadPropertyTest(),
@@ -331,112 +196,113 @@ public class BenchmarkRunner {
                         new UpdateManyChildNodesTest(),
                         new TransientManyChildNodesTest(),
                         new WikipediaImport(
-                    wikipedia.value(options),
-                    flatStructure.value(options),
-                    report.value(options)),
+                                benchmarkOptions.getWikipedia().value(options),
+                                benchmarkOptions.getFlatStructure().value(options),
+                                benchmarkOptions.getReport().value(options)),
                         new CreateNodesBenchmark(),
-            new ManyNodes(options.has(verbose)),
+                        new ManyNodes(options.has(benchmarkOptions.getVerbose())),
                         new ObservationTest(),
                         new RevisionGCTest(),
                         new ContinuousRevisionGCTest(),
                         new XmlImportTest(),
                         new FlatTreeWithAceForSamePrincipalTest(),
                         new ReadDeepTreeTest(
-                    runAsAdmin.value(options),
-                    itemsToRead.value(options),
-                    report.value(options)),
+                                benchmarkOptions.getRunAsAdmin().value(options),
+                                benchmarkOptions.getItemsToRead().value(options),
+                                benchmarkOptions.getReport().value(options)),
                         new CompositeAuthorizationTest(
-                        runAsAdmin.value(options),
-                        itemsToRead.value(options)), // NOTE: this is currently the no of configurations
-            new CugTest(runAsAdmin.value(options),
-                        itemsToRead.value(options),
-                        randomUser.value(options),
-                        supportedPaths.values(options),
-                        reverseOrder.value(options)),
-            new CugOakTest(runAsAdmin.value(options),
-                        itemsToRead.value(options),
-                        randomUser.value(options),
-                        supportedPaths.values(options),
-                        reverseOrder.value(options)),
+                                benchmarkOptions.getRunAsAdmin().value(options),
+                                benchmarkOptions.getItemsToRead().value(options)), // NOTE: this is currently the no of configurations
+                        new CugTest(benchmarkOptions.getRunAsAdmin().value(options),
+                                benchmarkOptions.getItemsToRead().value(options),
+                                benchmarkOptions.getRandomUser().value(options),
+                                benchmarkOptions.getSupportedPaths().values(options),
+                                benchmarkOptions.getReverseOrder().value(options)),
+                        new CugOakTest(benchmarkOptions.getRunAsAdmin().value(options),
+                                benchmarkOptions.getItemsToRead().value(options),
+                                benchmarkOptions.getRandomUser().value(options),
+                                benchmarkOptions.getSupportedPaths().values(options),
+                                benchmarkOptions.getReverseOrder().value(options)),
                         new PrinicipalBasedReadTest(
-                    itemsToRead.value(options),
-                    numberOfInitialAce.value(options),
-                    numberOfUsers.value(options),
-                    entriesForEachPrincipal.value(options),
-                    reverseOrder.value(options),
-                    compositionType.value(options),
-                    useAggregationFilter.value(options),
-                    report.value(options)),
+                                benchmarkOptions.getItemsToRead().value(options),
+                                benchmarkOptions.getNumberOfInitialAce().value(options),
+                                benchmarkOptions.getNumberOfUsers().value(options),
+                                benchmarkOptions.getEntriesForEachPrincipal().value(options),
+                                benchmarkOptions.getReverseOrder().value(options),
+                                benchmarkOptions.getCompositionType().value(options),
+                                benchmarkOptions.getUseAggregationFilter().value(options),
+                                benchmarkOptions.getReport().value(options)),
                         new PermissionEvaluationTest(
-                    itemsToRead.value(options),
-                    numberOfInitialAce.value(options),
-                    numberOfUsers.value(options),
-                    entriesForEachPrincipal.value(options),
-                    reverseOrder.value(options),
-                    compositionType.value(options),
-                    useAggregationFilter.value(options),
-                    report.value(options)),
+                                benchmarkOptions.getItemsToRead().value(options),
+                                benchmarkOptions.getNumberOfInitialAce().value(options),
+                                benchmarkOptions.getNumberOfUsers().value(options),
+                                benchmarkOptions.getEntriesForEachPrincipal().value(options),
+                                benchmarkOptions.getReverseOrder().value(options),
+                                benchmarkOptions.getCompositionType().value(options),
+                                benchmarkOptions.getUseAggregationFilter().value(options),
+                                benchmarkOptions.getReport().value(options)),
                         new HasItemGetItemIsModifiedTest(
-                    itemsToRead.value(options),
-                    numberOfInitialAce.value(options),
-                    numberOfUsers.value(options),
-                    entriesForEachPrincipal.value(options),
-                    reverseOrder.value(options),
-                    compositionType.value(options),
-                    useAggregationFilter.value(options),
-                    report.value(options)),
-            new EagerCacheSizeTest(itemsToRead.value(options),
-                    repeatedRead.value(options),
-                    numberOfInitialAce.value(options),
-                    numberOfUsers.value(options),
+                                benchmarkOptions.getItemsToRead().value(options),
+                                benchmarkOptions.getNumberOfInitialAce().value(options),
+                                benchmarkOptions.getNumberOfUsers().value(options),
+                                benchmarkOptions.getEntriesForEachPrincipal().value(options),
+                                benchmarkOptions.getReverseOrder().value(options),
+                                benchmarkOptions.getCompositionType().value(options),
+                                benchmarkOptions.getUseAggregationFilter().value(options),
+                                benchmarkOptions.getReport().value(options)),
+                        new EagerCacheSizeTest(benchmarkOptions.getItemsToRead().value(options),
+                                benchmarkOptions.getRepeatedRead().value(options),
+                                benchmarkOptions.getNumberOfInitialAce().value(options),
+                                benchmarkOptions.getNumberOfUsers().value(options),
                                 cacheSize,
-                    report.value(options)),
+                                benchmarkOptions.getReport().value(options)),
                         new ConcurrentReadDeepTreeTest(
-                    runAsAdmin.value(options),
-                    itemsToRead.value(options),
-                    report.value(options)),
+                                benchmarkOptions.getRunAsAdmin().value(options),
+                                benchmarkOptions.getItemsToRead().value(options),
+                                benchmarkOptions.getReport().value(options)),
                         new ConcurrentReadSinglePolicyTreeTest(
-                    runAsAdmin.value(options),
-                    itemsToRead.value(options),
-                    report.value(options)),
+                                benchmarkOptions.getRunAsAdmin().value(options),
+                                benchmarkOptions.getItemsToRead().value(options),
+                                benchmarkOptions.getReport().value(options)),
                         new ConcurrentReadAccessControlledTreeTest(
-                    runAsAdmin.value(options),
-                    itemsToRead.value(options),
-                    report.value(options)),
+                                benchmarkOptions.getRunAsAdmin().value(options),
+                                benchmarkOptions.getItemsToRead().value(options),
+                                benchmarkOptions.getReport().value(options)),
                         new ConcurrentReadAccessControlledTreeTest2(
-                    runAsAdmin.value(options),
-                    itemsToRead.value(options),
-                    report.value(options)),
+                                benchmarkOptions.getRunAsAdmin().value(options),
+                                benchmarkOptions.getItemsToRead().value(options),
+                                benchmarkOptions.getReport().value(options)),
                         new ConcurrentReadRandomNodeAndItsPropertiesTest(
-                    runAsAdmin.value(options),
-                    itemsToRead.value(options),
-                    report.value(options)),
+                                benchmarkOptions.getRunAsAdmin().value(options),
+                                benchmarkOptions.getItemsToRead().value(options),
+                                benchmarkOptions.getReport().value(options)),
                         new ConcurrentHasPermissionTest(
-                    runAsAdmin.value(options),
-                    itemsToRead.value(options),
-                    report.value(options)),
+                                benchmarkOptions.getRunAsAdmin().value(options),
+                                benchmarkOptions.getItemsToRead().value(options),
+                                benchmarkOptions.getReport().value(options)),
                         new ConcurrentHasPermissionTest2(
-                    runAsAdmin.value(options),
-                    itemsToRead.value(options),
-                    report.value(options)),
+                                benchmarkOptions.getRunAsAdmin().value(options),
+                                benchmarkOptions.getItemsToRead().value(options),
+                                benchmarkOptions.getReport().value(options)),
                         new ManyUserReadTest(
-                    runAsAdmin.value(options),
-                    itemsToRead.value(options),
-                    report.value(options),
-                    randomUser.value(options)),
+                                benchmarkOptions.getRunAsAdmin().value(options),
+                                benchmarkOptions.getItemsToRead().value(options),
+                                benchmarkOptions.getReport().value(options),
+                                benchmarkOptions.getRandomUser().value(options)),
                         new ReadWithMembershipTest(
-                    itemsToRead.value(options),
-                    report.value(options),
-                    numberOfGroups.value(options),
-                    numberOfInitialAce.value(options)),
+                                benchmarkOptions.getItemsToRead().value(options),
+                                benchmarkOptions.getReport().value(options),
+                                benchmarkOptions.getNumberOfGroups().value(options),
+                                benchmarkOptions.getNumberOfInitialAce().value(options)),
                         new ConcurrentTraversalTest(
-                    runAsAdmin.value(options),
-                    itemsToRead.value(options),
-                    report.value(options),
-                    randomUser.value(options)),
-            new ConcurrentWriteACLTest(itemsToRead.value(options)),
-            new ConcurrentEveryoneACLTest(runAsAdmin.value(options), itemsToRead.value(options)),
-            new AceCreationTest(batchSize.value(options), numberOfInitialAce.value(options), transientWrites.value(options)),
+                                benchmarkOptions.getRunAsAdmin().value(options),
+                                benchmarkOptions.getItemsToRead().value(options),
+                                benchmarkOptions.getReport().value(options),
+                                benchmarkOptions.getRandomUser().value(options)),
+                        new ConcurrentWriteACLTest(benchmarkOptions.getItemsToRead().value(options)),
+                        new ConcurrentEveryoneACLTest(benchmarkOptions.getRunAsAdmin().value(options), benchmarkOptions.getItemsToRead().value(options)),
+                        new AceCreationTest(benchmarkOptions.getBatchSize().value(options), benchmarkOptions.getNumberOfInitialAce().value(options),
+                                benchmarkOptions.getTransientWrites().value(options)),
 
                         ReadManyTest.linear("LinearReadEmpty", 1, ReadManyTest.EMPTY),
                         ReadManyTest.linear("LinearReadFiles", 1, ReadManyTest.FILES),
@@ -450,106 +316,113 @@ public class BenchmarkRunner {
                         new GetPoliciesTest(),
                         new ConcurrentFileWriteTest(),
                         new GetAuthorizableByIdTest(
-                    numberOfUsers.value(options),
-                    flatStructure.value(options)),
+                                benchmarkOptions.getNumberOfUsers().value(options),
+                                benchmarkOptions.getFlatStructure().value(options)),
                         new GetAuthorizableByPrincipalTest(
-                    numberOfUsers.value(options),
-                    flatStructure.value(options)),
+                                benchmarkOptions.getNumberOfUsers().value(options),
+                                benchmarkOptions.getFlatStructure().value(options)),
                         new GetPrincipalTest(
-                    numberOfUsers.value(options),
-                    flatStructure.value(options)),
+                                benchmarkOptions.getNumberOfUsers().value(options),
+                                benchmarkOptions.getFlatStructure().value(options)),
                         new GetGroupPrincipalsTest(
-                    numberOfGroups.value(options),
-                    nestedGroups.value(options)),
+                                benchmarkOptions.getNumberOfGroups().value(options),
+                                benchmarkOptions.getNestedGroups().value(options)),
 
                         // benchmarks adding multiple or single members
                         new AddMembersTest(
-                    numberOfUsers.value(options),
-                    batchSize.value(options),
-                    importBehavior.value(options)),
+                                benchmarkOptions.getNumberOfUsers().value(options),
+                                benchmarkOptions.getBatchSize().value(options),
+                                benchmarkOptions.getImportBehavior().value(options)),
                         new AddMemberTest(
-                    numberOfUsers.value(options),
-                    batchSize.value(options)),
+                                benchmarkOptions.getNumberOfUsers().value(options),
+                                benchmarkOptions.getBatchSize().value(options)),
                         new AddUniqueMembersTest(
-                    numberOfUsers.value(options),
-                    batchSize.value(options)),
+                                benchmarkOptions.getNumberOfUsers().value(options),
+                                benchmarkOptions.getBatchSize().value(options)),
 
                         // benchmarks removing multiple or single members
                         new RemoveMembersTest(
-                    numberOfUsers.value(options),
-                    batchSize.value(options)),
+                                benchmarkOptions.getNumberOfUsers().value(options),
+                                benchmarkOptions.getBatchSize().value(options)),
                         new RemoveMemberTest(
-                    numberOfUsers.value(options),
-                    batchSize.value(options)),
+                                benchmarkOptions.getNumberOfUsers().value(options),
+                                benchmarkOptions.getBatchSize().value(options)),
 
                         // benchmark testing isMember/isDeclared member; each user only being member of 1 group
                         new IsMemberTest(
-                    numberOfUsers.value(options),
-                    nestedGroups.value(options)),
+                                benchmarkOptions.getNumberOfUsers().value(options),
+                                benchmarkOptions.getNestedGroups().value(options)),
                         new IsDeclaredMemberTest(
-                    numberOfUsers.value(options),
-                    nestedGroups.value(options)),
+                                benchmarkOptions.getNumberOfUsers().value(options),
+                                benchmarkOptions.getNestedGroups().value(options)),
 
                         // 4 benchmarks with the same setup test various membership operations.
                         new MemberDeclaredMemberOf(
-                    numberOfGroups.value(options),
-                    nestedGroups.value(options),
-                    numberOfUsers.value(options)),
+                                benchmarkOptions.getNumberOfGroups().value(options),
+                                benchmarkOptions.getNestedGroups().value(options),
+                                benchmarkOptions.getNumberOfUsers().value(options)),
                         new MemberMemberOf(
-                    numberOfGroups.value(options),
-                    nestedGroups.value(options),
-                    numberOfUsers.value(options)),
+                                benchmarkOptions.getNumberOfGroups().value(options),
+                                benchmarkOptions.getNestedGroups().value(options),
+                                benchmarkOptions.getNumberOfUsers().value(options)),
                         new MemberIsDeclaredMember(
-                    numberOfGroups.value(options),
-                    nestedGroups.value(options),
-                    numberOfUsers.value(options)),
+                                benchmarkOptions.getNumberOfGroups().value(options),
+                                benchmarkOptions.getNestedGroups().value(options),
+                                benchmarkOptions.getNumberOfUsers().value(options)),
                         new MemberIsMember(
-                    numberOfGroups.value(options),
-                    nestedGroups.value(options),
-                    numberOfUsers.value(options)),
-
-            new FullTextSearchTest(
-                    wikipedia.value(options),
-                    flatStructure.value(options),
-                    report.value(options), withStorage.value(options)),
-            new FullTextSolrSearchTest(
-                    wikipedia.value(options),
-                    flatStructure.value(options),
-                    report.value(options), withStorage.value(options), withServer.value(options)),
-            new FindAuthorizableWithScopeTest(numberOfUsers.value(options), numberOfGroups.value(options), queryMaxCount.value(options), setScope.value(options), declaredMembership.value(options), runAsAdmin.value(options)),
-            new LucenePropertyFullTextTest(
-                wikipedia.value(options),
-                flatStructure.value(options),
-                report.value(options), withStorage.value(options)),
-            new LucenePropertyFTSeparated(
-                wikipedia.value(options),
-                flatStructure.value(options),
-                report.value(options), withStorage.value(options)),
+                                benchmarkOptions.getNumberOfGroups().value(options),
+                                benchmarkOptions.getNestedGroups().value(options),
+                                benchmarkOptions.getNumberOfUsers().value(options)),
+                        // TODO - remove this from here and implement runner in oak-benchmarks-solr
+                        // (Not high priority now - do it after elastic implementation)
+                        /*new FullTextSolrSearchTest(
+                                benchmarkOptions.getWikipedia().value(options),
+                                benchmarkOptions.getFlatStructure().value(options),
+                                benchmarkOptions.getReport().value(options), benchmarkOptions.getWithStorage().value(options),
+                                benchmarkOptions.getWithServer().value(options)),*/
+                        new FindAuthorizableWithScopeTest(benchmarkOptions.getNumberOfUsers().value(options),
+                                benchmarkOptions.getNumberOfGroups().value(options),
+                                benchmarkOptions.getQueryMaxCount().value(options), benchmarkOptions.getSetScope().value(options),
+                                benchmarkOptions.getDeclaredMembership().value(options),
+                                benchmarkOptions.getRunAsAdmin().value(options)),
                         new ReplicaCrashResilienceTest(),
 
                         // benchmarks for oak-auth-external
-                new ExternalLoginTest(numberOfUsers.value(options), numberOfGroups.value(options),
-                        expiration.value(options), dynamicMembership.value(options), autoMembership.values(options),
-                        report.value(options), statsProvider),
-            new SyncAllExternalUsersTest(numberOfUsers.value(options), numberOfGroups.value(options), expiration.value(options), dynamicMembership.value(options), autoMembership.values(options)),
-            new SyncAllUsersTest(numberOfUsers.value(options), numberOfGroups.value(options), expiration.value(options), dynamicMembership.value(options), autoMembership.values(options)),
-            new SyncExternalUsersTest(numberOfUsers.value(options), numberOfGroups.value(options), expiration.value(options), dynamicMembership.value(options), autoMembership.values(options), batchSize.value(options)),
-            new PrincipalNameResolutionTest(numberOfUsers.value(options), numberOfGroups.value(options), expiration.value(options), roundtripDelay.value(options)),
-            new ListIdentitiesTest(numberOfUsers.value(options)),
-
-            new HybridIndexTest(base.value(options), statsProvider),
+                        new ExternalLoginTest(benchmarkOptions.getNumberOfUsers().value(options),
+                                benchmarkOptions.getNumberOfGroups().value(options),
+                                benchmarkOptions.getExpiration().value(options), benchmarkOptions.getDynamicMembership().value(options),
+                                benchmarkOptions.getAutoMembership().values(options),
+                                benchmarkOptions.getReport().value(options), statsProvider),
+                        new SyncAllExternalUsersTest(benchmarkOptions.getNumberOfUsers().value(options),
+                                benchmarkOptions.getNumberOfGroups().value(options), benchmarkOptions.getExpiration().value(options),
+                                benchmarkOptions.getDynamicMembership().value(options),
+                                benchmarkOptions.getAutoMembership().values(options)),
+                        new SyncAllUsersTest(benchmarkOptions.getNumberOfUsers().value(options),
+                                benchmarkOptions.getNumberOfGroups().value(options), benchmarkOptions.getExpiration().value(options),
+                                benchmarkOptions.getDynamicMembership().value(options),
+                                benchmarkOptions.getAutoMembership().values(options)),
+                        new SyncExternalUsersTest(benchmarkOptions.getNumberOfUsers().value(options),
+                                benchmarkOptions.getNumberOfGroups().value(options), benchmarkOptions.getExpiration().value(options),
+                                benchmarkOptions.getDynamicMembership().value(options),
+                                benchmarkOptions.getAutoMembership().values(options), benchmarkOptions.getBatchSize().value(options)),
+                        new PrincipalNameResolutionTest(benchmarkOptions.getNumberOfUsers().value(options),
+                                benchmarkOptions.getNumberOfGroups().value(options), benchmarkOptions.getExpiration().value(options),
+                                benchmarkOptions.getRoundtripDelay().value(options)),
+                        new ListIdentitiesTest(benchmarkOptions.getNumberOfUsers().value(options)),
                         new BundlingNodeTest(),
                         new PersistentCacheTest(statsProvider),
                         new StringWriteTest(),
                         new BasicWriteTest(),
                         new CanReadNonExisting(),
-            new IsNodeTypeTest(runAsAdmin.value(options)),
+                        new IsNodeTypeTest(benchmarkOptions.getRunAsAdmin().value(options)),
                         new SetPropertyTransientTest(),
                         new GetURITest(),
                         new ISO8601FormatterTest()
-        };
+                )
+        );
 
-        Set<String> argset = Sets.newHashSet(nonOption.values(options));
+
+        Set<String> argset = Sets.newHashSet(benchmarkOptions.getNonOption().values(options));
         List<RepositoryFixture> fixtures = Lists.newArrayList();
         for (RepositoryFixture fixture : allFixtures) {
             if (argset.remove(fixture.toString())) {
@@ -577,14 +450,14 @@ public class BenchmarkRunner {
 
         if (argset.isEmpty()) {
             PrintStream out = null;
-            if (options.has(csvFile)) {
-                out = new PrintStream(FileUtils.openOutputStream(csvFile.value(options), true));
+            if (options.has(benchmarkOptions.getCsvFile())) {
+                out = new PrintStream(FileUtils.openOutputStream(benchmarkOptions.getCsvFile().value(options), true));
             }
             for (Benchmark benchmark : benchmarks) {
                 if (benchmark instanceof CSVResultGenerator) {
                     ((CSVResultGenerator) benchmark).setPrintStream(out);
                 }
-                benchmark.run(fixtures, options.valuesOf(concurrency));
+                benchmark.run(fixtures, options.valuesOf(benchmarkOptions.getConcurrency()));
             }
             if (out != null) {
                 out.close();
@@ -615,6 +488,18 @@ public class BenchmarkRunner {
         }
     }
 
+    protected static void initOptionSet(String[] args) throws IOException {
+        if (!initFlag) {
+            benchmarkOptions = new BenchmarkOptions(parser);
+            options = parser.parse(args);
+            initFlag = true;
+        }
+    }
+
+    protected static void addToBenchMarkList(List<Benchmark> benchmarks) {
+        allBenchmarks.addAll(benchmarks);
+    }
+
     private static void configure(RepositoryFixture fixture, StatisticsProvider statsProvider) {
         if (fixture instanceof OakRepositoryFixture) {
             ((OakRepositoryFixture) fixture).setStatisticsProvider(statsProvider);
@@ -630,9 +515,15 @@ public class BenchmarkRunner {
         return tmp.toString();
     }
 
-    private static MetricStatisticsProvider getStatsProvider(){
+    protected static StatisticsProvider getStatsProvider() {
+        if (statsProvider == null) {
             ScheduledExecutorService executorService = MoreExecutors.getExitingScheduledExecutorService(
                     (ScheduledThreadPoolExecutor) Executors.newScheduledThreadPool(1));
+
             return new MetricStatisticsProvider(null, executorService);
+        } else {
+            return statsProvider;
+        }
+
     }
 }
diff --git oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/benchmark/FullTextSearchTest.java oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/benchmark/FullTextSearchTest.java
index 5be07db..bd58f7a 100644
--- oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/benchmark/FullTextSearchTest.java
+++ oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/benchmark/FullTextSearchTest.java
@@ -33,7 +33,6 @@ import java.util.regex.Matcher;
 import java.util.regex.Pattern;
 
 import javax.jcr.Node;
-import javax.jcr.Repository;
 import javax.jcr.Session;
 import javax.jcr.query.Query;
 import javax.jcr.query.QueryManager;
@@ -41,18 +40,7 @@ import javax.jcr.query.QueryResult;
 import javax.jcr.query.RowIterator;
 
 import org.apache.commons.io.FileUtils;
-import org.apache.jackrabbit.oak.Oak;
 import org.apache.jackrabbit.oak.benchmark.wikipedia.WikipediaImport;
-import org.apache.jackrabbit.oak.fixture.JcrCreator;
-import org.apache.jackrabbit.oak.fixture.OakRepositoryFixture;
-import org.apache.jackrabbit.oak.fixture.RepositoryFixture;
-import org.apache.jackrabbit.oak.jcr.Jcr;
-import org.apache.jackrabbit.oak.plugins.index.lucene.IndexCopier;
-import org.apache.jackrabbit.oak.plugins.index.lucene.LuceneIndexEditorProvider;
-import org.apache.jackrabbit.oak.plugins.index.lucene.LuceneIndexProvider;
-import org.apache.jackrabbit.oak.plugins.index.lucene.util.LuceneInitializerHelper;
-import org.apache.jackrabbit.oak.spi.commit.Observer;
-import org.apache.jackrabbit.oak.spi.query.QueryIndexProvider;
 
 public class FullTextSearchTest extends AbstractTest<FullTextSearchTest.TestContext> {
 
@@ -65,8 +53,6 @@ public class FullTextSearchTest extends AbstractTest<FullTextSearchTest.TestCont
 
     private int maxSampleSize = 100;
 
-    private final boolean disableCopyOnRead = Boolean.getBoolean("disableCopyOnRead");
-
     private final WikipediaImport importer;
 
     private final Set<String> sampleSet = newHashSet();
@@ -84,9 +70,9 @@ public class FullTextSearchTest extends AbstractTest<FullTextSearchTest.TestCont
      */
     protected Boolean storageEnabled;
 
-    private ExecutorService executorService = Executors.newFixedThreadPool(2);
+    protected ExecutorService executorService = Executors.newFixedThreadPool(2);
 
-    private File indexCopierDir;
+    protected File indexCopierDir;
 
     public FullTextSearchTest(File dump, boolean flat, boolean doReport, Boolean storageEnabled) {
         this.importer = new WikipediaImport(dump, flat, doReport) {
@@ -175,36 +161,6 @@ public class FullTextSearchTest extends AbstractTest<FullTextSearchTest.TestCont
         return words;
     }
 
-    @Override
-    protected Repository[] createRepository(RepositoryFixture fixture) throws Exception {
-        if (fixture instanceof OakRepositoryFixture) {
-            return ((OakRepositoryFixture) fixture).setUpCluster(1, new JcrCreator() {
-                @Override
-                public Jcr customize(Oak oak) {
-                    LuceneIndexProvider provider = createLuceneIndexProvider();
-                    oak.with((QueryIndexProvider) provider)
-                            .with((Observer) provider)
-                            .with(new LuceneIndexEditorProvider())
-                            .with(new LuceneInitializerHelper("luceneGlobal", storageEnabled));
-                    return new Jcr(oak);
-                }
-            });
-        }
-        return super.createRepository(fixture);
-    }
-
-    private LuceneIndexProvider createLuceneIndexProvider() {
-        if (!disableCopyOnRead) {
-            try {
-                IndexCopier copier = new IndexCopier(executorService, indexCopierDir, true);
-                return new LuceneIndexProvider(copier);
-            } catch (IOException e) {
-                throw new RuntimeException(e);
-            }
-        }
-        return new LuceneIndexProvider();
-    }
-
     private File createTemporaryFolder(File parentFolder){
         File createdFolder = null;
         try {
diff --git oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/benchmark/FullTextSolrSearchTest.java oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/benchmark/FullTextSolrSearchTest.java
deleted file mode 100644
index c807706..0000000
--- oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/benchmark/FullTextSolrSearchTest.java
+++ /dev/null
@@ -1,139 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *   http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-package org.apache.jackrabbit.oak.benchmark;
-
-import java.io.File;
-import java.io.FileOutputStream;
-import java.io.InputStream;
-import java.io.StringReader;
-import javax.jcr.Repository;
-
-import org.apache.commons.io.FileUtils;
-import org.apache.commons.io.IOUtils;
-import org.apache.jackrabbit.oak.Oak;
-import org.apache.jackrabbit.oak.fixture.JcrCreator;
-import org.apache.jackrabbit.oak.fixture.OakRepositoryFixture;
-import org.apache.jackrabbit.oak.fixture.RepositoryFixture;
-import org.apache.jackrabbit.oak.jcr.Jcr;
-import org.apache.jackrabbit.oak.plugins.index.solr.configuration.DefaultSolrConfiguration;
-import org.apache.jackrabbit.oak.plugins.index.solr.configuration.EmbeddedSolrServerConfiguration;
-import org.apache.jackrabbit.oak.plugins.index.solr.configuration.OakSolrConfiguration;
-import org.apache.jackrabbit.oak.plugins.index.solr.configuration.OakSolrConfigurationProvider;
-import org.apache.jackrabbit.oak.plugins.index.solr.configuration.RemoteSolrServerConfiguration;
-import org.apache.jackrabbit.oak.plugins.index.solr.configuration.nodestate.NodeStateSolrServersObserver;
-import org.apache.jackrabbit.oak.plugins.index.solr.index.SolrIndexEditorProvider;
-import org.apache.jackrabbit.oak.plugins.index.solr.query.SolrQueryIndexProvider;
-import org.apache.jackrabbit.oak.plugins.index.solr.server.EmbeddedSolrServerProvider;
-import org.apache.jackrabbit.oak.plugins.index.solr.server.SolrServerProvider;
-import org.apache.jackrabbit.oak.plugins.index.solr.util.SolrIndexInitializer;
-import org.apache.solr.client.solrj.SolrClient;
-import org.apache.solr.client.solrj.embedded.EmbeddedSolrServer;
-import org.jetbrains.annotations.NotNull;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-public class FullTextSolrSearchTest extends FullTextSearchTest {
-
-    private final Logger log = LoggerFactory.getLogger(getClass());
-
-    private SolrServerProvider serverProvider;
-    private String server;
-
-    public FullTextSolrSearchTest(File dump, boolean flat, boolean doReport, Boolean storageEnabled, String server) {
-        super(dump, flat, doReport, storageEnabled);
-        this.server = server;
-    }
-
-    @Override
-    protected Repository[] createRepository(RepositoryFixture fixture) throws Exception {
-        initializeProvider();
-        if (fixture instanceof OakRepositoryFixture) {
-            return ((OakRepositoryFixture) fixture).setUpCluster(1, new JcrCreator() {
-                @Override
-                public Jcr customize(Oak oak) {
-                    OakSolrConfigurationProvider configurationProvider = new OakSolrConfigurationProvider() {
-                        @NotNull
-                        public OakSolrConfiguration getConfiguration() {
-                            return new DefaultSolrConfiguration() {
-                                @Override
-                                public int getRows() {
-                                    return 50;
-                                }
-                            };
-                        }
-                    };
-                    oak.with(new SolrQueryIndexProvider(serverProvider, configurationProvider))
-                        .with(new NodeStateSolrServersObserver())
-                        .with(new SolrIndexEditorProvider(serverProvider, configurationProvider))
-                        .with(new SolrIndexInitializer(false));
-                    return new Jcr(oak);
-                }
-            });
-        }
-        return super.createRepository(fixture);
-    }
-
-    private void initializeProvider() throws Exception {
-        if (server == null || "default".equals(server)) {
-            log.info("spawning Solr locally");
-            serverProvider = createEmbeddedSolrServerProvider(true);
-        } else if (server != null && "embedded".equals(server)) {
-            log.info("using embedded Solr");
-            serverProvider = createEmbeddedSolrServerProvider(false);
-        } else if (server != null && (server.startsWith("http") || server.matches("\\w+\\:\\d{3,5}"))) {
-            log.info("using remote Solr {}", server);
-            RemoteSolrServerConfiguration remoteSolrServerConfiguration = new RemoteSolrServerConfiguration(
-                    server, "oak", 2, 2, null, 10, 10, server);
-            serverProvider = remoteSolrServerConfiguration.getProvider();
-        } else {
-            throw new IllegalArgumentException("server parameter value must be either 'embedded', 'default', an URL or an host:port String");
-        }
-    }
-
-    private EmbeddedSolrServerProvider createEmbeddedSolrServerProvider(boolean http) throws Exception {
-        String tempDirectoryPath = FileUtils.getTempDirectoryPath();
-        File solrHome = new File(tempDirectoryPath, "solr" + System.nanoTime());
-        EmbeddedSolrServerConfiguration embeddedSolrServerConfiguration = new EmbeddedSolrServerConfiguration(solrHome.getAbsolutePath(), "oak");
-        if (http) {
-            embeddedSolrServerConfiguration = embeddedSolrServerConfiguration.withHttpConfiguration("/solr", 8983);
-        }
-        EmbeddedSolrServerProvider embeddedSolrServerProvider = embeddedSolrServerConfiguration.getProvider();
-        SolrClient solrServer = embeddedSolrServerProvider.getSolrServer();
-        if (storageEnabled != null && !storageEnabled) {
-            // change schema.xml and reload the core
-            File schemaXML = new File(solrHome.getAbsolutePath() + "/oak/conf", "schema.xml");
-            InputStream inputStream = getClass().getResourceAsStream("/solr/oak/conf/schema.xml");
-            String schemaString = IOUtils.toString(inputStream).replace("<dynamicField name=\"*\" type=\"text_general\" indexed=\"true\" stored=\"true\" multiValued=\"true\"/>",
-                    "<dynamicField name=\"*\" type=\"text_general\" indexed=\"true\" stored=\"false\" multiValued=\"true\"/>");
-            FileOutputStream fileOutputStream = new FileOutputStream(schemaXML);
-            IOUtils.copy(new StringReader(schemaString), fileOutputStream);
-            fileOutputStream.flush();
-            ((EmbeddedSolrServer) solrServer).getCoreContainer().reload("oak");
-        }
-        return embeddedSolrServerProvider;
-    }
-
-    @Override
-    protected void afterSuite() throws Exception {
-        SolrClient solrServer = serverProvider.getSolrServer();
-        if (solrServer != null) {
-            solrServer.close();
-        }
-    }
-}
diff --git oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/benchmark/HybridIndexTest.java oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/benchmark/HybridIndexTest.java
deleted file mode 100644
index 1361f94..0000000
--- oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/benchmark/HybridIndexTest.java
+++ /dev/null
@@ -1,590 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *   http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-
-package org.apache.jackrabbit.oak.benchmark;
-
-import java.io.File;
-import java.io.IOException;
-import java.lang.reflect.Field;
-import java.util.ArrayList;
-import java.util.Arrays;
-import java.util.List;
-import java.util.Queue;
-import java.util.Random;
-import java.util.concurrent.Executors;
-import java.util.concurrent.LinkedBlockingDeque;
-import java.util.concurrent.ExecutorService;
-import java.util.concurrent.ThreadPoolExecutor;
-import java.util.concurrent.TimeUnit;
-import java.util.concurrent.atomic.AtomicInteger;
-import java.util.function.Predicate;
-
-import javax.jcr.Node;
-import javax.jcr.Repository;
-import javax.jcr.RepositoryException;
-import javax.jcr.Session;
-import javax.jcr.query.Query;
-import javax.jcr.query.QueryManager;
-import javax.jcr.query.QueryResult;
-
-import com.google.common.base.Joiner;
-import com.google.common.collect.Iterators;
-import com.google.common.collect.Lists;
-import com.google.common.util.concurrent.MoreExecutors;
-import org.apache.commons.io.FileUtils;
-import org.apache.jackrabbit.oak.Oak;
-import org.apache.jackrabbit.oak.api.Type;
-import org.apache.jackrabbit.oak.api.jmx.IndexStatsMBean;
-import org.apache.jackrabbit.oak.fixture.JcrCreator;
-import org.apache.jackrabbit.oak.fixture.OakRepositoryFixture;
-import org.apache.jackrabbit.oak.fixture.RepositoryFixture;
-import org.apache.jackrabbit.oak.jcr.Jcr;
-import org.apache.jackrabbit.oak.plugins.index.AsyncIndexInfoService;
-import org.apache.jackrabbit.oak.plugins.index.AsyncIndexInfoServiceImpl;
-import org.apache.jackrabbit.oak.plugins.index.AsyncIndexUpdate;
-import org.apache.jackrabbit.oak.plugins.index.IndexConstants;
-import org.apache.jackrabbit.oak.plugins.index.IndexPathService;
-import org.apache.jackrabbit.oak.plugins.index.IndexPathServiceImpl;
-import org.apache.jackrabbit.oak.plugins.index.IndexUtils;
-import org.apache.jackrabbit.oak.plugins.index.lucene.IndexCopier;
-import org.apache.jackrabbit.oak.plugins.index.lucene.IndexTracker;
-import org.apache.jackrabbit.oak.plugins.index.lucene.LuceneIndexConstants;
-import org.apache.jackrabbit.oak.plugins.index.lucene.LuceneIndexEditorProvider;
-import org.apache.jackrabbit.oak.plugins.index.lucene.LuceneIndexProvider;
-import org.apache.jackrabbit.oak.plugins.index.lucene.hybrid.DocumentQueue;
-import org.apache.jackrabbit.oak.plugins.index.lucene.hybrid.LocalIndexObserver;
-import org.apache.jackrabbit.oak.plugins.index.lucene.hybrid.NRTIndexFactory;
-import org.apache.jackrabbit.oak.plugins.index.lucene.property.PropertyIndexCleaner;
-import org.apache.jackrabbit.oak.plugins.index.lucene.reader.DefaultIndexReaderFactory;
-import org.apache.jackrabbit.oak.plugins.index.lucene.reader.LuceneIndexReaderFactory;
-import org.apache.jackrabbit.oak.plugins.index.lucene.util.IndexDefinitionBuilder;
-import org.apache.jackrabbit.oak.plugins.index.lucene.util.IndexDefinitionBuilder.PropertyRule;
-import org.apache.jackrabbit.oak.plugins.index.search.FulltextIndexConstants;
-import org.apache.jackrabbit.oak.spi.commit.BackgroundObserver;
-import org.apache.jackrabbit.oak.spi.lifecycle.RepositoryInitializer;
-import org.apache.jackrabbit.oak.spi.mount.MountInfoProvider;
-import org.apache.jackrabbit.oak.spi.mount.Mounts;
-import org.apache.jackrabbit.oak.spi.query.QueryIndexProvider;
-import org.apache.jackrabbit.oak.spi.state.NodeBuilder;
-import org.apache.jackrabbit.oak.spi.state.NodeStore;
-import org.apache.jackrabbit.oak.spi.whiteboard.Registration;
-import org.apache.jackrabbit.oak.spi.whiteboard.Whiteboard;
-import org.apache.jackrabbit.oak.spi.whiteboard.WhiteboardUtils;
-import org.apache.jackrabbit.oak.stats.Clock;
-import org.apache.jackrabbit.oak.stats.StatisticsProvider;
-import org.jetbrains.annotations.NotNull;
-import org.jetbrains.annotations.Nullable;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-import static com.google.common.base.Preconditions.checkNotNull;
-import static java.util.Collections.singleton;
-import static java.util.Collections.singletonList;
-import static org.apache.jackrabbit.oak.plugins.index.IndexConstants.DECLARING_NODE_TYPES;
-import static org.apache.jackrabbit.oak.plugins.index.IndexConstants.INDEX_DEFINITIONS_NODE_TYPE;
-import static org.apache.jackrabbit.oak.spi.nodetype.NodeTypeConstants.NT_OAK_UNSTRUCTURED;
-import static org.apache.jackrabbit.oak.spi.whiteboard.WhiteboardUtils.scheduleWithFixedDelay;
-
-public class HybridIndexTest extends AbstractTest<HybridIndexTest.TestContext> {
-    enum Status {
-        NONE, STARTING, STARTED, STOPPING, STOPPED, ABORTED;
-
-        private int count;
-
-        public void inc(){
-            count++;
-        }
-
-        public int count(){
-            return count;
-        }
-
-        public Status next(){
-            Status[] ss = values();
-            if (ordinal() == ss.length - 1){
-                return ss[0];
-            }
-            return ss[ordinal() + 1];
-        }
-    }
-
-    private final Random random = new Random(42); //fixed seed
-    private String indexedPropName = "foo";
-    private int nodesPerIteration = Status.values().length;
-    private int numOfIndexes = Integer.getInteger("numOfIndexes", 10);
-    private int refreshDeltaMillis = Integer.getInteger("refreshDeltaMillis", 1000);
-    private int asyncInterval = Integer.getInteger("asyncInterval", 5);
-    private int cleanerIntervalInSecs = Integer.getInteger("cleanerIntervalInSecs", 10);
-    private int queueSize = Integer.getInteger("queueSize", 1000);
-    private boolean hybridIndexEnabled = Boolean.getBoolean("hybridIndexEnabled");
-    private boolean dumpStats = Boolean.getBoolean("dumpStats");
-    private boolean useOakCodec = Boolean.parseBoolean(System.getProperty("useOakCodec", "true"));
-    private boolean syncIndexing = Boolean.parseBoolean(System.getProperty("syncIndexing", "false"));
-    private String indexingMode = System.getProperty("indexingMode", "nrt");
-
-    private boolean searcherEnabled = Boolean.parseBoolean(System.getProperty("searcherEnabled", "true"));
-    private File indexCopierDir;
-    private IndexCopier copier;
-    private NRTIndexFactory nrtIndexFactory;
-    private LuceneIndexProvider luceneIndexProvider;
-    private LuceneIndexEditorProvider luceneEditorProvider;
-    private DocumentQueue queue;
-    private LocalIndexObserver localIndexObserver;
-    private RepositoryInitializer indexInitializer = new PropertyIndexInitializer();
-    private TestContext defaultContext;
-    private final File workDir;
-    private Whiteboard whiteboard;
-    private Searcher searcher;
-    private Mutator mutator;
-    private final AtomicInteger indexedNodeCount = new AtomicInteger();
-    private List<TestContext> contexts = new ArrayList<>();
-    private final StatisticsProvider statsProvider;
-    private final Logger log = LoggerFactory.getLogger(getClass());
-    private final ExecutorService executorService = MoreExecutors.getExitingExecutorService(
-            (ThreadPoolExecutor) Executors.newFixedThreadPool(5));
-    private final List<Registration> regs = new ArrayList<>();
-    private BackgroundObserver backgroundObserver;
-
-
-    public HybridIndexTest(File workDir, StatisticsProvider statsProvider) {
-        this.workDir = workDir;
-        this.statsProvider = statsProvider;
-    }
-
-    @Override
-    protected Repository[] createRepository(RepositoryFixture fixture) throws Exception {
-        if (fixture instanceof OakRepositoryFixture) {
-            return ((OakRepositoryFixture) fixture).setUpCluster(1, new JcrCreator() {
-                @Override
-                public Jcr customize(Oak oak) {
-                    Jcr jcr = new Jcr(oak);
-                    whiteboard = oak.getWhiteboard();
-                    prepareLuceneIndexer(workDir, getNodeStore(oak));
-
-                    backgroundObserver = new BackgroundObserver(luceneIndexProvider, executorService, 5);
-
-                    jcr.with((QueryIndexProvider) luceneIndexProvider)
-                            .with(backgroundObserver)
-                            .with(luceneEditorProvider)
-                            .with(new NodeTypeIndexFixerInitializer());
-
-                    if (hybridIndexEnabled) {
-                        jcr.with(localIndexObserver);
-                        indexInitializer = new LuceneIndexInitializer();
-                    }
-
-                    jcr.with(indexInitializer);
-
-                    //Configure the default global fulltext index as it impacts
-                    //both pure property index based setup and nrt based
-                    //So more closer to real world
-                    jcr.with(new LuceneFullTextInitializer());
-
-                    //Async indexing is enabled for both property and lucene
-                    //as for property it relies on counter index
-                    oak.withAsyncIndexing("async", asyncInterval);
-                    return jcr;
-                }
-            });
-        }
-        return super.createRepository(fixture);
-    }
-
-    @Override
-    public void beforeSuite() throws Exception {
-        if (hybridIndexEnabled) {
-            runAsyncIndex();
-        }
-        defaultContext = new TestContext();
-        contexts.add(defaultContext);
-        searcher = new Searcher();
-        mutator = new Mutator();
-
-        if (searcherEnabled) {
-            addBackgroundJob(searcher);
-        }
-
-        addBackgroundJob(mutator);
-    }
-
-    @Override
-    protected TestContext prepareThreadExecutionContext() throws RepositoryException {
-        TestContext ctx = new TestContext();
-        contexts.add(ctx);
-        return ctx;
-    }
-
-    @Override
-    protected void runTest() throws Exception {
-        runTest(defaultContext);
-    }
-
-    @Override
-    protected void runTest(TestContext ctx)  throws Exception {
-        //Create tree in breadth first fashion with each node having 50 child
-        Node parent = ctx.session.getNode(ctx.paths.remove());
-        Status status = Status.NONE;
-        for (int i = 0; i < nodesPerIteration; i++) {
-            Node child = parent.addNode(nextNodeName());
-            child.setProperty(indexedPropName, status.name());
-            ctx.session.save();
-            ctx.paths.add(child.getPath());
-            indexedNodeCount.incrementAndGet();
-            status.inc();
-            status = status.next();
-        }
-    }
-
-    @Override
-    protected void disposeThreadExecutionContext(TestContext context) throws RepositoryException {
-        context.dispose();
-    }
-
-    @Override
-    protected void afterSuite() throws Exception {
-        //TODO This to avoid issue with Indexing still running post afterSuite call
-        //TO handle this properly we would need a callback after repository shutdown
-        //and before NodeStore teardown
-        getAsyncIndexUpdate().close();
-
-        if (backgroundObserver != null){
-            backgroundObserver.close();
-        }
-
-        int sleepCount = 0;
-        while (backgroundObserver.getMBean().getQueueSize()> 0 && ++sleepCount < 100) {
-            TimeUnit.MILLISECONDS.sleep(100);
-        }
-
-        for (Registration r : regs) {
-            r.unregister();
-        }
-
-        //Close hybrid stuff after async is closed
-        if (hybridIndexEnabled){
-            queue.close();
-            nrtIndexFactory.close();
-        }
-
-        if (indexCopierDir != null) {
-            FileUtils.deleteDirectory(indexCopierDir);
-        }
-        System.out.printf("numOfIndexes: %d, refreshDeltaMillis: %d, asyncInterval: %d, queueSize: %d , " +
-                        "hybridIndexEnabled: %s, indexingMode: %s, useOakCodec: %s, cleanerIntervalInSecs: %d, " +
-                        "syncIndexing: %s %n",
-                numOfIndexes, refreshDeltaMillis, asyncInterval, queueSize, hybridIndexEnabled,
-                indexingMode, useOakCodec, cleanerIntervalInSecs, syncIndexing);
-
-        if (dumpStats) {
-            dumpStats();
-        }
-    }
-
-    @Override
-    protected String[] statsNames() {
-        return new String[]{"Searcher", "Mutator", "Indexed"};
-    }
-
-    @Override
-    protected String[] statsFormats() {
-        return new String[]{"%8d", "%8d", "%8d"};
-    }
-
-    @Override
-    protected Object[] statsValues() {
-        return new Object[]{searcher.resultSize, mutator.mutationCount, indexedNodeCount.get()};
-    }
-
-    @Override
-    protected String comment() {
-        List<String> commentElements = new ArrayList<>();
-        if (hybridIndexEnabled){
-            commentElements.add(indexingMode);
-
-            if (useOakCodec){
-                commentElements.add("oakCodec");
-            }
-            if (syncIndexing) {
-                commentElements.add("sync");
-            }
-        } else {
-            commentElements.add("property");
-        }
-
-        commentElements.add("numIdxs:"+ numOfIndexes);
-        return Joiner.on(',').join(commentElements);
-    }
-
-    protected class TestContext {
-        final Session session = loginWriter();
-        final Queue<String> paths = new LinkedBlockingDeque<>();
-
-        final Node dump;
-
-        public TestContext() throws RepositoryException {
-            dump = session.getRootNode()
-                    .addNode(nextNodeName(), NT_OAK_UNSTRUCTURED)
-                    .addNode(nextNodeName(), NT_OAK_UNSTRUCTURED)
-                    .addNode(nextNodeName(), NT_OAK_UNSTRUCTURED)
-                    .addNode(nextNodeName(), NT_OAK_UNSTRUCTURED)
-                    .addNode(nextNodeName(), NT_OAK_UNSTRUCTURED)
-                    .addNode(nextNodeName(), NT_OAK_UNSTRUCTURED);
-            session.save();
-            paths.add(dump.getPath());
-        }
-
-        public void dispose() throws RepositoryException {
-            dump.remove();
-            session.logout();
-        }
-    }
-
-    private String randomStatus() {
-        Status status = Status.values()[random.nextInt(Status.values().length)];
-        status.inc();
-        return status.name();
-    }
-
-    private void prepareLuceneIndexer(File workDir, NodeStore nodeStore) {
-        try {
-            indexCopierDir = createTemporaryFolderIn(workDir);
-            copier = new IndexCopier(executorService, indexCopierDir, true);
-        } catch (IOException e) {
-            throw new RuntimeException(e);
-        }
-
-        IndexPathService indexPathService = new IndexPathServiceImpl(nodeStore);
-        AsyncIndexInfoService asyncIndexInfoService = new AsyncIndexInfoServiceImpl(nodeStore);
-
-        nrtIndexFactory = new NRTIndexFactory(copier, Clock.SIMPLE,
-                TimeUnit.MILLISECONDS.toSeconds(refreshDeltaMillis), StatisticsProvider.NOOP);
-        MountInfoProvider mip = Mounts.defaultMountInfoProvider();
-        LuceneIndexReaderFactory indexReaderFactory = new DefaultIndexReaderFactory(mip, copier);
-
-        IndexTracker tracker = new IndexTracker(indexReaderFactory, nrtIndexFactory);
-
-        luceneIndexProvider = new LuceneIndexProvider(tracker);
-        luceneEditorProvider = new LuceneIndexEditorProvider(copier,
-                tracker,
-                null, //extractedTextCache
-                null, //augmentorFactory
-                mip);
-
-        queue = new DocumentQueue(queueSize, tracker, executorService, statsProvider);
-        localIndexObserver = new LocalIndexObserver(queue, statsProvider);
-        luceneEditorProvider.setIndexingQueue(queue);
-
-        if (syncIndexing) {
-            PropertyIndexCleaner cleaner = new PropertyIndexCleaner(nodeStore, indexPathService, asyncIndexInfoService, statsProvider);
-            regs.add(scheduleWithFixedDelay(whiteboard, cleaner,
-                    cleanerIntervalInSecs, true, true));
-        }
-
-
-        Thread.setDefaultUncaughtExceptionHandler((t, e) -> log.warn("Uncaught exception", e));
-    }
-
-    private void runAsyncIndex() {
-        checkNotNull(getAsyncIndexUpdate()).run();
-    }
-
-    private AsyncIndexUpdate getAsyncIndexUpdate() {
-        return (AsyncIndexUpdate)WhiteboardUtils.getService(whiteboard, Runnable.class, new Predicate<Runnable>() {
-                @Override
-                public boolean test(@Nullable Runnable input) {
-                    return input instanceof AsyncIndexUpdate;
-                }
-            });
-    }
-
-    private void dumpStats() {
-        IndexStatsMBean indexStats = WhiteboardUtils.getService(whiteboard, IndexStatsMBean.class);
-        System.out.println(indexStats.getConsolidatedExecutionStats());
-        String queueSize = Arrays.toString(statsProvider.getStats().getTimeSeries("HYBRID_QUEUE_SIZE", false)
-                .getValuePerSecond());
-        System.out.println("Queue size - " + queueSize);
-    }
-
-    @SuppressWarnings("ResultOfMethodCallIgnored")
-    private static File createTemporaryFolderIn(File parentFolder) throws IOException {
-        File createdFolder = File.createTempFile("oak-", "", parentFolder);
-        createdFolder.delete();
-        createdFolder.mkdir();
-        return createdFolder;
-    }
-
-    private static NodeStore getNodeStore(Oak oak) {
-        try {
-            Field f = Oak.class.getDeclaredField("store");
-            f.setAccessible(true);
-            return (NodeStore) f.get(oak);
-        } catch (Exception e) {
-            throw new RuntimeException(e);
-        }
-    }
-
-    private class PropertyIndexInitializer implements RepositoryInitializer {
-
-        @Override
-        public void initialize(@NotNull NodeBuilder builder) {
-            NodeBuilder oakIndex = IndexUtils.getOrCreateOakIndex(builder);
-            addPropIndexDefn(oakIndex, indexedPropName);
-            for (int i = 0; i < numOfIndexes - 1; i++) {
-                addPropIndexDefn(oakIndex, indexedPropName + i);
-            }
-        }
-
-        private void addPropIndexDefn(NodeBuilder parent, String propName){
-            try {
-                NodeBuilder idx = IndexUtils.createIndexDefinition(parent, propName, false,
-                        singleton(propName), null, "property", null);
-                if ( propName.equals(indexedPropName)) {
-                    idx.setProperty("tags", singletonList("fooIndex"), Type.STRINGS);
-                }
-            } catch (RepositoryException e) {
-                throw new RuntimeException(e);
-            }
-
-        }
-    }
-
-    private class LuceneIndexInitializer implements RepositoryInitializer {
-        @Override
-        public void initialize(@NotNull NodeBuilder builder) {
-            NodeBuilder oakIndex = IndexUtils.getOrCreateOakIndex(builder);
-
-            IndexDefinitionBuilder defnBuilder = new IndexDefinitionBuilder();
-            defnBuilder.evaluatePathRestrictions();
-            defnBuilder.async("async", indexingMode, "async");
-            PropertyRule pr = defnBuilder.indexRule("nt:base").property(indexedPropName).propertyIndex();
-            if (syncIndexing) {
-                pr.sync();
-            }
-            if (useOakCodec) {
-                defnBuilder.codec("oakCodec");
-            }
-
-            for (int i = 0; i < numOfIndexes - 1; i++) {
-                defnBuilder.indexRule("nt:base").property(indexedPropName + i).propertyIndex();
-            }
-
-            oakIndex.setChildNode(indexedPropName, defnBuilder.build());
-            oakIndex.child(indexedPropName).setProperty("tags", singletonList("fooIndex"), Type.STRINGS);
-        }
-    }
-
-    private class LuceneFullTextInitializer implements RepositoryInitializer {
-        @Override
-        public void initialize(@NotNull NodeBuilder builder) {
-            NodeBuilder oakIndex = IndexUtils.getOrCreateOakIndex(builder);
-
-            IndexDefinitionBuilder defnBuilder = new IndexDefinitionBuilder();
-            defnBuilder.async("async", "async");
-            defnBuilder.codec("Lucene46");
-            defnBuilder.indexRule("nt:base")
-                    .property(FulltextIndexConstants.REGEX_ALL_PROPS, true)
-                    .nodeScopeIndex();
-            oakIndex.setChildNode("globalIndex", defnBuilder.build());
-        }
-    }
-
-    private class NodeTypeIndexFixerInitializer implements RepositoryInitializer {
-
-        @Override
-        public void initialize(@NotNull NodeBuilder builder) {
-            //Due to OAK-1150 currently all nodes get indexed
-            //With explicit list on those nodes would be indexed
-            NodeBuilder nodetype = builder.getChildNode("oak:index").getChildNode("nodetype");
-            if (nodetype.exists()) {
-                List<String> nodetypes = Lists.newArrayList();
-                if (nodetype.hasProperty(DECLARING_NODE_TYPES)){
-                    nodetypes = Lists.newArrayList(nodetype.getProperty(DECLARING_NODE_TYPES).getValue(Type.STRINGS));
-                }
-
-                if (nodetypes.isEmpty()) {
-                    nodetypes.add(INDEX_DEFINITIONS_NODE_TYPE);
-                    nodetypes.add("rep:Authorizable");
-                    nodetype.setProperty(DECLARING_NODE_TYPES, nodetypes, Type.NAMES);
-                    nodetype.setProperty(IndexConstants.REINDEX_PROPERTY_NAME, true);
-                }
-            }
-
-            //Disable counter index to disable traversal
-            NodeBuilder counter = builder.getChildNode("oak:index").getChildNode("counter");
-            if (counter.exists()) {
-                counter.setProperty("type", "disabled");
-            }
-        }
-    }
-
-    private class Searcher implements Runnable {
-        final Session session = loginWriter();
-        int resultSize = 0;
-        @Override
-        public void run() {
-            try{
-                run0();
-            } catch (RepositoryException e) {
-                throw new RuntimeException(e);
-            }
-        }
-
-        private void run0() throws RepositoryException {
-            session.refresh(false);
-            QueryManager qm = session.getWorkspace().getQueryManager();
-            Query q = qm.createQuery("select * from [nt:base] where [" + indexedPropName + "] = $status " +
-                    "option(index tag fooIndex)", Query.JCR_SQL2);
-            q.bindValue("status", session.getValueFactory().createValue(randomStatus()));
-            QueryResult result = q.execute();
-
-            //With property index at time traversing index wins (somehow reporting lower cost)
-            //and that leads to warning. So limit the iterator size
-            resultSize += Iterators.size(Iterators.limit(result.getNodes(), 500));
-        }
-    }
-
-    private class Mutator implements Runnable {
-        final Session session = loginWriter();
-        int mutationCount = 0;
-        @Override
-        public void run() {
-            try{
-                run0();
-            } catch (RepositoryException e) {
-                throw new RuntimeException(e);
-            }
-        }
-
-        private void run0() throws RepositoryException {
-            TestContext ctx = contexts.get(random.nextInt(contexts.size()));
-            String path = ctx.paths.peek();
-            session.refresh(false);
-            if (path != null){
-                Node node = session.getNode(path);
-                if(node.hasProperty(indexedPropName)){
-                    String value = node.getProperty(indexedPropName).getString();
-                    String newValue = Status.valueOf(value).next().name();
-                    node.setProperty(indexedPropName, newValue);
-                    session.save();
-                    mutationCount++;
-                }
-            }
-        }
-    }
-}
diff --git oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/benchmark/LucenePropertyFTSeparated.java oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/benchmark/LucenePropertyFTSeparated.java
deleted file mode 100644
index 630d4fe..0000000
--- oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/benchmark/LucenePropertyFTSeparated.java
+++ /dev/null
@@ -1,74 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *      http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.jackrabbit.oak.benchmark;
-
-import static com.google.common.collect.ImmutableSet.of;
-
-import java.io.File;
-
-import javax.jcr.Repository;
-
-import org.apache.jackrabbit.oak.Oak;
-import org.apache.jackrabbit.oak.fixture.JcrCreator;
-import org.apache.jackrabbit.oak.fixture.OakRepositoryFixture;
-import org.apache.jackrabbit.oak.fixture.RepositoryFixture;
-import org.apache.jackrabbit.oak.jcr.Jcr;
-import org.apache.jackrabbit.oak.plugins.index.lucene.LuceneIndexEditorProvider;
-import org.apache.jackrabbit.oak.plugins.index.lucene.LuceneIndexProvider;
-import org.apache.jackrabbit.oak.plugins.index.lucene.util.LuceneInitializerHelper;
-import org.apache.jackrabbit.oak.spi.commit.Observer;
-import org.apache.jackrabbit.oak.spi.query.QueryIndexProvider;
-
-/**
- * same as {@link LucenePropertyFullTextTest} but will initialise a repository where the global
- * full-text runs on a separate thread from lucene property.
- */
-public class LucenePropertyFTSeparated extends LucenePropertyFullTextTest {
-
-    public LucenePropertyFTSeparated(final File dump, 
-                                     final boolean flat, 
-                                     final boolean doReport,
-                                     final Boolean storageEnabled) {
-        super(dump, flat, doReport, storageEnabled);
-        currentTest = this.getClass().getSimpleName();
-    }
-
-    @Override
-    protected Repository[] createRepository(RepositoryFixture fixture) throws Exception {
-        if (fixture instanceof OakRepositoryFixture) {
-            currentFixture = fixture.toString();
-            return ((OakRepositoryFixture) fixture).setUpCluster(1, new JcrCreator() {
-                @Override
-                public Jcr customize(Oak oak) {
-                    LuceneIndexProvider provider = new LuceneIndexProvider();
-                    oak.with((QueryIndexProvider) provider)
-                       .with((Observer) provider)
-                       .with(new LuceneIndexEditorProvider())
-                        .with(
-                            (new LuceneInitializerHelper("luceneGlobal", storageEnabled))
-                                .async("async-slow"))
-                       // the WikipediaImporter set a property `title`
-                       .with(new LucenePropertyInitialiser("luceneTitle", of("title")))
-                       .withAsyncIndexing("async", 5)
-                       .withAsyncIndexing("async-slow", 5);
-                    return new Jcr(oak);
-                }
-            });
-        }
-        return super.createRepository(fixture);
-    }
-}
diff --git oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/benchmark/LucenePropertyFullTextTest.java oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/benchmark/LucenePropertyFullTextTest.java
deleted file mode 100644
index 8c4b921..0000000
--- oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/benchmark/LucenePropertyFullTextTest.java
+++ /dev/null
@@ -1,295 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *      http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.jackrabbit.oak.benchmark;
-
-import static com.google.common.base.Preconditions.checkNotNull;
-import static com.google.common.collect.ImmutableSet.of;
-import static org.apache.jackrabbit.oak.api.Type.BOOLEAN;
-import static org.apache.jackrabbit.oak.api.Type.LONG;
-import static org.apache.jackrabbit.oak.api.Type.NAME;
-import static org.apache.jackrabbit.oak.api.Type.STRING;
-import static org.apache.jackrabbit.oak.plugins.index.IndexConstants.ASYNC_PROPERTY_NAME;
-import static org.apache.jackrabbit.oak.plugins.index.IndexConstants.INDEX_DEFINITIONS_NAME;
-import static org.apache.jackrabbit.oak.plugins.index.IndexConstants.INDEX_DEFINITIONS_NODE_TYPE;
-import static org.apache.jackrabbit.oak.plugins.index.IndexConstants.REINDEX_PROPERTY_NAME;
-import static org.apache.jackrabbit.oak.plugins.index.IndexConstants.TYPE_PROPERTY_NAME;
-import static org.apache.jackrabbit.oak.plugins.index.lucene.LuceneIndexConstants.TYPE_LUCENE;
-import static org.apache.jackrabbit.oak.plugins.index.search.FulltextIndexConstants.COMPAT_MODE;
-import static org.apache.jackrabbit.oak.plugins.index.search.FulltextIndexConstants.INDEX_RULES;
-import static org.apache.jackrabbit.oak.plugins.index.search.FulltextIndexConstants.PROP_NAME;
-import static org.apache.jackrabbit.oak.plugins.index.search.FulltextIndexConstants.PROP_NODE;
-import static org.apache.jackrabbit.oak.plugins.index.search.FulltextIndexConstants.PROP_PROPERTY_INDEX;
-
-import java.io.File;
-import java.util.Set;
-import java.util.concurrent.TimeUnit;
-import java.util.concurrent.atomic.AtomicReference;
-
-import javax.jcr.Repository;
-import javax.jcr.RepositoryException;
-import javax.jcr.Session;
-import javax.jcr.ValueFactory;
-import javax.jcr.query.Query;
-import javax.jcr.query.QueryManager;
-import javax.jcr.query.RowIterator;
-
-import org.apache.jackrabbit.oak.Oak;
-import org.apache.jackrabbit.oak.api.Tree;
-import org.apache.jackrabbit.oak.benchmark.wikipedia.WikipediaImport;
-import org.apache.jackrabbit.oak.commons.PathUtils;
-import org.apache.jackrabbit.oak.fixture.JcrCreator;
-import org.apache.jackrabbit.oak.fixture.OakRepositoryFixture;
-import org.apache.jackrabbit.oak.fixture.RepositoryFixture;
-import org.apache.jackrabbit.oak.jcr.Jcr;
-import org.apache.jackrabbit.oak.plugins.index.lucene.LuceneIndexEditorProvider;
-import org.apache.jackrabbit.oak.plugins.index.lucene.LuceneIndexProvider;
-import org.apache.jackrabbit.oak.plugins.index.lucene.util.LuceneInitializerHelper;
-import org.apache.jackrabbit.oak.plugins.tree.factories.TreeFactory;
-import org.apache.jackrabbit.oak.spi.commit.Observer;
-import org.apache.jackrabbit.oak.spi.lifecycle.RepositoryInitializer;
-import org.apache.jackrabbit.oak.spi.query.QueryIndexProvider;
-import org.apache.jackrabbit.oak.spi.state.NodeBuilder;
-import org.jetbrains.annotations.NotNull;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-/**
- * <p>
- * Perform a benchmark on how long it takes for an ingested item to be available in a Lucene
- * Property index when indexed in conjunction with a Global full-text lucene (same thread). It makes
- * use of the {@link WikipediaImport} to use a Wikipedia dump for content injestion.
- * </p>
- * <p>
- * Suggested dump: 
- * <a href="https://dumps.wikimedia.org/enwiki/20150403/enwiki-20150403-pages-articles.xml.bz2">https://dumps.wikimedia.org/enwiki/20150403/enwiki-20150403-pages-articles.xml.bz2</a>
- * </p>
- * <p>
- * Usage example:
- * </p>
- * 
- * <pre>
- * java -Druntime=900 -Dlogback.configurationFile=logback-benchmark.xml \
- *      -jar ~/.m2/repository/org/apache/jackrabbit/oak-run/1.4-SNAPSHOT/oak-run-1.4-SNAPSHOT.jar \
- *      benchmark --wikipedia enwiki-20150403-pages-articles.xml.bz2 \
- *      --base ~/tmp/oak/ LucenePropertyFullTextTest Oak-Tar Oak-Mongo
- * </pre>
- * <p>
- * it will run the benchmark for 15 minutes against TarNS and MongoNS.
- * </p>
- */
-public class LucenePropertyFullTextTest extends AbstractTest<LucenePropertyFullTextTest.TestContext> {
-    private static final Logger LOG = LoggerFactory.getLogger(LucenePropertyFullTextTest.class);
-    private WikipediaImport importer;    
-    private Thread asyncImporter;
-    private boolean benchmarkCompleted, importerCompleted;
-    Boolean storageEnabled;
-    String currentFixture, currentTest;
-    
-    /**
-     * context used across the tests
-     */
-    class TestContext {
-        final Session session = loginWriter();
-        final String title;
-        
-        public TestContext(@NotNull final String title) {
-            this.title = checkNotNull(title);
-        }
-    }
-
-    /**
-     * helper class to initialise the Lucene Property index definition
-     */
-    static class LucenePropertyInitialiser implements RepositoryInitializer {
-        private String name;
-        private Set<String> properties;
-        
-        public LucenePropertyInitialiser(@NotNull final String name, 
-                                         @NotNull final Set<String> properties) {
-            this.name = checkNotNull(name);
-            this.properties = checkNotNull(properties);
-        }
-                
-        private boolean isAlreadyThere(@NotNull final NodeBuilder root) {
-            return checkNotNull(root).hasChildNode(INDEX_DEFINITIONS_NAME) &&
-                root.getChildNode(INDEX_DEFINITIONS_NAME).hasChildNode(name);
-        }
-        
-        @Override
-        public void initialize(final NodeBuilder builder) {
-            if (!isAlreadyThere(builder)) {
-                Tree t = TreeFactory.createTree(builder.child(INDEX_DEFINITIONS_NAME));
-                t = t.addChild(name);
-                t.setProperty("jcr:primaryType", INDEX_DEFINITIONS_NODE_TYPE, NAME);
-                t.setProperty(COMPAT_MODE, 2L, LONG);
-                t.setProperty(TYPE_PROPERTY_NAME, TYPE_LUCENE, STRING);
-                t.setProperty(ASYNC_PROPERTY_NAME, "async", STRING);
-                t.setProperty(REINDEX_PROPERTY_NAME, true);
-                
-                t = t.addChild(INDEX_RULES);
-                t.setOrderableChildren(true);
-                t.setProperty("jcr:primaryType", "nt:unstructured", NAME);
-                
-                t = t.addChild("nt:base");
-                
-                Tree propnode = t.addChild(PROP_NODE);
-                propnode.setOrderableChildren(true);
-                propnode.setProperty("jcr:primaryType", "nt:unstructured", NAME);
-                
-                for (String p : properties) {
-                    Tree t1 = propnode.addChild(PathUtils.getName(p));
-                    t1.setProperty(PROP_PROPERTY_INDEX, true, BOOLEAN);
-                    t1.setProperty(PROP_NAME, p);
-                }
-            }
-        }
-    }
-    
-    /**
-     * reference to the last added title. Used for looking up with queries.
-     */
-    private AtomicReference<String> lastTitle = new AtomicReference<String>();
-    
-    public LucenePropertyFullTextTest(final File dump, 
-                                      final boolean flat, 
-                                      final boolean doReport, 
-                                      final Boolean storageEnabled) {
-        this.importer = new WikipediaImport(dump, flat, doReport) {
-
-            @Override
-            protected void pageAdded(String title, String text) {
-                LOG.trace("Setting title: {}", title);
-                lastTitle.set(title);
-            }
-        };
-        this.storageEnabled = storageEnabled;
-        this.currentTest = this.getClass().getSimpleName();
-    }
-
-    @Override
-    protected Repository[] createRepository(RepositoryFixture fixture) throws Exception {
-        if (fixture instanceof OakRepositoryFixture) {
-            currentFixture = fixture.toString();
-            return ((OakRepositoryFixture) fixture).setUpCluster(1, new JcrCreator() {
-                @Override
-                public Jcr customize(Oak oak) {
-                    LuceneIndexProvider provider = new LuceneIndexProvider();
-                    oak.with((QueryIndexProvider) provider)
-                       .with((Observer) provider)
-                       .with(new LuceneIndexEditorProvider())
-                       .with((new LuceneInitializerHelper("luceneGlobal", storageEnabled)).async())
-                       // the WikipediaImporter set a property `title`
-                       .with(new LucenePropertyInitialiser("luceneTitle", of("title")))
-                       .withAsyncIndexing("async", 5);
-                    return new Jcr(oak);
-                }
-            });
-        }
-        return super.createRepository(fixture);
-    }
-
-    @Override
-    protected void beforeSuite() throws Exception {
-        LOG.debug("beforeSuite() - {} - {}", currentFixture, currentTest);
-        benchmarkCompleted = false;
-        importerCompleted = false;
-        asyncImporter = new Thread(new Runnable() {
-            @Override
-            public void run() {
-                try {
-                    importer.importWikipedia(loginWriter());
-                } catch (Exception e) {
-                    LOG.error("Error while importing the dump. Trying to halt everything.", e);
-                    importerCompleted = true;
-                } finally {
-                    if (!benchmarkCompleted) {
-                        importerCompleted = true;
-                        issueHaltRequest("Wikipedia import completed.");
-                    }
-                }
-            }
-        });
-        asyncImporter.start();
-
-        // allowing the async index to catch up. 
-        TimeUnit.SECONDS.sleep(10);
-    }
-
-    @Override
-    protected void afterSuite() throws Exception {
-        LOG.debug("afterSuite() - {} - {}", currentFixture, currentTest);
-        asyncImporter.join();
-    }
-    
-    @Override
-    protected void runTest() throws Exception {
-        if (lastTitle.get() == null) {
-            return;
-        }
-        runTest(new TestContext(lastTitle.get()));
-    }
-
-    @Override
-    protected void runTest(final TestContext ec) throws Exception {
-        if (importerCompleted) {
-            return;
-        }
-        final long maxWait = TimeUnit.MINUTES.toMillis(5);
-        final long waitUnit = 50;
-        long sleptSoFar = 0;
-        
-        while (!performQuery(ec) && sleptSoFar < maxWait) {
-            LOG.trace("title '{}' not found. Waiting and retry. sleptSoFar: {}ms", ec.title,
-                sleptSoFar);
-            sleptSoFar += waitUnit;
-            TimeUnit.MILLISECONDS.sleep(waitUnit);
-        }
-        
-        if (sleptSoFar < maxWait) {
-            // means we exited the loop as we found it.
-            LOG.info("{} - {} - title '{}' found with a wait/try of {}ms", currentFixture,
-                currentTest, ec.title, sleptSoFar);
-        } else {
-            LOG.warn("{} - {} - title '{}' timed out with a way/try of {}ms.", currentFixture,
-                currentTest, ec.title, sleptSoFar);
-        }
-    }
-    
-    private boolean performQuery(@NotNull final TestContext ec) throws RepositoryException {
-        QueryManager qm = ec.session.getWorkspace().getQueryManager();
-        ValueFactory vf = ec.session.getValueFactory();
-        Query q = qm.createQuery("SELECT * FROM [nt:base] WHERE [title] = $title", Query.JCR_SQL2);
-        q.bindValue("title", vf.createValue(ec.title));
-        LOG.trace("statement: {} - title: {}", q.getStatement(), ec.title);        
-        RowIterator rows = q.execute().getRows();
-        if (rows.hasNext()) {
-            rows.nextRow().getPath();
-            return true;
-        } else {
-            return false;
-        }
-    }
-
-    @Override
-    protected void issueHaltChildThreads() {
-        if (!importerCompleted) {
-            LOG.info("benchmark completed. Issuing an halt for the importer");
-            benchmarkCompleted = true;
-            this.importer.issueHaltImport();
-        }
-    }
-}
diff --git oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/benchmark/util/OakIndexUtils.java oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/benchmark/util/OakIndexUtils.java
index 846f545..b1eb2f7 100644
--- oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/benchmark/util/OakIndexUtils.java
+++ oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/benchmark/util/OakIndexUtils.java
@@ -21,10 +21,8 @@ import com.google.common.collect.Lists;
 import org.apache.jackrabbit.JcrConstants;
 import org.apache.jackrabbit.commons.JcrUtils;
 import org.apache.jackrabbit.oak.plugins.index.IndexConstants;
-import org.apache.jackrabbit.oak.plugins.index.lucene.LuceneIndexConstants;
 import org.apache.jackrabbit.oak.plugins.index.property.OrderedIndex;
 import org.apache.jackrabbit.oak.plugins.index.property.PropertyIndexEditorProvider;
-import org.apache.jackrabbit.oak.plugins.index.search.FulltextIndexConstants;
 import org.apache.jackrabbit.oak.spi.nodetype.NodeTypeConstants;
 import org.jetbrains.annotations.Nullable;
 
@@ -285,74 +283,4 @@ public class OakIndexUtils {
 
         return indexDef;
     }
-
-    /**
-     * Helper method to create or update a lucene property index definition.
-     *
-     * @param session the session
-     * @param indexDefinitionName the name of the node for the index definition
-     * @param propertyNames the list of properties to index
-     * @param type the types of the properties in order of the properties
-     * @param orderedPropsMap the ordered props and its properties
-     * @param persistencePath the path if the persistence=file (default is repository)
-     * @return the node just created
-     * @throws RepositoryException the repository exception
-     */
-    public static Node luceneIndexDefinition(Session session, String indexDefinitionName,
-        String async, String[] propertyNames, String[] type,
-        Map<String, Map<String, String>> orderedPropsMap, String persistencePath)
-        throws RepositoryException {
-
-        Node root = session.getRootNode();
-        Node indexDefRoot = JcrUtils.getOrAddNode(root, IndexConstants.INDEX_DEFINITIONS_NAME,
-            NodeTypeConstants.NT_UNSTRUCTURED);
-
-        Node indexDef = JcrUtils.getOrAddNode(indexDefRoot, indexDefinitionName,
-            IndexConstants.INDEX_DEFINITIONS_NODE_TYPE);
-
-        indexDef.setProperty(IndexConstants.TYPE_PROPERTY_NAME, LuceneIndexConstants.TYPE_LUCENE);
-        indexDef.setProperty(FulltextIndexConstants.FULL_TEXT_ENABLED, false);
-        if (async != null) {
-            indexDef.setProperty(IndexConstants.ASYNC_PROPERTY_NAME, async);
-        }
-        // Set indexed property names
-        indexDef.setProperty(FulltextIndexConstants.INCLUDE_PROPERTY_NAMES, propertyNames,
-            PropertyType.NAME);
-
-        Node propsNode = JcrUtils.getOrAddNode(indexDef, FulltextIndexConstants.PROP_NODE);
-        for (int i = 0; i < propertyNames.length; i++) {
-            Node propNode =
-                JcrUtils.getOrAddNode(propsNode, propertyNames[i], NodeTypeConstants.NT_OAK_UNSTRUCTURED);
-            propNode.setProperty(FulltextIndexConstants.PROP_TYPE, type[i]);
-        }
-
-        // Set ordered property names
-        if ((orderedPropsMap != null) && !orderedPropsMap.isEmpty()) {
-            List<String> orderedProps = Lists.newArrayList();
-            for (Map.Entry<String, Map<String, String>> orderedPropEntry : orderedPropsMap
-                .entrySet()) {
-                Node propNode = JcrUtils.getOrAddNode(propsNode, orderedPropEntry.getKey(),
-                    NodeTypeConstants.NT_OAK_UNSTRUCTURED);
-                propNode.setProperty(FulltextIndexConstants.PROP_TYPE,
-                    orderedPropEntry.getValue().get(FulltextIndexConstants.PROP_TYPE));
-                orderedProps.add(orderedPropEntry.getKey());
-            }
-            if (!orderedProps.isEmpty()) {
-                indexDef.setProperty(FulltextIndexConstants.ORDERED_PROP_NAMES,
-                    orderedProps.toArray(new String[orderedProps.size()]),
-                    PropertyType.NAME);
-            }
-        }
-
-        // Set file persistence if specified
-        if (!Strings.isNullOrEmpty(persistencePath)) {
-            indexDef.setProperty(FulltextIndexConstants.PERSISTENCE_NAME,
-                FulltextIndexConstants.PERSISTENCE_FILE);
-            indexDef.setProperty(FulltextIndexConstants.PERSISTENCE_PATH,
-                persistencePath);
-        }
-        session.save();
-
-        return indexDef;
-    }
 }
diff --git oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/scalability/ScalabilityOptions.java oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/scalability/ScalabilityOptions.java
new file mode 100644
index 0000000..edceef7
--- /dev/null
+++ oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/scalability/ScalabilityOptions.java
@@ -0,0 +1,207 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+package org.apache.jackrabbit.oak.scalability;
+
+
+import joptsimple.OptionParser;
+import joptsimple.OptionSpec;
+
+import java.io.File;
+
+import static java.util.Arrays.asList;
+
+public class ScalabilityOptions {
+
+    private final OptionSpec<File> base;
+    private final OptionSpec<String> host;
+    private final OptionSpec<Integer> port;
+    private final OptionSpec<String> dbName;
+    private final OptionSpec<Boolean> dropDBAfterTest;
+    private final OptionSpec<String> rdbjdbcuri;
+    private final OptionSpec<String> rdbjdbcuser;
+    private final OptionSpec<String> rdbjdbcpasswd;
+    private final OptionSpec<String> rdbjdbctableprefix;
+    private final  OptionSpec<Boolean> mmap;
+    private final OptionSpec<Integer> cache;
+    private final OptionSpec<Integer> fdsCache;
+    private final OptionSpec<Boolean> withStorage;
+    private final OptionSpec<Integer> coldSyncInterval;
+    private final OptionSpec<Boolean> coldUseDataStore;
+    private final OptionSpec<Boolean> coldShareDataStore;
+    private final OptionSpec<Boolean> coldOneShotRun;
+    private final OptionSpec<Boolean> coldSecure;
+    private final OptionSpec<?> help;
+    private final OptionSpec<String> nonOption;
+    private final OptionSpec<File> csvFile;
+
+    public OptionSpec<Integer> getColdSyncInterval() {
+        return coldSyncInterval;
+    }
+
+    public OptionSpec<File> getBase() {
+        return base;
+    }
+
+    public OptionSpec<String> getHost() {
+        return host;
+    }
+
+    public OptionSpec<Integer> getPort() {
+        return port;
+    }
+
+    public OptionSpec<String> getDbName() {
+        return dbName;
+    }
+
+    public OptionSpec<Boolean> getDropDBAfterTest() {
+        return dropDBAfterTest;
+    }
+
+    public OptionSpec<String> getRdbjdbcuri() {
+        return rdbjdbcuri;
+    }
+
+    public OptionSpec<String> getRdbjdbcuser() {
+        return rdbjdbcuser;
+    }
+
+    public OptionSpec<String> getRdbjdbcpasswd() {
+        return rdbjdbcpasswd;
+    }
+
+    public OptionSpec<String> getRdbjdbctableprefix() {
+        return rdbjdbctableprefix;
+    }
+
+    public OptionSpec<Boolean> getMmap() {
+        return mmap;
+    }
+
+    public OptionSpec<Integer> getCache() {
+        return cache;
+    }
+
+    public OptionSpec<Integer> getFdsCache() {
+        return fdsCache;
+    }
+
+    public OptionSpec<Boolean> getWithStorage() {
+        return withStorage;
+    }
+
+    public OptionSpec<Boolean> getColdUseDataStore() {
+        return coldUseDataStore;
+    }
+
+    public OptionSpec<Boolean> getColdShareDataStore() {
+        return coldShareDataStore;
+    }
+
+    public OptionSpec<Boolean> getColdOneShotRun() {
+        return coldOneShotRun;
+    }
+
+    public OptionSpec<Boolean> getColdSecure() {
+        return coldSecure;
+    }
+
+    public OptionSpec<?> getHelp() {
+        return help;
+    }
+
+    public OptionSpec<String> getNonOption() {
+        return nonOption;
+    }
+
+    public OptionSpec<File> getCsvFile() {
+        return csvFile;
+    }
+
+
+
+    public ScalabilityOptions(OptionParser parser) {
+
+        base = parser.accepts("base", "Base directory")
+                .withRequiredArg().ofType(File.class)
+                .defaultsTo(new File("target"));
+        host = parser.accepts("host", "MongoDB host")
+                .withRequiredArg().defaultsTo("localhost");
+        port = parser.accepts("port", "MongoDB port")
+                .withRequiredArg().ofType(Integer.class).defaultsTo(27017);
+        dbName = parser.accepts("db", "MongoDB database")
+                .withRequiredArg();
+        dropDBAfterTest =
+                parser.accepts("dropDBAfterTest",
+                        "Whether to drop the MongoDB database after the test")
+                        .withOptionalArg().ofType(Boolean.class).defaultsTo(true);
+        rdbjdbcuri = parser.accepts("rdbjdbcuri", "RDB JDBC URI")
+                .withOptionalArg().defaultsTo("jdbc:h2:./target/benchmark");
+        rdbjdbcuser = parser.accepts("rdbjdbcuser", "RDB JDBC user")
+                .withOptionalArg().defaultsTo("");
+        rdbjdbcpasswd = parser.accepts("rdbjdbcpasswd", "RDB JDBC password")
+                .withOptionalArg().defaultsTo("");
+        rdbjdbctableprefix = parser.accepts("rdbjdbctableprefix", "RDB JDBC table prefix")
+                .withOptionalArg().defaultsTo("");
+        mmap = parser.accepts("mmap", "TarMK memory mapping")
+                .withOptionalArg().ofType(Boolean.class)
+                .defaultsTo("64".equals(System.getProperty("sun.arch.data.model")));
+        cache = parser.accepts("cache", "cache size (MB)")
+                .withRequiredArg().ofType(Integer.class).defaultsTo(100);
+        fdsCache = parser.accepts("blobCache", "cache size (MB)")
+                .withRequiredArg().ofType(Integer.class).defaultsTo(32);
+        withStorage = parser
+                .accepts("storage", "Index storage enabled").withOptionalArg()
+                .ofType(Boolean.class);
+        csvFile =
+                parser.accepts("csvFile", "File to write a CSV version of the benchmark data.")
+                        .withOptionalArg().ofType(File.class);
+        coldSyncInterval = parser.accepts("coldSyncInterval", "interval between sync cycles in sec (Segment-Tar-Cold only)")
+                .withRequiredArg().ofType(Integer.class).defaultsTo(5);
+        coldUseDataStore = parser
+                .accepts("useDataStore",
+                        "Whether to use a datastore in the cold standby topology (Segment-Tar-Cold only)")
+                .withOptionalArg().ofType(Boolean.class)
+                .defaultsTo(Boolean.TRUE);
+        coldShareDataStore = parser
+                .accepts("shareDataStore",
+                        "Whether to share the datastore for primary and standby in the cold standby topology (Segment-Tar-Cold only)")
+                .withOptionalArg().ofType(Boolean.class)
+                .defaultsTo(Boolean.FALSE);
+        coldOneShotRun = parser
+                .accepts("oneShotRun",
+                        "Whether to do a continuous sync between client and server or sync only once (Segment-Tar-Cold only)")
+                .withOptionalArg().ofType(Boolean.class)
+                .defaultsTo(Boolean.TRUE);
+        coldSecure = parser
+                .accepts("secure",
+                        "Whether to enable secure communication between primary and standby in the cold standby topology (Segment-Tar-Cold only)")
+                .withOptionalArg().ofType(Boolean.class)
+                .defaultsTo(Boolean.FALSE);
+
+        help = parser.acceptsAll(asList("h", "?", "help"), "show help").forHelp();
+        nonOption = parser.nonOptions();
+
+
+    }
+
+}
+
+
+
diff --git oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/scalability/ScalabilityRunner.java oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/scalability/ScalabilityRunner.java
index a25e50c..0c66de4 100644
--- oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/scalability/ScalabilityRunner.java
+++ oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/scalability/ScalabilityRunner.java
@@ -18,10 +18,9 @@
  */
 package org.apache.jackrabbit.oak.scalability;
 
-import static java.util.Arrays.asList;
-
-import java.io.File;
+import java.io.IOException;
 import java.io.PrintStream;
+import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.Iterator;
 import java.util.List;
@@ -35,38 +34,12 @@ import com.google.common.collect.Maps;
 import com.google.common.collect.Sets;
 import joptsimple.OptionParser;
 import joptsimple.OptionSet;
-import joptsimple.OptionSpec;
 import org.apache.commons.io.FileUtils;
 import org.apache.jackrabbit.oak.benchmark.CSVResultGenerator;
-import org.apache.jackrabbit.oak.benchmark.util.Date;
 import org.apache.jackrabbit.oak.fixture.JackrabbitRepositoryFixture;
 import org.apache.jackrabbit.oak.fixture.OakRepositoryFixture;
 import org.apache.jackrabbit.oak.fixture.RepositoryFixture;
-import org.apache.jackrabbit.oak.scalability.benchmarks.search.AggregateNodeSearcher;
-import org.apache.jackrabbit.oak.scalability.benchmarks.search.ConcurrentReader;
-import org.apache.jackrabbit.oak.scalability.benchmarks.search.ConcurrentWriter;
-import org.apache.jackrabbit.oak.scalability.benchmarks.search.FacetSearcher;
-import org.apache.jackrabbit.oak.scalability.benchmarks.search.FormatSearcher;
-import org.apache.jackrabbit.oak.scalability.benchmarks.search.FullTextSearcher;
-import org.apache.jackrabbit.oak.scalability.benchmarks.search.LastModifiedSearcher;
-import org.apache.jackrabbit.oak.scalability.benchmarks.search.MultiFilterOrderByKeysetPageSearcher;
-import org.apache.jackrabbit.oak.scalability.benchmarks.search.MultiFilterOrderByOffsetPageSearcher;
-import org.apache.jackrabbit.oak.scalability.benchmarks.search.MultiFilterOrderBySearcher;
-import org.apache.jackrabbit.oak.scalability.benchmarks.search.MultiFilterSplitOrderByKeysetPageSearcher;
-import org.apache.jackrabbit.oak.scalability.benchmarks.search.MultiFilterSplitOrderByOffsetPageSearcher;
-import org.apache.jackrabbit.oak.scalability.benchmarks.search.MultiFilterSplitOrderBySearcher;
-import org.apache.jackrabbit.oak.scalability.benchmarks.search.NodeTypeSearcher;
-import org.apache.jackrabbit.oak.scalability.benchmarks.search.OrderByDate;
-import org.apache.jackrabbit.oak.scalability.benchmarks.search.OrderByKeysetPageSearcher;
-import org.apache.jackrabbit.oak.scalability.benchmarks.search.OrderByOffsetPageSearcher;
-import org.apache.jackrabbit.oak.scalability.benchmarks.search.OrderBySearcher;
-import org.apache.jackrabbit.oak.scalability.benchmarks.search.SplitOrderByKeysetPageSearcher;
-import org.apache.jackrabbit.oak.scalability.benchmarks.search.SplitOrderByOffsetPageSearcher;
-import org.apache.jackrabbit.oak.scalability.benchmarks.search.SplitOrderBySearcher;
 import org.apache.jackrabbit.oak.scalability.benchmarks.segment.standby.StandbyBulkTransferBenchmark;
-import org.apache.jackrabbit.oak.scalability.suites.ScalabilityBlobSearchSuite;
-import org.apache.jackrabbit.oak.scalability.suites.ScalabilityNodeRelationshipSuite;
-import org.apache.jackrabbit.oak.scalability.suites.ScalabilityNodeSuite;
 import org.apache.jackrabbit.oak.scalability.suites.ScalabilityStandbySuite;
 
 /**
@@ -77,144 +50,82 @@ public class ScalabilityRunner {
 
     private static final long MB = 1024 * 1024L;
 
-    public static void main(String[] args) throws Exception {
-        OptionParser parser = new OptionParser();
-        OptionSpec<File> base = parser.accepts("base", "Base directory")
-                .withRequiredArg().ofType(File.class)
-                .defaultsTo(new File("target"));
-        OptionSpec<String> host = parser.accepts("host", "MongoDB host")
-                .withRequiredArg().defaultsTo("localhost");
-        OptionSpec<Integer> port = parser.accepts("port", "MongoDB port")
-                .withRequiredArg().ofType(Integer.class).defaultsTo(27017);
-        OptionSpec<String> dbName = parser.accepts("db", "MongoDB database")
-                .withRequiredArg();
-        OptionSpec<Boolean> dropDBAfterTest =
-                parser.accepts("dropDBAfterTest",
-                        "Whether to drop the MongoDB database after the test")
-                        .withOptionalArg().ofType(Boolean.class).defaultsTo(true);
-        OptionSpec<String> rdbjdbcuri = parser.accepts("rdbjdbcuri", "RDB JDBC URI")
-            .withOptionalArg().defaultsTo("jdbc:h2:./target/benchmark");
-        OptionSpec<String> rdbjdbcuser = parser.accepts("rdbjdbcuser", "RDB JDBC user")
-            .withOptionalArg().defaultsTo("");
-        OptionSpec<String> rdbjdbcpasswd = parser.accepts("rdbjdbcpasswd", "RDB JDBC password")
-            .withOptionalArg().defaultsTo("");
-        OptionSpec<String> rdbjdbctableprefix = parser.accepts("rdbjdbctableprefix", "RDB JDBC table prefix")
-            .withOptionalArg().defaultsTo("");
-        OptionSpec<Boolean> mmap = parser.accepts("mmap", "TarMK memory mapping")
-                .withOptionalArg().ofType(Boolean.class)
-                .defaultsTo("64".equals(System.getProperty("sun.arch.data.model")));
-        OptionSpec<Integer> cache = parser.accepts("cache", "cache size (MB)")
-                .withRequiredArg().ofType(Integer.class).defaultsTo(100);
-        OptionSpec<Integer> fdsCache = parser.accepts("blobCache", "cache size (MB)")
-                .withRequiredArg().ofType(Integer.class).defaultsTo(32);
-        OptionSpec<Boolean> withStorage = parser
-                .accepts("storage", "Index storage enabled").withOptionalArg()
-                .ofType(Boolean.class);
-        OptionSpec<File> csvFile =
-                parser.accepts("csvFile", "File to write a CSV version of the benchmark data.")
-                        .withOptionalArg().ofType(File.class);
-        OptionSpec<Integer> coldSyncInterval = parser.accepts("coldSyncInterval", "interval between sync cycles in sec (Segment-Tar-Cold only)")
-                .withRequiredArg().ofType(Integer.class).defaultsTo(5);
-        OptionSpec<Boolean> coldUseDataStore = parser
-                .accepts("useDataStore",
-                        "Whether to use a datastore in the cold standby topology (Segment-Tar-Cold only)")
-                .withOptionalArg().ofType(Boolean.class)
-                .defaultsTo(Boolean.TRUE);
-        OptionSpec<Boolean> coldShareDataStore = parser
-                .accepts("shareDataStore",
-                        "Whether to share the datastore for primary and standby in the cold standby topology (Segment-Tar-Cold only)")
-                .withOptionalArg().ofType(Boolean.class)
-                .defaultsTo(Boolean.FALSE);
-        OptionSpec<Boolean> coldOneShotRun = parser
-                .accepts("oneShotRun",
-                        "Whether to do a continuous sync between client and server or sync only once (Segment-Tar-Cold only)")
-                .withOptionalArg().ofType(Boolean.class)
-                .defaultsTo(Boolean.TRUE);
-        OptionSpec<Boolean> coldSecure = parser
-                .accepts("secure",
-                        "Whether to enable secure communication between primary and standby in the cold standby topology (Segment-Tar-Cold only)")
-                .withOptionalArg().ofType(Boolean.class)
-                .defaultsTo(Boolean.FALSE);
-        
-        OptionSpec<?> help = parser.acceptsAll(asList("h", "?", "help"), "show help").forHelp();
-        OptionSpec<String> nonOption = parser.nonOptions();
+    protected static List<ScalabilitySuite> allSuites = Lists.newArrayList();
+    private static OptionParser parser = new OptionParser();
+    protected static ScalabilityOptions scalabilityOptions = null;
+    protected static OptionSet options;
+    private static boolean initFlag = false;
 
+    public static void main(String[] args) throws Exception {
+        initOptionSet(args);
         OptionSet options = parser.parse(args);
 
-        if (options.has(help)) {
+        if (options.has(scalabilityOptions.getHelp())) {
             parser.printHelpOn(System.out);
             System.exit(0);
         }
 
-        int cacheSize = cache.value(options);
+        int cacheSize = scalabilityOptions.getCache().value(options);
         RepositoryFixture[] allFixtures = new RepositoryFixture[] {
-                new JackrabbitRepositoryFixture(base.value(options), cacheSize),
+                new JackrabbitRepositoryFixture(scalabilityOptions.getBase().value(options), cacheSize),
                 OakRepositoryFixture.getMemoryNS(cacheSize * MB),
                 OakRepositoryFixture.getMongo(
-                    host.value(options), port.value(options),
-                    dbName.value(options), dropDBAfterTest.value(options),
+                        scalabilityOptions.getHost().value(options),
+                        scalabilityOptions.getPort().value(options),
+                        scalabilityOptions.getDbName().value(options),
+                        scalabilityOptions.getDropDBAfterTest().value(options),
                         cacheSize * MB),
                 OakRepositoryFixture.getMongoWithDS(
-                    host.value(options), port.value(options),
-                    dbName.value(options), dropDBAfterTest.value(options),
+                        scalabilityOptions.getHost().value(options),
+                        scalabilityOptions.getPort().value(options),
+                        scalabilityOptions.getDbName().value(options),
+                        scalabilityOptions.getDropDBAfterTest().value(options),
                         cacheSize * MB,
-                    base.value(options),
-                    fdsCache.value(options)),
+                        scalabilityOptions.getBase().value(options),
+                        scalabilityOptions.getFdsCache().value(options)),
                 OakRepositoryFixture.getMongoNS(
-                    host.value(options), port.value(options),
-                    dbName.value(options), dropDBAfterTest.value(options),
+                        scalabilityOptions.getHost().value(options),
+                        scalabilityOptions.getPort().value(options),
+                        scalabilityOptions.getDbName().value(options),
+                        scalabilityOptions.getDropDBAfterTest().value(options),
                     cacheSize * MB),
                 OakRepositoryFixture.getSegmentTar(
-                    base.value(options), 256, cacheSize, mmap.value(options)),
-                OakRepositoryFixture.getSegmentTarWithDataStore(base.value(options), 256, cacheSize,
-                    mmap.value(options), fdsCache.value(options)),
-                OakRepositoryFixture.getSegmentTarWithColdStandby(base.value(options), 256, cacheSize,
-                        mmap.value(options), coldUseDataStore.value(options), fdsCache.value(options), 
-                        coldSyncInterval.value(options), coldShareDataStore.value(options), coldSecure.value(options), 
-                        coldOneShotRun.value(options)),
-                OakRepositoryFixture.getRDB(rdbjdbcuri.value(options), rdbjdbcuser.value(options),
-                    rdbjdbcpasswd.value(options), rdbjdbctableprefix.value(options),
-                    dropDBAfterTest.value(options), cacheSize * MB, -1),
-                OakRepositoryFixture.getRDBWithDS(rdbjdbcuri.value(options), rdbjdbcuser.value(options),
-                    rdbjdbcpasswd.value(options), rdbjdbctableprefix.value(options),
-                    dropDBAfterTest.value(options), cacheSize * MB, base.value(options),
-                    fdsCache.value(options), -1)
+                        scalabilityOptions.getBase().value(options), 256, cacheSize,
+                        scalabilityOptions.getMmap().value(options)),
+                OakRepositoryFixture.getSegmentTarWithDataStore(scalabilityOptions.getBase().value(options),
+                        256, cacheSize,
+                        scalabilityOptions.getMmap().value(options),
+                        scalabilityOptions.getFdsCache().value(options)),
+                OakRepositoryFixture.getSegmentTarWithColdStandby(scalabilityOptions.getBase().value(options), 256, cacheSize,
+                        scalabilityOptions.getMmap().value(options),
+                        scalabilityOptions.getColdUseDataStore().value(options),
+                        scalabilityOptions.getFdsCache().value(options),
+                        scalabilityOptions.getColdSyncInterval().value(options),
+                        scalabilityOptions.getColdShareDataStore().value(options),
+                        scalabilityOptions.getColdSecure().value(options),
+                        scalabilityOptions.getColdOneShotRun().value(options)),
+                OakRepositoryFixture.getRDB(scalabilityOptions.getRdbjdbcuri().value(options),
+                        scalabilityOptions.getRdbjdbcuser().value(options),
+                        scalabilityOptions.getRdbjdbcpasswd().value(options),
+                        scalabilityOptions.getRdbjdbctableprefix().value(options),
+                        scalabilityOptions.getDropDBAfterTest().value(options), cacheSize * MB, -1),
+                OakRepositoryFixture.getRDBWithDS(scalabilityOptions.getRdbjdbcuri().value(options),
+                        scalabilityOptions.getRdbjdbcuser().value(options),
+                        scalabilityOptions.getRdbjdbcpasswd().value(options),
+                        scalabilityOptions.getRdbjdbctableprefix().value(options),
+                        scalabilityOptions.getDropDBAfterTest().value(options), cacheSize * MB,
+                        scalabilityOptions.getBase().value(options),
+                        scalabilityOptions.getFdsCache().value(options), -1)
         };
-        ScalabilitySuite[] allSuites =
-                new ScalabilitySuite[] {
-                        new ScalabilityBlobSearchSuite(withStorage.value(options))
-                                .addBenchmarks(new FullTextSearcher(),
-                                        new NodeTypeSearcher(),
-                                        new FormatSearcher(),
-                                        new FacetSearcher(),
-                                        new LastModifiedSearcher(Date.LAST_2_HRS),
-                                        new LastModifiedSearcher(Date.LAST_24_HRS),
-                                        new LastModifiedSearcher(Date.LAST_7_DAYS),
-                                        new LastModifiedSearcher(Date.LAST_MONTH),
-                                        new LastModifiedSearcher(Date.LAST_YEAR),
-                                        new OrderByDate()),
-                        new ScalabilityNodeSuite(withStorage.value(options))
-                                .addBenchmarks(new OrderBySearcher(),
-                                        new SplitOrderBySearcher(),
-                                        new OrderByOffsetPageSearcher(),
-                                        new SplitOrderByOffsetPageSearcher(),
-                                        new OrderByKeysetPageSearcher(),
-                                        new SplitOrderByKeysetPageSearcher(),
-                                        new MultiFilterOrderBySearcher(),
-                                        new MultiFilterSplitOrderBySearcher(),
-                                        new MultiFilterOrderByOffsetPageSearcher(),
-                                        new MultiFilterSplitOrderByOffsetPageSearcher(),
-                                        new MultiFilterOrderByKeysetPageSearcher(),
-                                        new MultiFilterSplitOrderByKeysetPageSearcher(),
-                                        new ConcurrentReader(),
-                                        new ConcurrentWriter()),
-                        new ScalabilityNodeRelationshipSuite(withStorage.value(options))
-                                .addBenchmarks(new AggregateNodeSearcher()),
+
+        addToScalabilitySuiteList(
+                Arrays.asList(
                         new ScalabilityStandbySuite()
-                                .addBenchmarks(new StandbyBulkTransferBenchmark())
-                };
+                                .addBenchmarks(new StandbyBulkTransferBenchmark()
+                                )
+                ));
 
-        Set<String> argset = Sets.newHashSet(nonOption.values(options));
+        Set<String> argset = Sets.newHashSet(scalabilityOptions.getNonOption().values(options));
         List<RepositoryFixture> fixtures = Lists.newArrayList();
         for (RepositoryFixture fixture : allFixtures) {
             if (argset.remove(fixture.toString())) {
@@ -260,9 +171,9 @@ public class ScalabilityRunner {
 
         if (argmap.isEmpty()) {
             PrintStream out = null;
-            if (options.has(csvFile)) {
+            if (options.has(scalabilityOptions.getCsvFile())) {
                 out =
-                    new PrintStream(FileUtils.openOutputStream(csvFile.value(options), true), false,
+                    new PrintStream(FileUtils.openOutputStream(scalabilityOptions.getCsvFile().value(options), true), false,
                                             Charsets.UTF_8.name());
             }
             for (ScalabilitySuite suite : suites) {
@@ -278,4 +189,17 @@ public class ScalabilityRunner {
             System.err.println("Unknown arguments: " + argset);
         }
     }
+
+    protected static void addToScalabilitySuiteList(List<ScalabilitySuite> suites) {
+        allSuites.addAll(suites);
+    }
+
+    protected static void initOptionSet(String[] args) throws IOException {
+        if(!initFlag) {
+            scalabilityOptions = new ScalabilityOptions(parser);
+            options = parser.parse(args);
+            initFlag = true;
+        }
+    }
+
 }
diff --git oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/AggregateNodeSearcher.java oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/AggregateNodeSearcher.java
deleted file mode 100644
index 3a2c2b1..0000000
--- oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/AggregateNodeSearcher.java
+++ /dev/null
@@ -1,117 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- *  or more contributor license agreements.  See the NOTICE file
- *  distributed with this work for additional information
- *  regarding copyright ownership.  The ASF licenses this file
- *  to you under the Apache License, Version 2.0 (the
- *  "License"); you may not use this file except in compliance
- *  with the License.  You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- *  Unless required by applicable law or agreed to in writing,
- *  software distributed under the License is distributed on an
- *  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- *  KIND, either express or implied.  See the License for the
- *  specific language governing permissions and limitations
- *  under the License.
- */
-
-package org.apache.jackrabbit.oak.scalability.benchmarks.search;
-
-import com.google.common.collect.Lists;
-
-import org.apache.jackrabbit.api.security.user.Authorizable;
-import org.jetbrains.annotations.NotNull;
-
-import javax.jcr.*;
-import javax.jcr.query.Query;
-import javax.jcr.query.QueryManager;
-
-import java.util.List;
-import java.util.Random;
-
-import org.apache.jackrabbit.oak.scalability.suites.ScalabilityAbstractSuite;
-import org.apache.jackrabbit.oak.scalability.suites.ScalabilityNodeRelationshipSuite;
-import org.apache.jackrabbit.oak.scalability.suites.ScalabilityAbstractSuite.ExecutionContext;
-
-/**
- * Retrieves search property by iterating over nodes and then executes search using the retrieved
- * criteria.
- */
-public class AggregateNodeSearcher extends SearchScalabilityBenchmark {
-    private static final String RELATIONSHIPS = "relationships";
-
-    /**
-     * Queries for nodes with property satisfying a set of properties and ordering by the latest.
-     *
-     * @param qm the query manager
-     * @param context the execution context
-     * @return the query object
-     * @throws RepositoryException
-     */
-    protected Query getQuery(@NotNull QueryManager qm,
-        ExecutionContext context) throws RepositoryException {
-        List<String> relationships = (List<String>) context.getMap().get(RELATIONSHIPS);
-        // /jcr:root//element(*, ActivityType)[((id = 1234 or id = '1354'))] order by jcr:created
-        // descending
-        StringBuilder statement = new StringBuilder("");
-        statement.append("/jcr:root")
-            .append("//element(*, ")
-            .append(
-                (String) context.getMap().get(ScalabilityNodeRelationshipSuite.CTX_ACT_NODE_TYPE_PROP))
-            .append(")");
-        statement.append("[((");
-
-        // adding all the possible mime-types in an OR fashion
-        for (String relationship : relationships) {
-            statement.append(ScalabilityNodeRelationshipSuite.SOURCE_ID).append(" = '")
-                .append(relationship).append("' or ");
-        }
-
-        // removing latest ' or '
-        statement.delete(statement.lastIndexOf(" or "), statement.length());
-
-        statement.append("))]");
-        // order by jcr:created descending
-        statement.append(" order by").append(" @").append(ScalabilityNodeRelationshipSuite.CREATED)
-            .append(" descending");
-
-        LOG.debug("{}", statement);
-
-        return qm.createQuery(statement.toString(), Query.XPATH);
-    }
-
-    @Override
-    public void execute(Repository repository, Credentials credentials,
-        ExecutionContext context) throws Exception {
-        Session session = repository.login(credentials);
-        QueryManager qm;
-        try {
-            List<Authorizable> users = (List<Authorizable>) context.getMap()
-                .get(ScalabilityNodeRelationshipSuite.CTX_USER);
-            Random rand = new Random(99);
-            Authorizable user = users.get(rand.nextInt(users.size()));
-            List<String> targets = getRelatedUsers(session, user);
-            context.getMap().put(RELATIONSHIPS, targets);
-            qm = session.getWorkspace().getQueryManager();
-            search(qm, context);
-            context.getMap().remove(RELATIONSHIPS);
-        } catch (RepositoryException e) {
-            e.printStackTrace();
-        }
-    }
-
-    private List<String> getRelatedUsers(Session session, Authorizable user)
-        throws RepositoryException {
-        List<String> targets = Lists.newArrayList();
-        Node relRootNode =
-            session.getNode(user.getPath() + "/" + ScalabilityNodeRelationshipSuite.RELATIONSHIPS);
-        NodeIterator children = relRootNode.getNodes();
-        while (children.hasNext()) {
-            Node node = children.nextNode();
-            targets.add(node.getProperty(ScalabilityNodeRelationshipSuite.TARGET_ID).getString());
-        }
-        return targets;
-    }
-}
diff --git oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/FacetSearcher.java oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/FacetSearcher.java
deleted file mode 100644
index a23173e..0000000
--- oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/FacetSearcher.java
+++ /dev/null
@@ -1,43 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *   http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-package org.apache.jackrabbit.oak.scalability.benchmarks.search;
-
-import javax.jcr.RepositoryException;
-import javax.jcr.query.Query;
-import javax.jcr.query.QueryManager;
-import org.apache.jackrabbit.oak.scalability.suites.ScalabilityAbstractSuite;
-import org.jetbrains.annotations.NotNull;
-
-/**
- * Scalability test for facet query implementation
- */
-public class FacetSearcher extends SearchScalabilityBenchmark {
-
-    @Override
-    protected Query getQuery(@NotNull QueryManager qm, ScalabilityAbstractSuite.ExecutionContext context) throws RepositoryException {
-
-        final String statement = "select [jcr:path], [facet(jcr:primaryType)] from [nt:base] where native('lucene','*:*')";
-
-        LOG.debug("statement: {}", statement);
-
-        return qm.createQuery(statement, Query.JCR_SQL2);
-    }
-
-
-}
diff --git oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/FormatSearcher.java oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/FormatSearcher.java
deleted file mode 100644
index e7de878..0000000
--- oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/FormatSearcher.java
+++ /dev/null
@@ -1,61 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *   http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-package org.apache.jackrabbit.oak.scalability.benchmarks.search;
-
-import javax.jcr.RepositoryException;
-import javax.jcr.query.Query;
-import javax.jcr.query.QueryManager;
-
-import org.apache.jackrabbit.oak.benchmark.util.MimeType;
-import org.apache.jackrabbit.oak.spi.nodetype.NodeTypeConstants;
-import org.apache.jackrabbit.oak.scalability.suites.ScalabilityBlobSearchSuite;
-import org.apache.jackrabbit.oak.scalability.suites.ScalabilityAbstractSuite.ExecutionContext;
-
-/**
- * Searches on the file format/Mime type 
- *
- */
-public class FormatSearcher extends SearchScalabilityBenchmark {
-    @SuppressWarnings("deprecation")
-    @Override
-    protected Query getQuery(QueryManager qm, ExecutionContext context) throws RepositoryException {
-        StringBuilder statement = new StringBuilder("/jcr:root/");
-        
-        statement.append(((String) context.getMap().get(ScalabilityBlobSearchSuite.CTX_ROOT_NODE_NAME_PROP))).append("//element(*, ")
-            .append(context.getMap().get(ScalabilityBlobSearchSuite.CTX_FILE_NODE_TYPE_PROP)).append(")");
-        statement.append("[((");
-        
-        // adding all the possible mime-types in an OR fashion
-        for (MimeType mt : MimeType.values()) {
-            statement.append("jcr:content/@").append(NodeTypeConstants.JCR_MIMETYPE).append(" = '")
-                .append(mt.getValue()).append("' or ");
-        }
-
-        // removing latest ' or '
-        statement.delete(statement.lastIndexOf(" or "), statement.length());
-        
-        statement.append("))]");
-        
-        LOG.debug("{}", statement);
-        
-        return qm.createQuery(statement.toString(), Query.XPATH);
-    }
-    
-}
-
diff --git oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/FullTextSearcher.java oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/FullTextSearcher.java
deleted file mode 100644
index d8a10c1..0000000
--- oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/FullTextSearcher.java
+++ /dev/null
@@ -1,49 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *   http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-package org.apache.jackrabbit.oak.scalability.benchmarks.search;
-
-import java.util.List;
-import java.util.Random;
-
-import javax.jcr.RepositoryException;
-import javax.jcr.query.Query;
-import javax.jcr.query.QueryManager;
-import org.apache.jackrabbit.oak.scalability.suites.ScalabilityBlobSearchSuite;
-import org.apache.jackrabbit.oak.scalability.suites.ScalabilityAbstractSuite.ExecutionContext;
-import org.jetbrains.annotations.NotNull;
-
-/**
- * Full text query search
- *
- */
-public class FullTextSearcher extends SearchScalabilityBenchmark {
-    private final Random random = new Random(93);
-
-    @SuppressWarnings("deprecation")
-    @Override
-    protected Query getQuery(@NotNull final QueryManager qm, ExecutionContext context) throws RepositoryException {
-        @SuppressWarnings("unchecked")
-        List<String> paths = (List<String>) context.getMap().get(ScalabilityBlobSearchSuite.CTX_SEARCH_PATHS_PROP);
-        
-        return qm.createQuery("//*[jcr:contains(., '" + paths.get(random.nextInt(paths.size()))  + "File"
-                + "*"
-                + "')] ", Query.XPATH);
-    }
-}
-
diff --git oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/LastModifiedSearcher.java oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/LastModifiedSearcher.java
deleted file mode 100644
index f714ed5..0000000
--- oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/LastModifiedSearcher.java
+++ /dev/null
@@ -1,80 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *   http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-package org.apache.jackrabbit.oak.scalability.benchmarks.search;
-
-import javax.jcr.RepositoryException;
-import javax.jcr.query.Query;
-import javax.jcr.query.QueryManager;
-
-import org.apache.jackrabbit.oak.benchmark.util.Date;
-import org.apache.jackrabbit.oak.scalability.suites.ScalabilityBlobSearchSuite;
-import org.apache.jackrabbit.oak.scalability.suites.ScalabilityAbstractSuite.ExecutionContext;
-
-/**
- * perform searches using the {@code jcr:lastModified} and the provided timeframe
- */
-public class LastModifiedSearcher extends SearchScalabilityBenchmark {
-    private final Date timeframe;
-    
-    public LastModifiedSearcher(Date timeframe) {
-        this.timeframe = timeframe;
-    }
-    
-    @SuppressWarnings("deprecation")
-    @Override
-    protected Query getQuery(QueryManager qm, ExecutionContext context) throws RepositoryException {
-        //  /jcr:root/content/dam//element(*, dam:Asset)[(jcr:content/@jcr:lastModified >= xs:dateTime('2013-05-09T09:44:01.403Z'))
-        final String path = (String) context.getMap().get(ScalabilityBlobSearchSuite.CTX_ROOT_NODE_NAME_PROP);
-        final String statement = "/jcr:root/" + path + "//element(*, "
-                                 + context.getMap().get(ScalabilityBlobSearchSuite.CTX_FILE_NODE_TYPE_PROP)
-                                 + ")[(jcr:content/@jcr:lastModified >= xs:dateTime('"
-                                 + timeframe.toISO_8601_2000() + "'))]";
-        
-        LOG.debug("LastModifiedSearcher: {}", statement);
-        
-        return qm.createQuery(statement, Query.XPATH);
-    }
-
-    @Override
-    public String toString() {
-        String s = "::";
-        
-        switch(timeframe) {
-        case LAST_2_HRS:
-            s += "Hour";
-            break;
-        case LAST_24_HRS:
-            s += "Day";
-            break;
-        case LAST_7_DAYS:
-            s += "Week";
-            break;
-        case LAST_MONTH:
-            s += "Month";
-            break;
-        case LAST_YEAR:
-            s += "Year";
-            break;
-        default:
-        }
-        
-        return super.toString() + s;
-    }
-}
-
diff --git oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/MultiFilterOrderByKeysetPageSearcher.java oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/MultiFilterOrderByKeysetPageSearcher.java
deleted file mode 100644
index c633c7c..0000000
--- oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/MultiFilterOrderByKeysetPageSearcher.java
+++ /dev/null
@@ -1,35 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- *  or more contributor license agreements.  See the NOTICE file
- *  distributed with this work for additional information
- *  regarding copyright ownership.  The ASF licenses this file
- *  to you under the Apache License, Version 2.0 (the
- *  "License"); you may not use this file except in compliance
- *  with the License.  You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- *  Unless required by applicable law or agreed to in writing,
- *  software distributed under the License is distributed on an
- *  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- *  KIND, either express or implied.  See the License for the
- *  specific language governing permissions and limitations
- *  under the License.
- */
-package org.apache.jackrabbit.oak.scalability.benchmarks.search;
-
-import javax.jcr.RepositoryException;
-import javax.jcr.query.QueryManager;
-
-import org.apache.jackrabbit.oak.scalability.suites.ScalabilityAbstractSuite.ExecutionContext;
-
-/**
- * Simulates keyset pagination over the search {@link org.apache.jackrabbit.oak.scalability.benchmarks.search.MultiFilterOrderBySearcher}
- */
-public class MultiFilterOrderByKeysetPageSearcher extends MultiFilterOrderBySearcher {
-    @Override
-    protected void search(QueryManager qm, ExecutionContext context) throws RepositoryException {
-        processResultsKeysetPagination(qm, context);
-    }
-}
-
diff --git oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/MultiFilterOrderByOffsetPageSearcher.java oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/MultiFilterOrderByOffsetPageSearcher.java
deleted file mode 100644
index 20bbf9a..0000000
--- oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/MultiFilterOrderByOffsetPageSearcher.java
+++ /dev/null
@@ -1,35 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- *  or more contributor license agreements.  See the NOTICE file
- *  distributed with this work for additional information
- *  regarding copyright ownership.  The ASF licenses this file
- *  to you under the Apache License, Version 2.0 (the
- *  "License"); you may not use this file except in compliance
- *  with the License.  You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- *  Unless required by applicable law or agreed to in writing,
- *  software distributed under the License is distributed on an
- *  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- *  KIND, either express or implied.  See the License for the
- *  specific language governing permissions and limitations
- *  under the License.
- */
-package org.apache.jackrabbit.oak.scalability.benchmarks.search;
-
-import javax.jcr.RepositoryException;
-import javax.jcr.query.QueryManager;
-
-import org.apache.jackrabbit.oak.scalability.suites.ScalabilityAbstractSuite.ExecutionContext;
-
-/**
- * Simulates offset pagination over the search {@link org.apache.jackrabbit.oak.scalability.benchmarks.search.MultiFilterOrderBySearcher}
- */
-public class MultiFilterOrderByOffsetPageSearcher extends MultiFilterOrderBySearcher {
-    @Override
-    protected void search(QueryManager qm, ExecutionContext context) throws RepositoryException {
-        processResultsOffsetPagination(qm, context);
-    }
-}
-
diff --git oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/MultiFilterOrderBySearcher.java oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/MultiFilterOrderBySearcher.java
deleted file mode 100644
index e2808db..0000000
--- oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/MultiFilterOrderBySearcher.java
+++ /dev/null
@@ -1,66 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- *  or more contributor license agreements.  See the NOTICE file
- *  distributed with this work for additional information
- *  regarding copyright ownership.  The ASF licenses this file
- *  to you under the Apache License, Version 2.0 (the
- *  "License"); you may not use this file except in compliance
- *  with the License.  You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- *  Unless required by applicable law or agreed to in writing,
- *  software distributed under the License is distributed on an
- *  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- *  KIND, either express or implied.  See the License for the
- *  specific language governing permissions and limitations
- *  under the License.
- */
-package org.apache.jackrabbit.oak.scalability.benchmarks.search;
-
-import java.util.Calendar;
-
-import javax.jcr.RepositoryException;
-import javax.jcr.query.Query;
-import javax.jcr.query.QueryManager;
-
-import org.apache.jackrabbit.oak.benchmark.util.Date;
-import org.apache.jackrabbit.oak.scalability.suites.ScalabilityBlobSearchSuite;
-import org.apache.jackrabbit.oak.scalability.suites.ScalabilityNodeSuite;
-import org.apache.jackrabbit.oak.scalability.suites.ScalabilityAbstractSuite.ExecutionContext;
-import org.jetbrains.annotations.NotNull;
-
-/**
- * Searches on node with a filter property and orders the results by 2 properties 
- *
- */
-public class MultiFilterOrderBySearcher extends PaginationEnabledSearcher {
-    @SuppressWarnings("deprecation")
-    @Override
-    protected Query getQuery(@NotNull QueryManager qm, ExecutionContext context)
-        throws RepositoryException {
-        // /jcr:root/LongevitySearchAssets/12345//element(*, ParentType)[(@filter = 'true' or not
-        // (@filter)] order by @viewed descending, @added descending
-        StringBuilder statement = new StringBuilder("/jcr:root/");
-
-        statement.append(
-            ((String) context.getMap().get(ScalabilityBlobSearchSuite.CTX_ROOT_NODE_NAME_PROP)))
-            .append("//element(*, ")
-            .append(context.getMap().get(ScalabilityNodeSuite.CTX_ACT_NODE_TYPE_PROP)).append(")");
-        statement.append("[((").append("@").append(ScalabilityNodeSuite.FILTER_PROP)
-            .append(" = 'true'").append(" or").append(" not(@")
-            .append(ScalabilityNodeSuite.FILTER_PROP).append("))");
-        if (context.getMap().containsKey(KEYSET_VAL_PROP)) {
-            statement.append(" and @").append(ScalabilityNodeSuite.CTX_PAGINATION_KEY_PROP)
-                .append(" < xs:dateTime('").append(
-                Date.convertToISO_8601_2000((Calendar) context.getMap().get(KEYSET_VAL_PROP)))
-                .append("')");
-        }
-        statement.append(")]").append(getOrderByClause());
-
-        LOG.debug("{}", statement);
-
-        return qm.createQuery(statement.toString(), Query.XPATH);
-    }
-}
-
diff --git oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/MultiFilterSplitOrderByKeysetPageSearcher.java oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/MultiFilterSplitOrderByKeysetPageSearcher.java
deleted file mode 100644
index 7765914..0000000
--- oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/MultiFilterSplitOrderByKeysetPageSearcher.java
+++ /dev/null
@@ -1,36 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- *  or more contributor license agreements.  See the NOTICE file
- *  distributed with this work for additional information
- *  regarding copyright ownership.  The ASF licenses this file
- *  to you under the Apache License, Version 2.0 (the
- *  "License"); you may not use this file except in compliance
- *  with the License.  You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- *  Unless required by applicable law or agreed to in writing,
- *  software distributed under the License is distributed on an
- *  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- *  KIND, either express or implied.  See the License for the
- *  specific language governing permissions and limitations
- *  under the License.
- */
-package org.apache.jackrabbit.oak.scalability.benchmarks.search;
-
-import org.apache.jackrabbit.oak.scalability.suites.ScalabilityAbstractSuite.ExecutionContext;
-
-import javax.jcr.RepositoryException;
-import javax.jcr.query.QueryManager;
-
-/**
- * Simulates keyset pagination over the search {@link org.apache.jackrabbit.oak.scalability.benchmarks.search.MultiFilterSplitOrderBySearcher}
- */
-public class MultiFilterSplitOrderByKeysetPageSearcher extends MultiFilterSplitOrderBySearcher {
-    @Override
-    protected void search(QueryManager qm, ExecutionContext context) throws RepositoryException {
-        searchCommon(qm, context);
-        processResultsKeysetPagination(qm, context);
-    }
-}
-
diff --git oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/MultiFilterSplitOrderByOffsetPageSearcher.java oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/MultiFilterSplitOrderByOffsetPageSearcher.java
deleted file mode 100644
index 4ad5cef..0000000
--- oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/MultiFilterSplitOrderByOffsetPageSearcher.java
+++ /dev/null
@@ -1,37 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- *  or more contributor license agreements.  See the NOTICE file
- *  distributed with this work for additional information
- *  regarding copyright ownership.  The ASF licenses this file
- *  to you under the Apache License, Version 2.0 (the
- *  "License"); you may not use this file except in compliance
- *  with the License.  You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- *  Unless required by applicable law or agreed to in writing,
- *  software distributed under the License is distributed on an
- *  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- *  KIND, either express or implied.  See the License for the
- *  specific language governing permissions and limitations
- *  under the License.
- */
-
-package org.apache.jackrabbit.oak.scalability.benchmarks.search;
-
-import javax.jcr.RepositoryException;
-import javax.jcr.query.QueryManager;
-
-import org.apache.jackrabbit.oak.scalability.suites.ScalabilityAbstractSuite;
-
-/**
- * Simulates offset pagination over the search {@link org.apache.jackrabbit.oak.scalability.benchmarks.search.MultiFilterSplitOrderBySearcher}
- */
-public class MultiFilterSplitOrderByOffsetPageSearcher extends MultiFilterSplitOrderBySearcher {
-    @Override
-    protected void search(QueryManager qm, ScalabilityAbstractSuite.ExecutionContext context)
-        throws RepositoryException {
-        searchCommon(qm, context);
-        processResultsOffsetPagination(qm, context);
-    }
-}
diff --git oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/MultiFilterSplitOrderBySearcher.java oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/MultiFilterSplitOrderBySearcher.java
deleted file mode 100644
index 062590d..0000000
--- oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/MultiFilterSplitOrderBySearcher.java
+++ /dev/null
@@ -1,89 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- *  or more contributor license agreements.  See the NOTICE file
- *  distributed with this work for additional information
- *  regarding copyright ownership.  The ASF licenses this file
- *  to you under the Apache License, Version 2.0 (the
- *  "License"); you may not use this file except in compliance
- *  with the License.  You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- *  Unless required by applicable law or agreed to in writing,
- *  software distributed under the License is distributed on an
- *  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- *  KIND, either express or implied.  See the License for the
- *  specific language governing permissions and limitations
- *  under the License.
- */
-
-package org.apache.jackrabbit.oak.scalability.benchmarks.search;
-
-import javax.jcr.Node;
-import javax.jcr.RepositoryException;
-import javax.jcr.query.*;
-
-import org.apache.jackrabbit.oak.scalability.suites.ScalabilityBlobSearchSuite;
-import org.apache.jackrabbit.oak.scalability.suites.ScalabilityNodeSuite;
-import org.apache.jackrabbit.oak.scalability.suites.ScalabilityAbstractSuite.ExecutionContext;
-import org.jetbrains.annotations.NotNull;
-
-/**
- * Splits the query in {@link org.apache.jackrabbit.oak.scalability.benchmarks.search.MultiFilterOrderBySearcher}
- * into multiple queries and unions the results.
- */
-public class MultiFilterSplitOrderBySearcher extends MultiFilterOrderBySearcher {
-    @Override
-    protected void search(QueryManager qm, ExecutionContext context)
-        throws RepositoryException {
-        searchCommon(qm, context);
-
-        Query q = getQuery(qm, context);
-        QueryResult r = q.execute();
-        RowIterator it = r.getRows();
-
-        for (int rows = 0; it.hasNext() && rows < LIMIT; rows++) {
-            Node node = it.nextRow().getNode();
-            LOG.debug(node.getPath());
-        }
-    }
-
-    protected void searchCommon(QueryManager qm, ExecutionContext
-        context) throws RepositoryException {
-        /** Execute standard query */
-        Query stdQuery = getStandardQuery(qm, context);
-        stdQuery.setLimit(LIMIT);
-        QueryResult stdResult = stdQuery.execute();
-        RowIterator stdIt = stdResult.getRows();
-
-        // Iterate the standard shown first
-        for (int rows = 0; stdIt.hasNext() && rows < LIMIT; rows++) {
-            Node node = stdIt.nextRow().getNode();
-            LOG.debug(node.getPath());
-        }
-    }
-
-    protected Query getStandardQuery(@NotNull final QueryManager qm, ExecutionContext context)
-        throws RepositoryException {
-        // /jcr:root/LongevitySearchAssets/12345//element(*, ParentType)[(@viewed = 'true')] order
-        // by @viewed descending
-        StringBuilder statement = new StringBuilder("/jcr:root/");
-
-        statement.append(
-            ((String) context.getMap().get(ScalabilityBlobSearchSuite.CTX_ROOT_NODE_NAME_PROP)))
-            .append("//element(*, ")
-            .append(context.getMap().get(ScalabilityNodeSuite.CTX_ACT_NODE_TYPE_PROP)).append(")");
-        statement.append("[(").append("@").append(ScalabilityNodeSuite.SORT_PROP)
-            .append("= 'true'");
-        statement.append(")]");
-
-        LOG.debug("{}", statement);
-
-        return qm.createQuery(statement.toString(), Query.XPATH);
-    }
-
-    @Override
-    protected String getOrderByClause() {
-        return " order by" + " @" + ScalabilityNodeSuite.DATE_PROP + " descending";
-    }
-}
diff --git oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/NodeTypeSearcher.java oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/NodeTypeSearcher.java
deleted file mode 100644
index 7e8748a..0000000
--- oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/NodeTypeSearcher.java
+++ /dev/null
@@ -1,43 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *   http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-package org.apache.jackrabbit.oak.scalability.benchmarks.search;
-
-import javax.jcr.RepositoryException;
-import javax.jcr.query.Query;
-import javax.jcr.query.QueryManager;
-import org.apache.jackrabbit.oak.scalability.suites.ScalabilityBlobSearchSuite;
-import org.apache.jackrabbit.oak.scalability.suites.ScalabilityAbstractSuite.ExecutionContext;
-import org.jetbrains.annotations.NotNull;
-
-/**
- * Searches on the NodeType 
- *
- */
-public class NodeTypeSearcher extends SearchScalabilityBenchmark {
-    
-    @SuppressWarnings("deprecation")
-    @Override
-    protected Query getQuery(@NotNull final QueryManager qm, ExecutionContext context) throws RepositoryException {
-        return qm.createQuery(
-                "/jcr:root/" + ((String) context.getMap().get(ScalabilityBlobSearchSuite.CTX_ROOT_NODE_NAME_PROP)) + "//element(*, "
-                        + context.getMap().get(ScalabilityBlobSearchSuite.CTX_FILE_NODE_TYPE_PROP) + ")",
-                Query.XPATH);
-    }
-}
-
diff --git oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/OrderByDate.java oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/OrderByDate.java
deleted file mode 100644
index 3b2c281..0000000
--- oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/OrderByDate.java
+++ /dev/null
@@ -1,43 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *      http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.jackrabbit.oak.scalability.benchmarks.search;
-
-import javax.jcr.RepositoryException;
-import javax.jcr.query.Query;
-import javax.jcr.query.QueryManager;
-import org.apache.jackrabbit.oak.scalability.suites.ScalabilityBlobSearchSuite;
-import org.apache.jackrabbit.oak.scalability.suites.ScalabilityAbstractSuite.ExecutionContext;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-public class OrderByDate extends SearchScalabilityBenchmark {
-    private static final Logger LOG = LoggerFactory.getLogger(OrderByDate.class);
-    
-    @Override
-    protected Query getQuery(final QueryManager qm, final ExecutionContext context) throws RepositoryException {
-        final String path = (String) context.getMap().get(
-            ScalabilityBlobSearchSuite.CTX_ROOT_NODE_NAME_PROP);
-        final String statement = String.format(
-            "SELECT * FROM [%s] WHERE ISDESCENDANTNODE('/%s') ORDER BY [jcr:content/jcr:lastModified]",
-            context.getMap().get(ScalabilityBlobSearchSuite.CTX_FILE_NODE_TYPE_PROP),
-            path);
-        
-        LOG.debug("statement: {}", statement);
-        
-        return qm.createQuery(statement, Query.JCR_SQL2);
-    }
-}
diff --git oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/OrderByKeysetPageSearcher.java oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/OrderByKeysetPageSearcher.java
deleted file mode 100644
index e5c7b0c..0000000
--- oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/OrderByKeysetPageSearcher.java
+++ /dev/null
@@ -1,35 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- *  or more contributor license agreements.  See the NOTICE file
- *  distributed with this work for additional information
- *  regarding copyright ownership.  The ASF licenses this file
- *  to you under the Apache License, Version 2.0 (the
- *  "License"); you may not use this file except in compliance
- *  with the License.  You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- *  Unless required by applicable law or agreed to in writing,
- *  software distributed under the License is distributed on an
- *  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- *  KIND, either express or implied.  See the License for the
- *  specific language governing permissions and limitations
- *  under the License.
- */
-package org.apache.jackrabbit.oak.scalability.benchmarks.search;
-
-import javax.jcr.RepositoryException;
-import javax.jcr.query.QueryManager;
-
-import org.apache.jackrabbit.oak.scalability.suites.ScalabilityAbstractSuite.ExecutionContext;
-
-/**
- * Simulates keyset pagination over the search {@link org.apache.jackrabbit.oak.scalability.benchmarks.search.OrderBySearcher}
- */
-public class OrderByKeysetPageSearcher extends OrderBySearcher {
-    @Override
-    protected void search(QueryManager qm, ExecutionContext context) throws RepositoryException {
-        processResultsKeysetPagination(qm, context);
-    }
-}
-
diff --git oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/OrderByOffsetPageSearcher.java oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/OrderByOffsetPageSearcher.java
deleted file mode 100644
index c91223b..0000000
--- oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/OrderByOffsetPageSearcher.java
+++ /dev/null
@@ -1,35 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- *  or more contributor license agreements.  See the NOTICE file
- *  distributed with this work for additional information
- *  regarding copyright ownership.  The ASF licenses this file
- *  to you under the Apache License, Version 2.0 (the
- *  "License"); you may not use this file except in compliance
- *  with the License.  You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- *  Unless required by applicable law or agreed to in writing,
- *  software distributed under the License is distributed on an
- *  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- *  KIND, either express or implied.  See the License for the
- *  specific language governing permissions and limitations
- *  under the License.
- */
-package org.apache.jackrabbit.oak.scalability.benchmarks.search;
-
-import javax.jcr.RepositoryException;
-import javax.jcr.query.QueryManager;
-
-import org.apache.jackrabbit.oak.scalability.suites.ScalabilityAbstractSuite.ExecutionContext;
-
-/**
- * Simulates offset pagination over the search {@link org.apache.jackrabbit.oak.scalability.benchmarks.search.OrderBySearcher}
- */
-public class OrderByOffsetPageSearcher extends OrderBySearcher {
-    @Override
-    protected void search(QueryManager qm, ExecutionContext context) throws RepositoryException {
-        processResultsOffsetPagination(qm, context);
-    }
-}
-
diff --git oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/OrderBySearcher.java oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/OrderBySearcher.java
deleted file mode 100644
index 2bf9c13..0000000
--- oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/OrderBySearcher.java
+++ /dev/null
@@ -1,62 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- *  or more contributor license agreements.  See the NOTICE file
- *  distributed with this work for additional information
- *  regarding copyright ownership.  The ASF licenses this file
- *  to you under the Apache License, Version 2.0 (the
- *  "License"); you may not use this file except in compliance
- *  with the License.  You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- *  Unless required by applicable law or agreed to in writing,
- *  software distributed under the License is distributed on an
- *  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- *  KIND, either express or implied.  See the License for the
- *  specific language governing permissions and limitations
- *  under the License.
- */
-package org.apache.jackrabbit.oak.scalability.benchmarks.search;
-
-import java.util.Calendar;
-
-import javax.jcr.RepositoryException;
-import javax.jcr.query.Query;
-import javax.jcr.query.QueryManager;
-
-import org.apache.jackrabbit.oak.benchmark.util.Date;
-import org.apache.jackrabbit.oak.scalability.suites.ScalabilityBlobSearchSuite;
-import org.apache.jackrabbit.oak.scalability.suites.ScalabilityNodeSuite;
-import org.apache.jackrabbit.oak.scalability.suites.ScalabilityAbstractSuite.ExecutionContext;
-import org.jetbrains.annotations.NotNull;
-
-/**
- * Searches on path and orders the results by 2 properties
- */
-public class OrderBySearcher extends PaginationEnabledSearcher {
-    @SuppressWarnings("deprecation") @Override
-    protected Query getQuery(@NotNull QueryManager qm, ExecutionContext context)
-        throws RepositoryException {
-        // /jcr:root/LongevitySearchAssets/12345//element(*, ParentType) order by @viewed
-        // descending, @added descending
-        StringBuilder statement = new StringBuilder("/jcr:root/");
-
-        statement.append(
-            ((String) context.getMap().get(ScalabilityBlobSearchSuite.CTX_ROOT_NODE_NAME_PROP)))
-            .append("//element(*, ")
-            .append(context.getMap().get(ScalabilityNodeSuite.CTX_ACT_NODE_TYPE_PROP)).append(")");
-        if (context.getMap().containsKey(KEYSET_VAL_PROP)) {
-            statement.append("[(").append("@").append(ScalabilityNodeSuite.CTX_PAGINATION_KEY_PROP)
-                .append(" < xs:dateTime('").append(
-                Date.convertToISO_8601_2000((Calendar) context.getMap().get(KEYSET_VAL_PROP)))
-                .append("'))]");
-        }
-
-        statement.append(getOrderByClause());
-
-        LOG.debug("{}", statement);
-
-        return qm.createQuery(statement.toString(), Query.XPATH);
-    }
-}
-
diff --git oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/PaginationEnabledSearcher.java oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/PaginationEnabledSearcher.java
deleted file mode 100644
index 81ff698..0000000
--- oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/PaginationEnabledSearcher.java
+++ /dev/null
@@ -1,101 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- *  or more contributor license agreements.  See the NOTICE file
- *  distributed with this work for additional information
- *  regarding copyright ownership.  The ASF licenses this file
- *  to you under the Apache License, Version 2.0 (the
- *  "License"); you may not use this file except in compliance
- *  with the License.  You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- *  Unless required by applicable law or agreed to in writing,
- *  software distributed under the License is distributed on an
- *  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- *  KIND, either express or implied.  See the License for the
- *  specific language governing permissions and limitations
- *  under the License.
- */
-package org.apache.jackrabbit.oak.scalability.benchmarks.search;
-
-import java.util.Calendar;
-import java.util.TimeZone;
-
-import javax.jcr.Node;
-import javax.jcr.Property;
-import javax.jcr.RepositoryException;
-import javax.jcr.query.Query;
-import javax.jcr.query.QueryManager;
-import javax.jcr.query.QueryResult;
-import javax.jcr.query.RowIterator;
-import org.apache.jackrabbit.oak.scalability.suites.ScalabilityNodeSuite;
-import org.apache.jackrabbit.oak.scalability.suites.ScalabilityAbstractSuite.ExecutionContext;
-import org.jetbrains.annotations.NotNull;
-
-/**
- * Abstract class which defines utility methods for processing results like 
- * pagination and no pagination. 
- *
- */
-public abstract class PaginationEnabledSearcher extends SearchScalabilityBenchmark {
-    /**
-     * Pagination limit for one page
-     */
-    protected static final int LIMIT = Integer.getInteger("limit", 25);
-
-    /**
-     * Number of page accesses
-     */
-    protected static final int PAGES = Integer.getInteger("pages", 5);
-
-    protected static final String KEYSET_VAL_PROP = "keysetval";
-
-    protected void processResultsOffsetPagination(@NotNull final QueryManager qm,
-            ExecutionContext context) throws RepositoryException {
-        for (int page = 0; page < PAGES; page++) {
-            Query query = getQuery(qm, context);
-            query.setLimit(LIMIT);
-            query.setOffset(page * LIMIT);
-
-            iterate(query);
-        }
-    }
-
-    private Node iterate(Query query) throws RepositoryException {
-        QueryResult r = query.execute();
-        RowIterator it = r.getRows();
-        Node last = null;
-
-        while (it.hasNext()) {
-            last = it.nextRow().getNode();
-            LOG.debug(last.getPath());
-        }
-        return last;
-    }
-
-    protected void processResultsKeysetPagination(@NotNull final QueryManager qm,
-            ExecutionContext context) throws RepositoryException {
-        Calendar now = Calendar.getInstance();
-        now.setTimeZone(TimeZone.getTimeZone("GMT"));
-        context.getMap().put(KEYSET_VAL_PROP, now);
-
-        for (int page = 0; page < PAGES; page++) {
-            Query query = getQuery(qm, context);
-            query.setLimit(LIMIT);
-
-            Node lastNode = iterate(query);
-            if (lastNode != null) {
-                Property prop =
-                        lastNode.getProperty(ScalabilityNodeSuite.CTX_PAGINATION_KEY_PROP);
-                context.getMap().put(KEYSET_VAL_PROP, prop.getDate());
-            }
-        }
-        context.getMap().remove(KEYSET_VAL_PROP);
-    }
-
-    protected String getOrderByClause() {
-        return " order by" + " @" + ScalabilityNodeSuite.SORT_PROP + " descending," + " @"
-            + ScalabilityNodeSuite.DATE_PROP + " descending";
-    }
-}
-
diff --git oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/SearchScalabilityBenchmark.java oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/SearchScalabilityBenchmark.java
deleted file mode 100644
index 4355a10..0000000
--- oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/SearchScalabilityBenchmark.java
+++ /dev/null
@@ -1,74 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *   http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-package org.apache.jackrabbit.oak.scalability.benchmarks.search;
-
-import javax.jcr.Credentials;
-import javax.jcr.Node;
-import javax.jcr.Repository;
-import javax.jcr.RepositoryException;
-import javax.jcr.Session;
-import javax.jcr.query.Query;
-import javax.jcr.query.QueryManager;
-import javax.jcr.query.QueryResult;
-import javax.jcr.query.RowIterator;
-import org.apache.jackrabbit.oak.scalability.benchmarks.ScalabilityBenchmark;
-import org.apache.jackrabbit.oak.scalability.suites.ScalabilityAbstractSuite.ExecutionContext;
-import org.jetbrains.annotations.NotNull;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-/**
- * Abstract class for search scalability benchmarks.
- *
- */
-public abstract class SearchScalabilityBenchmark extends ScalabilityBenchmark {
-    protected static final Logger LOG = LoggerFactory.getLogger(SearchScalabilityBenchmark.class);    
-
-    /**
-     * Controls the max results retrieved after search
-     */
-    private static final int MAX_RESULTS = Integer.getInteger("maxResults", 100);
-
-    @Override
-    public void execute(Repository repository, Credentials credentials, ExecutionContext context) 
-            throws Exception {
-        Session session = repository.login(credentials);
-        QueryManager qm;
-        try {
-            qm = session.getWorkspace().getQueryManager();
-            search(qm, context);
-        } catch (RepositoryException e) {
-            e.printStackTrace();
-        }
-    }
-
-    protected void search(QueryManager qm, ExecutionContext context) throws RepositoryException {
-        Query q = getQuery(qm, context);
-        QueryResult r = q.execute();
-        RowIterator it = r.getRows();
-        for (int rows = 0; it.hasNext() && rows < MAX_RESULTS; rows++) {
-            Node node = it.nextRow().getNode();
-            LOG.debug(node.getPath());
-        }
-    }
-
-    protected abstract Query getQuery(@NotNull final QueryManager qm, ExecutionContext context) 
-            throws RepositoryException;
-}
-
diff --git oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/SplitOrderByKeysetPageSearcher.java oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/SplitOrderByKeysetPageSearcher.java
deleted file mode 100644
index 5ca65be..0000000
--- oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/SplitOrderByKeysetPageSearcher.java
+++ /dev/null
@@ -1,35 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- *  or more contributor license agreements.  See the NOTICE file
- *  distributed with this work for additional information
- *  regarding copyright ownership.  The ASF licenses this file
- *  to you under the Apache License, Version 2.0 (the
- *  "License"); you may not use this file except in compliance
- *  with the License.  You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- *  Unless required by applicable law or agreed to in writing,
- *  software distributed under the License is distributed on an
- *  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- *  KIND, either express or implied.  See the License for the
- *  specific language governing permissions and limitations
- *  under the License.
- */
-package org.apache.jackrabbit.oak.scalability.benchmarks.search;
-
-import org.apache.jackrabbit.oak.scalability.suites.ScalabilityAbstractSuite.ExecutionContext;
-
-import javax.jcr.RepositoryException;
-import javax.jcr.query.QueryManager;
-
-/**
- * Simulates keyset pagination over the search {@link org.apache.jackrabbit.oak.scalability.benchmarks.search.SplitOrderBySearcher}
- */
-public class SplitOrderByKeysetPageSearcher extends SplitOrderBySearcher {
-    @Override
-    protected void search(QueryManager qm, ExecutionContext context) throws RepositoryException {
-        searchCommon(qm, context);
-        processResultsKeysetPagination(qm, context);
-    }
-}
diff --git oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/SplitOrderByOffsetPageSearcher.java oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/SplitOrderByOffsetPageSearcher.java
deleted file mode 100644
index 765b90c..0000000
--- oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/SplitOrderByOffsetPageSearcher.java
+++ /dev/null
@@ -1,36 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- *  or more contributor license agreements.  See the NOTICE file
- *  distributed with this work for additional information
- *  regarding copyright ownership.  The ASF licenses this file
- *  to you under the Apache License, Version 2.0 (the
- *  "License"); you may not use this file except in compliance
- *  with the License.  You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- *  Unless required by applicable law or agreed to in writing,
- *  software distributed under the License is distributed on an
- *  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- *  KIND, either express or implied.  See the License for the
- *  specific language governing permissions and limitations
- *  under the License.
- */
-package org.apache.jackrabbit.oak.scalability.benchmarks.search;
-
-import org.apache.jackrabbit.oak.scalability.suites.ScalabilityAbstractSuite.ExecutionContext;
-
-import javax.jcr.RepositoryException;
-import javax.jcr.query.QueryManager;
-
-/**
- * Simulates offset pagination over the search {@link org.apache.jackrabbit.oak.scalability.benchmarks.search.SplitOrderBySearcher}
- */
-public class SplitOrderByOffsetPageSearcher extends SplitOrderBySearcher {
-    @Override
-    protected void search(QueryManager qm, ExecutionContext context) throws RepositoryException {
-        searchCommon(qm, context);
-        processResultsOffsetPagination(qm, context);
-    }
-}
-
diff --git oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/SplitOrderBySearcher.java oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/SplitOrderBySearcher.java
deleted file mode 100644
index deb118d..0000000
--- oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/scalability/benchmarks/search/SplitOrderBySearcher.java
+++ /dev/null
@@ -1,92 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- *  or more contributor license agreements.  See the NOTICE file
- *  distributed with this work for additional information
- *  regarding copyright ownership.  The ASF licenses this file
- *  to you under the Apache License, Version 2.0 (the
- *  "License"); you may not use this file except in compliance
- *  with the License.  You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- *  Unless required by applicable law or agreed to in writing,
- *  software distributed under the License is distributed on an
- *  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- *  KIND, either express or implied.  See the License for the
- *  specific language governing permissions and limitations
- *  under the License.
- */
-package org.apache.jackrabbit.oak.scalability.benchmarks.search;
-
-import org.apache.jackrabbit.oak.scalability.suites.ScalabilityBlobSearchSuite;
-import org.apache.jackrabbit.oak.scalability.suites.ScalabilityNodeSuite;
-import org.apache.jackrabbit.oak.scalability.suites.ScalabilityAbstractSuite.ExecutionContext;
-import org.jetbrains.annotations.NotNull;
-
-import javax.jcr.Node;
-import javax.jcr.RepositoryException;
-import javax.jcr.query.Query;
-import javax.jcr.query.QueryManager;
-import javax.jcr.query.QueryResult;
-import javax.jcr.query.RowIterator;
-
-/**
- * Splits the search in {@link org.apache.jackrabbit.oak.scalability.benchmarks.search.OrderBySearcher} to multiple
- * queries and unions the results.
- *
- */
-public class SplitOrderBySearcher extends OrderBySearcher {
-    @Override
-    protected void search(QueryManager qm, ExecutionContext context)
-        throws RepositoryException {
-        searchCommon(qm, context);
-
-        Query q = getQuery(qm, context);
-        QueryResult r = q.execute();
-        RowIterator it = r.getRows();
-
-        for (int rows = 0; it.hasNext() && rows < LIMIT; rows++) {
-            Node node = it.nextRow().getNode();
-            LOG.debug(node.getPath());
-        }
-    }
-
-    protected void searchCommon(QueryManager qm, ExecutionContext context)
-        throws RepositoryException {
-        /** Execute standard query */
-        Query stdQuery = getStandardQuery(qm, context);
-        stdQuery.setLimit(LIMIT);
-        QueryResult stdResult = stdQuery.execute();
-        RowIterator stdIt = stdResult.getRows();
-
-        // Iterate the standard shown first
-        for (int rows = 0; stdIt.hasNext() && rows < LIMIT; rows++) {
-            Node node = stdIt.nextRow().getNode();
-            LOG.debug(node.getPath());
-        }
-    }
-
-    protected Query getStandardQuery(@NotNull final QueryManager qm,
-        ExecutionContext context)
-        throws RepositoryException {
-        // /jcr:root/LongevitySearchAssets/12345//element(*, ParentType)[(@viewed = 'true')]
-        StringBuilder statement = new StringBuilder("/jcr:root/");
-
-        statement.append(
-            ((String) context.getMap().get(ScalabilityBlobSearchSuite.CTX_ROOT_NODE_NAME_PROP)))
-            .append("//element(*, ")
-            .append(context.getMap().get(ScalabilityNodeSuite.CTX_ACT_NODE_TYPE_PROP)).append(")");
-        statement.append("[(").append("@").append(ScalabilityNodeSuite.SORT_PROP).append("= 'true'")
-            .append(")]");
-
-        LOG.debug("{}", statement);
-
-        return qm.createQuery(statement.toString(), Query.XPATH);
-    }
-
-    @Override
-    protected String getOrderByClause() {
-        return " order by" + " @" + ScalabilityNodeSuite.DATE_PROP + " descending";
-    }
-}
-
diff --git oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/scalability/suites/ScalabilityBlobSearchSuite.java oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/scalability/suites/ScalabilityBlobSearchSuite.java
deleted file mode 100644
index 77bfa2b..0000000
--- oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/scalability/suites/ScalabilityBlobSearchSuite.java
+++ /dev/null
@@ -1,445 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *   http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
- */
-package org.apache.jackrabbit.oak.scalability.suites;
-
-import static com.google.common.collect.Lists.newArrayList;
-import static com.google.common.collect.Lists.newArrayListWithCapacity;
-
-import java.util.List;
-import java.util.Random;
-import java.util.concurrent.TimeUnit;
-
-import javax.jcr.Binary;
-import javax.jcr.Node;
-import javax.jcr.Property;
-import javax.jcr.PropertyType;
-import javax.jcr.RepositoryException;
-import javax.jcr.Session;
-import javax.jcr.UnsupportedRepositoryOperationException;
-import javax.jcr.ValueFormatException;
-import javax.jcr.lock.LockException;
-import javax.jcr.nodetype.ConstraintViolationException;
-import javax.jcr.nodetype.NodeType;
-import javax.jcr.version.VersionException;
-
-import com.google.common.base.Stopwatch;
-import com.google.common.base.Strings;
-import com.google.common.collect.Lists;
-
-import org.apache.commons.io.output.NullOutputStream;
-import org.apache.commons.math.stat.descriptive.SynchronizedDescriptiveStatistics;
-import org.apache.jackrabbit.commons.JcrUtils;
-import org.apache.jackrabbit.oak.benchmark.TestInputStream;
-import org.apache.jackrabbit.oak.benchmark.util.Date;
-import org.apache.jackrabbit.oak.benchmark.util.MimeType;
-import org.apache.jackrabbit.oak.benchmark.util.OakIndexUtils;
-import org.apache.jackrabbit.oak.spi.nodetype.NodeTypeConstants;
-import org.apache.jackrabbit.oak.scalability.util.NodeTypeUtils;
-
-
-/**
- * The suite test will incrementally increase the load and execute searches.
- * Each test run thus adds blobs and executes different searches. This way we measure time taken for
- * search(es) execution.
- *
- * <p>
- * The following system JVM properties can be defined to configure the suite.
- * <ul>
- * <li>
- *     <code>fileWriters</code> - Controls the number of concurrent background threads for writing blobs.
- *     Defaults to 0.
- * </li>
- * <li>
- *     <code>fileReaders</code> - Controls the number of concurrent background threads for reading blobs.
- *     Defaults to 1.
- * </li>
- * <li>
- *     <code>fileSize</code> - Controls the size in KB of the blobs. Defaults to 1.
- * </li>
- * <li>
- *     <code>maxAssets</code> - Controls the max child nodes created under a node. Defaults to 500.
- * </li>
- * </ul>
- */
-public class ScalabilityBlobSearchSuite extends ScalabilityNodeSuite {
-    private static final int FILE_SIZE = Integer.getInteger("fileSize", 1);
-
-    /**
-     * Controls the number of concurrent threads for writing blobs
-     */
-    private static final int WRITERS = Integer.getInteger("fileWriters", 0);
-
-    /**
-     * Controls the number of concurrent thread for reading blobs
-     */
-    private static final int READERS = Integer.getInteger("fileReaders", 0);
-
-    /**
-     * Controls the max child nodes created under a node.
-     */
-    private static final int MAX_ASSETS_PER_LEVEL = Integer.getInteger("maxAssets", 500);
-
-    public static final String CTX_FILE_NODE_TYPE_PROP = "nodeType";
-
-    private static final String CUSTOM_PATH_PROP = "contentPath";
-
-    private static final String CUSTOM_REF_PROP = "references";
-
-    private static final String CUSTOM_NODE_TYPE = "Asset";
-
-    private static final String CUSTOM_INDEX_TYPE = "AssetIndex";
-
-    private final Random random = new Random(29);
-
-    private List<String> searchPaths;
-
-    private List<String> readPaths;
-    private String nodeType;
-    private String indexType;
-
-    public ScalabilityBlobSearchSuite(Boolean storageEnabled) {
-        super(storageEnabled);
-    }
-
-
-    @Override
-    protected void beforeSuite() throws Exception {
-        Session session = loginWriter();
-        Node root = session.getRootNode();
-        root.addNode(ROOT_NODE_NAME);
-        session.save();
-
-        if (CUSTOM_TYPE) {
-            indexType =
-                    NodeTypeUtils.createNodeType(session, CUSTOM_INDEX_TYPE, null, null, null,
-                            null, null, true);
-            setNodeType(NodeTypeUtils.createNodeType(
-                    session, CUSTOM_NODE_TYPE,
-                    new String[] {CUSTOM_PATH_PROP, CUSTOM_REF_PROP},
-                    new int[] {PropertyType.STRING, PropertyType.STRING},                    
-                    new String[] {indexType}, null, NodeTypeConstants.NT_FILE, false));
-        } else {
-            String type = NodeTypeConstants.NT_UNSTRUCTURED;
-            if (session.getWorkspace().getNodeTypeManager().hasNodeType(
-                    NodeTypeConstants.NT_OAK_UNSTRUCTURED)) {
-                type = NodeTypeConstants.NT_OAK_UNSTRUCTURED;
-            }
-            setNodeType(type);
-        }
-
-        // defining indexes
-        if (INDEX) {
-            OakIndexUtils.propertyIndexDefinition(session, NodeTypeConstants.JCR_MIMETYPE,
-                new String[] {NodeTypeConstants.JCR_MIMETYPE}, false,
-                (Strings.isNullOrEmpty(indexType) ? new String[0] : new String[] {indexType}));
-            OakIndexUtils
-                .orderedIndexDefinition(session, NodeTypeConstants.JCR_LASTMODIFIED, ASYNC_INDEX,
-                    new String[] {NodeTypeConstants.JCR_LASTMODIFIED}, false,
-                    (Strings.isNullOrEmpty(indexType) ? new String[0] : new String[] {indexType}),
-                    null);
-        }
-    }
-
-    /**
-     * Executes before each test run
-     */
-    @Override
-    public void beforeIteration(ExecutionContext context) throws RepositoryException {
-        if (LOG.isDebugEnabled()) {
-            LOG.debug("Started beforeIteration()");
-        }
-
-        // recreate paths created in this run
-        searchPaths = newArrayList();
-        readPaths = newArrayListWithCapacity(READERS);
-
-        // create the blob load for this iteration
-        createLoad(context);
-
-        // Add background jobs to simulate workload
-        for (int i = 0; i < WRITERS; i++) {
-            /* Each writer will write to a directory of the form load-b-i */
-            addBackgroundJob(new BlobWriter(String.valueOf(context.getIncrement() + "-b-" + i), 1,
-                    null));
-        }
-        for (int i = 0; i < READERS; i++) {
-            addBackgroundJob(new Reader());
-        }
-
-        if (LOG.isDebugEnabled()) {
-            LOG.debug("Finish beforeIteration()");
-        }
-
-        context.getMap().put(CTX_ROOT_NODE_NAME_PROP, ROOT_NODE_NAME);
-        context.getMap().put(CTX_SEARCH_PATHS_PROP, searchPaths);
-    }
-
-    @Override
-    protected Writer getWriter(ExecutionContext context,
-            SynchronizedDescriptiveStatistics writeStats, int idx) throws RepositoryException {
-        return new BlobWriter((context.getIncrement() + "-" + idx),
-                context.getIncrement() / LOADERS, writeStats);
-    }
-
-    private synchronized String getRandomReadPath() {
-        if (readPaths.isEmpty()) {
-            return "";
-        } else {
-            return readPaths.get(random.nextInt(readPaths.size()));
-        }
-    }
-
-    private synchronized void addReadPath(String file) {
-        // Limit the number of paths added to be no more than the number of readers to limit the
-        // heap used.
-        int limit = 1000;
-        if (readPaths.size() < limit) {
-            readPaths.add(file);
-        } else if (random.nextDouble() < 0.5) {
-            readPaths.set(random.nextInt(limit), file);
-        }
-    }
-
-    private synchronized void addSearchPath(String path) {
-        if (!searchPaths.contains(path)) {
-            searchPaths.add(path);
-        }
-    }
-
-    public String getNodeType() {
-        return nodeType;
-    }
-
-    protected void setNodeType(String nodeType) {
-        this.nodeType = nodeType;
-    }
-
-    private class Reader implements Runnable {
-
-        private final Session session = loginWriter();
-
-        @Override
-        public void run() {
-            try {
-                String path = getRandomReadPath();
-                session.refresh(false);
-                JcrUtils.readFile(
-                        session.getNode(path), new NullOutputStream());
-            } catch (Exception e) {
-                LOG.error("Exception in reader execution ", e);
-            }
-        }
-
-    }
-
-    /**
-     * Creates a node hierarchy similar to the below structure. Here a file Level0Level1Level2File0 is created
-     * which has a reference to Leve0Level1Level3File10:
-     *
-     * <pre>
-     * {@code
-     *  /LongevitySearchAssets<ID>
-     *      /writer<ID>
-     *          /0
-     *              /1
-     *                  /2
-     *                      /Level0Level1Level2File0
-     *                          jcr:primaryType : <oak:Unstructured|Asset|nt:unstructured>
-     *                          /jcr:content
-     *                              jcr:mimeType : <MIMETYPE>
-     *                              jcr:lastModified : <DATE>
-     *                              jcr:data : <BINARY>
-     *                              customPathProp : /LongevitySearchAssets<ID>/writer<ID>/0/1/2/Leve0Level1Level2File0
-     *                              references : /LongevitySearchAssets<ID>/writer<ID>/0/1/3/Leve0Level1Level3File10
-     * }
-     * </pre>
-     */
-    private class BlobWriter extends Writer implements Runnable {
-        BlobWriter(String id, int maxAssets, SynchronizedDescriptiveStatistics writeStats)
-                throws RepositoryException {
-            super(id, maxAssets, writeStats);
-        }
-
-        @Override
-        public void run() {
-            try {
-                int count = 0;
-                while (count < maxAssets) {
-                    session.refresh(false);
-
-                    List<String> levels = Lists.newArrayList();
-                    getParentLevels(count, maxAssets, levels);
-
-                    String fileNamePrefix = getFileNamePrefix(levels);
-                    String parentDir = getParentSuffix(levels);
-
-                    Stopwatch watch = Stopwatch.createStarted();
-
-                    Node file = putFile(fileNamePrefix, parentDir);
-                    session.save();
-
-                    if (stats != null) {
-                        stats.addValue(watch.elapsed(TimeUnit.MILLISECONDS));
-                    }
-
-                    // record for searching and reading
-                    addReadPath(file.getPath());
-                    addSearchPath(fileNamePrefix);
-
-                    if (LOG.isDebugEnabled() && (count + 1) % 1000 == 0) {
-                        LOG.debug("Thread " + id + " - Added assets : " + (count + 1));
-                    }
-                    count++;
-                }
-            } catch (Exception e) {
-                LOG.error("Exception in load creation ", e);
-            }
-        }
-
-        /**
-         * Puts the file at the given path with the given prefix.
-         * 
-         * @param fileNamePrefix the prefix for the filename
-         * @param parentDir the parent dir of the file
-         * @return the node
-         * @throws RepositoryException
-         * @throws UnsupportedRepositoryOperationException
-         * @throws ValueFormatException
-         * @throws VersionException
-         * @throws LockException
-         * @throws ConstraintViolationException
-         */
-        private Node putFile(String fileNamePrefix, String parentDir) throws RepositoryException {
-            Node filepath = JcrUtils.getOrAddNode(parent, parentDir, getParentType());
-            Node file =
-                    JcrUtils.getOrAddNode(filepath,
-                            (fileNamePrefix + "File" + counter++),
-                            getType());
-
-            Binary binary =
-                    parent.getSession().getValueFactory().createBinary(
-                            new TestInputStream(FILE_SIZE * 1024));
-            try {
-                Node content =
-                        JcrUtils.getOrAddNode(file, Node.JCR_CONTENT, NodeType.NT_RESOURCE);
-                if (indexType != null) {
-                    content.addMixin(CUSTOM_INDEX_TYPE);
-                    file.addMixin(CUSTOM_INDEX_TYPE);
-                }
-                content.setProperty(Property.JCR_MIMETYPE, MimeType.randomMimeType().getValue());
-                content.setProperty(Property.JCR_LAST_MODIFIED, Date.randomDate().getCalendar());
-                content.setProperty(Property.JCR_DATA, binary);
-
-                file.setProperty(CUSTOM_PATH_PROP, file.getPath());
-                String reference = getRandomReadPath();
-                if (!Strings.isNullOrEmpty(reference)) {
-                    file.setProperty(CUSTOM_REF_PROP, reference);
-                }
-            } finally {
-                binary.dispose();
-            }
-            return file;
-        }
-
-        /**
-         * Gets the node type of the parent.
-         * 
-         * @return the parent type
-         * @throws RepositoryException the repository exception
-         */
-        protected String getParentType() throws RepositoryException {
-            String type = NodeTypeConstants.NT_UNSTRUCTURED;
-            if (parent.getSession().getWorkspace().getNodeTypeManager().hasNodeType(
-                    NodeTypeConstants.NT_OAK_UNSTRUCTURED)) {
-                type = NodeTypeConstants.NT_OAK_UNSTRUCTURED;
-            }
-            return type;
-        }
-
-        /**
-         * Order of precedence is customNodeType, oak:Unstructured, nt:unstructured
-         * 
-         * @return the type
-         * @throws RepositoryException
-         */
-        protected String getType() throws RepositoryException {
-            String type = NodeTypeConstants.NT_UNSTRUCTURED;
-            if (!context.getMap().containsKey(CTX_FILE_NODE_TYPE_PROP)) {
-                if (getNodeType() != null) {
-                    type = getNodeType();
-                } else if (parent.getSession().getWorkspace().getNodeTypeManager().hasNodeType(
-                        NodeTypeConstants.NT_OAK_UNSTRUCTURED)) {
-                    type = NodeTypeConstants.NT_OAK_UNSTRUCTURED;
-                }
-                context.getMap().put(CTX_FILE_NODE_TYPE_PROP, type);
-            } else {
-                type = (String) context.getMap().get(CTX_FILE_NODE_TYPE_PROP);
-            }
-            return type;
-        }
-
-
-        /**
-         * Create a handy filename to search known files.
-         * 
-         * @param levels the levels for the file
-         * @return the prefix
-         */
-        private String getFileNamePrefix(List<String> levels) {
-            StringBuilder name = new StringBuilder();
-            for (String level : levels) {
-                name.append("Level").append(level);
-            }
-            return name.toString();
-        }
-
-        private String getParentSuffix(List<String> levels) {
-            StringBuilder parentSuffix = new StringBuilder();
-            for (String level : levels) {
-                parentSuffix.append(level).append("/");
-            }
-            return parentSuffix.toString();
-        }
-
-        /**
-         * Assigns the asset to it appropriate folder. The folder hierarchy is constructed such that
-         * each
-         * folder has only MAX_ASSETS_PER_LEVEL children.
-         * 
-         * @param assetNum the asset number
-         * @param maxAssets the max no. of assets to be created
-         * @param levels the no. of levels to create
-         */
-        private void getParentLevels(long assetNum, long maxAssets,
-                List<String> levels) {
-
-            int maxAssetsNextLevel =
-                    (int) Math.ceil((double) maxAssets / (double) MAX_ASSETS_PER_LEVEL);
-            long nextAssetBucket = assetNum / maxAssetsNextLevel;
-
-            levels.add(String.valueOf(nextAssetBucket));
-            if (maxAssetsNextLevel > MAX_ASSETS_PER_LEVEL) {
-                getParentLevels((assetNum - nextAssetBucket * maxAssetsNextLevel),
-                        maxAssetsNextLevel,
-                        levels);
-            }
-        }
-    }
-}
-
diff --git oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/scalability/suites/ScalabilityNodeRelationshipSuite.java oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/scalability/suites/ScalabilityNodeRelationshipSuite.java
deleted file mode 100644
index 0b4fee5..0000000
--- oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/scalability/suites/ScalabilityNodeRelationshipSuite.java
+++ /dev/null
@@ -1,554 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- *  or more contributor license agreements.  See the NOTICE file
- *  distributed with this work for additional information
- *  regarding copyright ownership.  The ASF licenses this file
- *  to you under the Apache License, Version 2.0 (the
- *  "License"); you may not use this file except in compliance
- *  with the License.  You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- *  Unless required by applicable law or agreed to in writing,
- *  software distributed under the License is distributed on an
- *  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- *  KIND, either express or implied.  See the License for the
- *  specific language governing permissions and limitations
- *  under the License.
- */
-package org.apache.jackrabbit.oak.scalability.suites;
-
-import java.util.Calendar;
-import java.util.List;
-import java.util.Map;
-import java.util.Random;
-import java.util.UUID;
-
-import javax.jcr.Node;
-import javax.jcr.NodeIterator;
-import javax.jcr.PropertyType;
-import javax.jcr.RepositoryException;
-import javax.jcr.Session;
-
-import com.google.common.collect.ImmutableList;
-import org.apache.commons.math.stat.descriptive.SynchronizedDescriptiveStatistics;
-import org.apache.jackrabbit.api.JackrabbitSession;
-import org.apache.jackrabbit.api.security.user.Authorizable;
-import org.apache.jackrabbit.api.security.user.Group;
-import org.apache.jackrabbit.api.security.user.User;
-import org.apache.jackrabbit.api.security.user.UserManager;
-import org.apache.jackrabbit.commons.JcrUtils;
-import org.apache.jackrabbit.oak.benchmark.util.OakIndexUtils;
-import org.apache.jackrabbit.oak.plugins.index.lucene.LuceneIndexConstants;
-import org.apache.jackrabbit.oak.plugins.index.property.OrderedIndex;
-import org.apache.jackrabbit.oak.plugins.index.search.FulltextIndexConstants;
-import org.apache.jackrabbit.oak.spi.nodetype.NodeTypeConstants;
-import org.apache.jackrabbit.oak.scalability.util.NodeTypeUtils;
-import org.apache.jackrabbit.util.Text;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-import com.google.common.base.Splitter;
-import com.google.common.base.StandardSystemProperty;
-import com.google.common.collect.Lists;
-import com.google.common.collect.Maps;
-
-/**
- * The suite test will incrementally increase the load and execute searches.
- * Each test run thus adds nodes and executes different benchmarks. This way we measure time
- * taken for benchmark execution.
- *
- * <p>
- * The following system JVM properties can be defined to configure the suite.
- * <ul>
- * <li>
- *     <code>nodeLevels</code> - Comma separated string property that governs the number of number of
- *     different node relationships in the following order:
- *      <ul>
- *          <li>Users</li>
- *          <li>Groups</li>
- *          <li>User Relationships</li>
- *          <li>Activities</li>
- *      </ul>
- *
- *     Defaults to 10,5,2,1.
- * </li>
- * </ul>
- *
- */
-public class ScalabilityNodeRelationshipSuite extends ScalabilityNodeSuite {
-    private static final Logger LOG =
-        LoggerFactory.getLogger(ScalabilityNodeRelationshipSuite.class);
-
-    public static final String CUSTOM_ACT_NODE_TYPE = "ActivityType";
-
-    public static final String CUSTOM_REL_NODE_TYPE = "RelationshipType";
-
-    public static final String ACTIVITIES = "Activities";
-
-    public static final String RELATIONSHIPS = "Relationships";
-
-    /**
-     * Node properties
-     */
-    public static final String CTX_USER = "User";
-    public static final String CTX_GROUP = "Group";
-    public static final String CREATED = "jcr:created";
-    public static final String SOURCE_ID = "sourceId";
-    public static final String TARGET_ID = "targetId";
-    public static final String ACTION = "action";
-    public static final String SOURCE = "source";
-    public static final String OBJECT = "object";
-    public static final String OBJECT_ID = "objectId";
-    public static final String TARGET = "target";
-
-    protected static final List<String> NODE_LEVELS = Splitter.on(",").trimResults()
-        .omitEmptyStrings().splitToList(System.getProperty("nodeLevels", "10,5,2,1"));
-
-    protected static final List<String> NODE_LEVELS_DEFAULT = ImmutableList.of("10","5","2","1");
-
-    private static final int NUM_USERS =
-        (NODE_LEVELS.size() >= 1 ? Integer.parseInt(NODE_LEVELS.get(0)) : Integer.parseInt(NODE_LEVELS_DEFAULT.get(0)));
-
-    private static final int NUM_GROUPS =
-        (NODE_LEVELS.size() >= 2 ? Integer.parseInt(NODE_LEVELS.get(1)) : Integer.parseInt(NODE_LEVELS_DEFAULT.get(1)));
-
-    private static final int NUM_RELATIONSHIPS =
-        (NODE_LEVELS.size() >= 3 ? Integer.parseInt(NODE_LEVELS.get(2)) : Integer.parseInt(NODE_LEVELS_DEFAULT.get(2)));
-
-    private static final int NUM_ACTIVITIES =
-        (NODE_LEVELS.size() >= 4 ? Integer.parseInt(NODE_LEVELS.get(3)) : Integer.parseInt(NODE_LEVELS_DEFAULT.get(3)));
-
-
-    private static final long BUCKET_SIZE = 100;
-
-    private static final List<String> actions = Lists
-        .newArrayList("act1", "act2", "act3", "act4", "act5", "act6", "act7", "act8", "act9",
-            "act10");
-    private static final List<String> objects = Lists
-        .newArrayList("obj1", "obj2", "obj3", "obj4", "obj5", "obj6", "obj7", "obj8", "obj9",
-            "obj10");
-
-    private final Random random = new Random(29);
-
-    private List<Authorizable> users;
-    private List<Authorizable> groups;
-
-    public ScalabilityNodeRelationshipSuite(Boolean storageEnabled) {
-        super(storageEnabled);
-    }
-
-    @Override
-    protected void beforeSuite() throws Exception {
-        Session session = loginWriter();
-        Node root = session.getRootNode();
-        root.addNode(ROOT_NODE_NAME);
-        session.save();
-
-        users = Lists.newArrayList();
-        groups = Lists.newArrayList();
-
-        if (CUSTOM_TYPE) {
-            NodeTypeUtils.createNodeType(session, CUSTOM_ACT_NODE_TYPE,
-                new String[] {TITLE_PROP, CREATED, ACTION, SOURCE_ID},
-                new int[] {PropertyType.STRING, PropertyType.DATE, PropertyType.STRING,
-                    PropertyType.STRING}, new String[0],
-                new String[] {NodeTypeConstants.NT_OAK_UNSTRUCTURED}, null, false);
-            NodeTypeUtils.createNodeType(session, CUSTOM_REL_NODE_TYPE,
-                new String[] {CREATED, SOURCE_ID, TARGET_ID},
-                new int[] {PropertyType.DATE, PropertyType.STRING, PropertyType.STRING},
-                new String[0], null, null, false);
-            nodeTypes.add(CUSTOM_ACT_NODE_TYPE);
-            nodeTypes.add(CUSTOM_REL_NODE_TYPE);
-        }
-
-        if (INDEX) {
-            createIndexes(session);
-        }
-    }
-
-    protected void createIndexes(Session session) throws RepositoryException {
-        Map<String, Map<String, String>> orderedMap = Maps.newHashMap();
-        String persistencePath = "";
-
-        // define indexes on properties
-        switch (INDEX_TYPE) {
-            case PROPERTY:
-                OakIndexUtils.propertyIndexDefinition(session, "customIndexActivity",
-                    new String[] {SOURCE_ID}, false,
-                    (!CUSTOM_TYPE ? new String[0] : new String[] {CUSTOM_ACT_NODE_TYPE}));
-                OakIndexUtils.propertyIndexDefinition(session, "customIndexRelationship",
-                    new String[] {SOURCE_ID}, false,
-                    (!CUSTOM_TYPE ? new String[0] : new String[] {CUSTOM_REL_NODE_TYPE}));
-                break;
-            // define ordered indexes on properties
-            case ORDERED:
-                OakIndexUtils.orderedIndexDefinition(session, "customIndexActivity", ASYNC_INDEX,
-                    new String[] {CREATED}, false,
-                    (!CUSTOM_TYPE ? new String[0] : new String[] {CUSTOM_ACT_NODE_TYPE}),
-                    OrderedIndex.OrderDirection.DESC.getDirection());
-                OakIndexUtils
-                    .orderedIndexDefinition(session, "customIndexRelationship", ASYNC_INDEX,
-                        new String[] {CREATED}, false,
-                        (!CUSTOM_TYPE ? new String[0] : new String[] {CUSTOM_REL_NODE_TYPE}),
-                        OrderedIndex.OrderDirection.DESC.getDirection());
-                break;
-            // define lucene index on properties
-            case LUCENE_FILE:
-                persistencePath =
-                    "target" + StandardSystemProperty.FILE_SEPARATOR.value() + "lucene" + String
-                        .valueOf(System.currentTimeMillis());
-                OakIndexUtils.luceneIndexDefinition(session, "customIndexActivity", ASYNC_INDEX,
-                    new String[] {SOURCE_ID, CREATED},
-                    new String[] {PropertyType.TYPENAME_STRING, PropertyType.TYPENAME_DATE},
-                    orderedMap, persistencePath);
-                break;
-            case LUCENE_FILE_DOC:
-                persistencePath =
-                    "target" + StandardSystemProperty.FILE_SEPARATOR.value() + "lucene" + String
-                        .valueOf(System.currentTimeMillis());
-            case LUCENE_DOC:
-                Map<String, String> propMap = Maps.newHashMap();
-                propMap.put(FulltextIndexConstants.PROP_TYPE, PropertyType.TYPENAME_DATE);
-                orderedMap.put(CREATED, propMap);
-            case LUCENE:
-                OakIndexUtils.luceneIndexDefinition(session, "customIndexActivity", ASYNC_INDEX,
-                    new String[] {SOURCE_ID, CREATED},
-                    new String[] {PropertyType.TYPENAME_STRING, PropertyType.TYPENAME_DATE},
-                    orderedMap, persistencePath);
-                break;
-        }
-    }
-
-    /**
-     * Executes before each test run
-     */
-    @Override
-    public void beforeIteration(ExecutionContext context) throws RepositoryException {
-        if (LOG.isDebugEnabled()) {
-            LOG.debug("Started beforeIteration()");
-        }
-
-        // Contextualize the node types being used
-        if (nodeTypes != null && !nodeTypes.isEmpty()) {
-            context.getMap().put(CTX_ACT_NODE_TYPE_PROP, nodeTypes.get(0));
-            context.getMap().put(CTX_REL_NODE_TYPE_PROP, nodeTypes.get(1));
-        }
-
-        Session session = loginWriter();
-        UserManager userMgr = ((JackrabbitSession) session).getUserManager();
-
-        context.getMap().put("PREV_ITER_USERS", users.size());
-
-        // Create Users and Groups based on the load for this iteration (cumulatively)
-        // Add users
-        for (int idx = 0; idx < NUM_USERS * context.getIncrement(); idx++) {
-            String name = String.valueOf((char) (random.nextInt(26) + 'a')) + CTX_USER + context
-                .getIncrement() + "_" + idx;
-            User user = userMgr.createUser(name, name);
-            LOG.debug("User created : " + name);
-            users.add(user);
-        }
-
-        // Add groups and include random number of members
-        for (int idx = 0; idx < NUM_GROUPS * context.getIncrement(); idx++) {
-            String name = String.valueOf((char) (random.nextInt(26) + 'a')) + CTX_GROUP + context
-                .getIncrement() + idx;
-            Group group = userMgr.createGroup(name);
-            groups.add(group);
-            int groupMembers = random.nextInt(users.size());
-            for (int i = 0; i < groupMembers; i++) {
-                group.addMember(users.get(random.nextInt(users.size())));
-            }
-        }
-        session.save();
-        // create the load for this iteration
-        createLoad(context);
-        long loadFinish = System.currentTimeMillis();
-
-        context.getMap().put(CTX_ROOT_NODE_NAME_PROP, ROOT_NODE_NAME);
-        context.getMap().put(CTX_USER, users);
-        context.getMap().put(CTX_GROUP, groups);
-
-        waitBeforeIterationFinish(loadFinish);
-
-        if (LOG.isDebugEnabled()) {
-            LOG.debug("Finished beforeIteration()");
-        }
-    }
-
-    @Override
-    protected Writer getWriter(ExecutionContext context,
-        SynchronizedDescriptiveStatistics writeStats, int idx) throws RepositoryException {
-        int numUsers = (context.getIncrement() * NUM_USERS) / LOADERS;
-        return new ActivityWriter((context.getIncrement() + "-" + idx), numUsers, idx * numUsers,
-            writeStats);
-    }
-
-    /**
-     * The users are created with the nomenclature {@code [a-z]User<INCREMENT>_<ID>}
-     *
-     * <p>
-     *
-     * Creates a node hierarchy similar to the node structure below.
-     * Here for example aUser0_1 and cUser0_5 are 2 users and aUser0_1 has a relationship structure to user cUser0_5.
-     *
-     * <pre>
-     * {@code
-     * /home
-     *  /a
-     *      /aUser0_1
-     *          /Relationships
-     *              /cUser0_5
-     *                  jcr:primaryType : <oak:Unstructured|descendantType|nt:unstructured>
-     *                  jcr:created : <DATE>
-     *                  sourceId : aUser0_1
-     *                  targetId : cUser0_5
-     *          /Activities
-     *             /2015
-     *                 /06
-     *                     /03
-     *                         /@1
-     *                             /<UUID>
-     *                                 jcr:primaryType : <oak:Unstructured|descendantType|nt:unstructured>
-     *                                 title : <sourceId targetId>
-     *                                 action : <act*>
-     *                                 sourceId : aUser0_1
-     *                                 /source
-     *                                     sourceId : aUser0_1
-     *                                 /object
-     *                                     objectId: <obj*>
-     *                                 /target
-     *                                     targetId: cUser0_5
-     * }
-     * </pre>
-     * </p>
-     */
-    class ActivityWriter extends Writer {
-        private int startIdx;
-
-        ActivityWriter(String id, int numUsers, int startIdx,
-            SynchronizedDescriptiveStatistics writeStats) throws RepositoryException {
-            super(id, numUsers, writeStats);
-            this.startIdx = startIdx;
-        }
-
-        @Override
-        public void run() {
-            try {
-                int idx = startIdx;
-                while (idx < (maxAssets + startIdx)) {
-                    session.refresh(false);
-
-                    // Current User
-                    int userIdx = (Integer) context.getMap().get("PREV_ITER_USERS") + idx;
-                    Authorizable user = users.get(userIdx);
-
-                    Node activitiesParentNode = JcrUtils
-                        .getOrAddNode(session.getNode(user.getPath()), ACTIVITIES,
-                            NodeTypeConstants.NT_OAK_UNSTRUCTURED);
-                    Node relationshipsParentNode = JcrUtils
-                        .getOrAddNode(session.getNode(user.getPath()), RELATIONSHIPS,
-                            NodeTypeConstants.NT_OAK_UNSTRUCTURED);
-                    createRelationships(user, relationshipsParentNode, activitiesParentNode);
-                    createActivities(user, activitiesParentNode);
-
-                    if ((counter + 1) % 100 == 0) {
-                        LOG.info("Thread " + id + " - Processed Users : " + (counter + 1));
-                    }
-                    idx++;
-                    counter++;
-                }
-            } catch (Exception e) {
-                LOG.error("Exception in load creation ", e);
-            }
-        }
-
-        /**
-         * Create activities for a use. The number of activities is governed by
-         * {# NODE_LEVELS.get(3)}
-         *
-         * @param user                 the user for who activities are to be created
-         * @param activitiesParentNode the parent node for all the user activities
-         * @throws RepositoryException
-         */
-        private void createActivities(Authorizable user, Node activitiesParentNode)
-            throws RepositoryException {
-            for (int i = 0; i < NUM_ACTIVITIES; i++) {
-                timer.start();
-
-                createActivity(activitiesParentNode, user.getID() + " " + i,
-                    actions.get(random.nextInt(actions.size())), user.getID(),
-                    objects.get(random.nextInt(objects.size())),
-                    objects.get(random.nextInt(objects.size())));
-
-                session.save();
-
-                // Record time taken for creation
-                timer.stop();
-            }
-        }
-
-        private void createActivity(Node activitiesParentNode, String title,
-                                    String action, String source, String object, String target) throws RepositoryException {
-            Node activityNode = getActivityParentNode(activitiesParentNode);
-
-            Map<String, String> activityMap = Maps.newHashMap();
-            activityMap.put(TITLE_PROP, title);
-            activityMap.put(ACTION, action);
-            activityMap.put(SOURCE_ID, source);
-            activityMap.put(OBJECT_ID, object);
-            activityMap.put(TARGET_ID, target);
-
-            createActivityNode(activityNode, activityMap);
-        }
-
-        /**
-         * Creates the activity node structure.
-         */
-        private void createActivityNode(Node activityParent, Map<String, String> props)
-            throws RepositoryException {
-            activityParent.setProperty(TITLE_PROP, props.get(TITLE_PROP));
-            activityParent.setProperty(CREATED, generateDate());
-            activityParent.setProperty(ACTION, props.get(ACTION));
-            activityParent.setProperty(SOURCE_ID, props.get(SOURCE_ID));
-            Node sourceNode = JcrUtils
-                .getOrAddNode(activityParent, SOURCE, NodeTypeConstants.NT_OAK_UNSTRUCTURED);
-            sourceNode.setProperty(SOURCE_ID, props.get(SOURCE_ID));
-
-            Node objNode = JcrUtils
-                .getOrAddNode(activityParent, OBJECT, NodeTypeConstants.NT_OAK_UNSTRUCTURED);
-            objNode.setProperty(OBJECT_ID, props.get(OBJECT_ID));
-
-            Node targetNode = JcrUtils
-                .getOrAddNode(activityParent, TARGET, NodeTypeConstants.NT_OAK_UNSTRUCTURED);
-            targetNode.setProperty(TARGET_ID, props.get(TARGET_ID));
-
-            LOG.debug(
-                "Activity created for User : " + props.get(SOURCE_ID) + " " + activityParent.getPath());
-        }
-
-        /**
-         * Creates bucketed parent node for the activity.
-         */
-        private Node getActivityParentNode(Node activitiesParentNode) throws RepositoryException {
-            Calendar c = Calendar.getInstance();
-            Node yearNode = JcrUtils
-                .getOrAddNode(activitiesParentNode, String.valueOf(c.get(Calendar.YEAR)),
-                    NodeTypeConstants.NT_OAK_UNSTRUCTURED);
-            String month = String.valueOf(c.get(Calendar.MONTH) + 1);
-            month = month.length() > 1 ? month : "0" + month;
-            Node monthNode =
-                JcrUtils.getOrAddNode(yearNode, month, NodeTypeConstants.NT_OAK_UNSTRUCTURED);
-            String day = String.valueOf(c.get(Calendar.DATE));
-            day = day.length() > 1 ? day : "0" + day;
-            Node dayNode =
-                JcrUtils.getOrAddNode(monthNode, day, NodeTypeConstants.NT_OAK_UNSTRUCTURED);
-
-            // find bucket
-            Node parentNode = dayNode;
-            NodeIterator iterator = dayNode.getNodes();
-            long size = iterator.getSize();
-            if (size < 0 || size > BUCKET_SIZE) {
-                size = 0;
-                int maxNum = -1;
-                while (iterator.hasNext()) {
-                    size++;
-                    Node child = iterator.nextNode();
-                    String name = child.getName();
-                    if (name.charAt(0) == '@') {
-                        int buckNum = Integer.parseInt(name.substring(1));
-                        if (buckNum > maxNum) {
-                            maxNum = buckNum;
-                            parentNode = child;
-                        }
-                    }
-                }
-                if (size > BUCKET_SIZE) {
-                    // check if last bucket has enough space
-                    if (maxNum < 0 || numChildNodes(parentNode) >= BUCKET_SIZE) {
-                        parentNode = dayNode.addNode("@" + String.valueOf(maxNum + 1),
-                            NodeTypeConstants.NT_OAK_UNSTRUCTURED);
-                    }
-                }
-            }
-            // create activity node
-            return JcrUtils
-                .getOrCreateUniqueByPath(parentNode, UUID.randomUUID().toString(), getType(0));
-        }
-
-        private long numChildNodes(Node node) throws RepositoryException {
-            NodeIterator iterator = node.getNodes();
-            if (iterator.getSize() >= 0) {
-                return iterator.getSize();
-            } else {
-                int num = 0;
-                while (iterator.hasNext() && num < BUCKET_SIZE) {
-                    iterator.nextNode();
-                    num++;
-                }
-                return num;
-            }
-        }
-
-        /**
-         * Create relationships to other users. The number of relationships is governed by
-         * {# NODE_LEVELS.get(2)}
-         *
-         * @param user                    the source user of the relationships
-         * @param relationshipsParentNode the node where the relationships are recorded  @throws
-         *                                RepositoryException
-         * @param activitiesParentNode the parent node for all the user activities
-         */
-        private void createRelationships(Authorizable user, Node relationshipsParentNode,
-            Node activitiesParentNode) throws RepositoryException {
-            List<Integer> usersIdx = Lists.newArrayList();
-            for (int count = 0; count < users.size(); count++) {
-                usersIdx.add(count);
-            }
-
-            for (int i = 0; i < NUM_RELATIONSHIPS; i++) {
-                if (usersIdx.size() > 0) {
-                    String otherUser =
-                        users.get(usersIdx.remove(random.nextInt(usersIdx.size()))).getID();
-                    timer.start();
-
-                    String nameHint = Text.getName(otherUser);
-                    Node rNode = relationshipsParentNode.addNode(nameHint, getType(1));
-                    rNode.setProperty(CREATED, generateDate());
-                    rNode.setProperty(SOURCE_ID, user.getID());
-                    rNode.setProperty(TARGET_ID, otherUser);
-
-                    LOG.debug(
-                        "Relationship created for User : " + user.getID() + " " + rNode.getPath());
-                    createActivity(activitiesParentNode, user.getID() + " " + otherUser,
-                        actions.get(random.nextInt(actions.size())), user.getID(),
-                        objects.get(random.nextInt(objects.size())), otherUser);
-
-                    session.save();
-
-                    timer.stop();
-                }
-            }
-        }
-
-        /**
-         * Order of precedence is custom type or oak:Unstructured
-         *
-         * @return the type
-         * @throws RepositoryException the repository exception
-         */
-        protected String getType(int typeIdx) throws RepositoryException {
-            String typeOfNode = (typeIdx == 0 ? CTX_ACT_NODE_TYPE_PROP : CTX_REL_NODE_TYPE_PROP);
-
-            String type = NodeTypeConstants.NT_OAK_UNSTRUCTURED;
-            if (context.getMap().containsKey(typeOfNode)) {
-                type = (String) context.getMap().get(typeOfNode);
-            } else {
-                context.getMap().put(typeOfNode, type);
-            }
-            return type;
-        }
-    }
-}
-
diff --git oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/scalability/suites/ScalabilityNodeSuite.java oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/scalability/suites/ScalabilityNodeSuite.java
deleted file mode 100644
index 13c84f0..0000000
--- oak-benchmarks/src/main/java/org/apache/jackrabbit/oak/scalability/suites/ScalabilityNodeSuite.java
+++ /dev/null
@@ -1,697 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- *  or more contributor license agreements.  See the NOTICE file
- *  distributed with this work for additional information
- *  regarding copyright ownership.  The ASF licenses this file
- *  to you under the Apache License, Version 2.0 (the
- *  "License"); you may not use this file except in compliance
- *  with the License.  You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- *  Unless required by applicable law or agreed to in writing,
- *  software distributed under the License is distributed on an
- *  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- *  KIND, either express or implied.  See the License for the
- *  specific language governing permissions and limitations
- *  under the License.
- */
-package org.apache.jackrabbit.oak.scalability.suites;
-
-import static com.google.common.collect.Lists.newArrayList;
-import static com.google.common.collect.Lists.newArrayListWithCapacity;
-
-import java.util.Calendar;
-import java.util.List;
-import java.util.Map;
-import java.util.Random;
-import java.util.TimeZone;
-import java.util.concurrent.TimeUnit;
-
-import javax.jcr.Node;
-import javax.jcr.PropertyType;
-import javax.jcr.Repository;
-import javax.jcr.RepositoryException;
-import javax.jcr.Session;
-
-import com.google.common.base.Splitter;
-import com.google.common.base.StandardSystemProperty;
-import com.google.common.base.Stopwatch;
-import com.google.common.base.Strings;
-import com.google.common.collect.Maps;
-
-import org.apache.commons.math.stat.descriptive.SynchronizedDescriptiveStatistics;
-import org.apache.jackrabbit.commons.JcrUtils;
-import org.apache.jackrabbit.oak.Oak;
-import org.apache.jackrabbit.oak.api.jmx.IndexStatsMBean;
-import org.apache.jackrabbit.oak.benchmark.util.OakIndexUtils;
-import org.apache.jackrabbit.oak.fixture.JcrCreator;
-import org.apache.jackrabbit.oak.fixture.OakRepositoryFixture;
-import org.apache.jackrabbit.oak.fixture.RepositoryFixture;
-import org.apache.jackrabbit.oak.jcr.Jcr;
-import org.apache.jackrabbit.oak.plugins.index.IndexConstants;
-import org.apache.jackrabbit.oak.plugins.index.lucene.LuceneIndexConstants;
-import org.apache.jackrabbit.oak.plugins.index.lucene.LuceneIndexEditorProvider;
-import org.apache.jackrabbit.oak.plugins.index.lucene.LuceneIndexProvider;
-import org.apache.jackrabbit.oak.plugins.index.lucene.util.LuceneInitializerHelper;
-import org.apache.jackrabbit.oak.plugins.index.property.OrderedIndex;
-import org.apache.jackrabbit.oak.plugins.index.search.FulltextIndexConstants;
-import org.apache.jackrabbit.oak.spi.nodetype.NodeTypeConstants;
-import org.apache.jackrabbit.oak.scalability.ScalabilitySuite;
-import org.apache.jackrabbit.oak.scalability.benchmarks.ScalabilityBenchmark;
-import org.apache.jackrabbit.oak.scalability.util.NodeTypeUtils;
-import org.apache.jackrabbit.oak.spi.commit.Observer;
-import org.apache.jackrabbit.oak.spi.query.QueryIndexProvider;
-import org.apache.jackrabbit.oak.spi.whiteboard.Whiteboard;
-import org.apache.jackrabbit.oak.spi.whiteboard.WhiteboardUtils;
-import org.apache.jackrabbit.util.ISO8601;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-/**
- * The suite test will incrementally increase the load and execute searches.
- * Each test run thus adds nodes and executes different benchmarks. This way we measure time taken for
- * benchmark execution.
- *
- * <p>
- * The following system JVM properties can be defined to configure the suite.
- * <ul>
- * <li>
- *     <code>loaders</code> - Controls the number of concurrent threads for loading blobs initially.
- *     Defaults to 1.
- * </li>
- * <li>
- *     <code>testers</code> - Controls the number of concurrent tester threads. Defaults to 1.
- * </li>
- * <li>
- *     <code>nodeLevels</code> - Comma separated string property that governs the depth and the number of
- *     nodes in the hierarchy. Defaults to 10, 5, 2.
- * </li>
- * <li>
- *     <code>densityLevel</code> - Controls the percentage of root nodes which will have sub nodes created.
- *     Defaults to 100.
- * </li>
- * <li>
- *     <code>index</code> - Controls if the index definitions are to be created. Defaults to false.
- * </li>
- * <li>
- *      <code>asyncIndex</code> - Controls whether the indexing is async. Defaults to false.
- * </li>
- * <li>
- *     <code>noFullIndex</code> - Controls whether fulltext indexing is enabled or disabled. Defaults to false.
- * </li>
- * <li>
- *     <code>randDate</code> - Controls whether to generate random dates in a range. Defaults to false.
- * </li>
- * <li>
- *     <code>customType</code> - Controls if nodes created in the load have a custom node type. Defaults to false.
- * </li>
- * </ul>
- *
- */
-public class ScalabilityNodeSuite extends ScalabilityAbstractSuite {
-    protected static final Logger LOG = LoggerFactory.getLogger(ScalabilityNodeSuite.class);
-
-    /**
-     * Controls the number of concurrent threads for loading blobs initially
-     */
-    protected static final int LOADERS = Integer.getInteger("loaders", 1);
-
-    /**
-     * Controls the number of nodes at each level
-     */
-    protected static final List<String> NODE_LEVELS = Splitter.on(",").trimResults()
-            .omitEmptyStrings().splitToList(System.getProperty("nodeLevels", "10,5,2"));
-
-    /**
-     * Controls the number of concurrent tester threads
-     */
-    protected static final int TESTERS = Integer.getInteger("testers", 1);
-
-    /**
-     * Controls the percentage of root nodes which will have sub nodes created.
-     * Value ranges from [0, 100]
-     */
-    protected static final int DENSITY_LEVEL = Integer.getInteger("densityLevel", 100);
-
-    /**
-     * Controls if the index definitions are to be created.
-     */
-    protected static final boolean INDEX = Boolean.getBoolean("index");
-
-    /**
-     * Controls whether the indexing is async
-     */
-    protected static final String ASYNC_INDEX = System.getProperty("asyncIndex");
-
-    /**
-     * Controls whether fulltext indexing is enabled or disabled. Enabled by default.
-     */
-    protected static final boolean FULL_TEXT = !Boolean.getBoolean("noFullIndex");
-
-    /**
-     * Controls whether to generate random dates in a range
-     */
-    protected static final boolean RAND_DATE = Boolean.getBoolean("randDate");
-
-    /**
-     * Controls if a customType is to be created
-     */
-    protected static final boolean CUSTOM_TYPE = Boolean.getBoolean("customType");
-
-    public static final String CTX_DESC_SEARCH_PATHS_PROP = "descPaths";
-
-    public static final String CTX_ROOT_NODE_NAME_PROP = "rootNodeName";
-
-    public static final String CTX_ACT_NODE_TYPE_PROP = "rootType";
-
-    public static final String CTX_REL_NODE_TYPE_PROP = "descendantType";
-
-    public static final String CUSTOM_ROOT_NODE_TYPE = "ParentType";
-
-    public static final String CUSTOM_DESC_NODE_TYPE = "DescendantType";
-
-    public static final String DATE_PROP = "added";
-
-    public static final String CTX_PAGINATION_KEY_PROP = DATE_PROP;
-
-    public static final String FILTER_PROP = "filter";
-
-    public static final String SORT_PROP = "viewed";
-
-    public static final String TITLE_PROP = "title";
-
-    public static final String ROOT_NODE_NAME =
-            "LongevitySearchAssets" + TEST_ID;
-
-    public enum Index {
-        PROPERTY, ORDERED, LUCENE, LUCENE_DOC, LUCENE_FILE, LUCENE_FILE_DOC
-    }
-
-    /** Type of index to be created */
-    public final Index INDEX_TYPE =
-        Index.valueOf(System.getProperty("indexType", Index.PROPERTY.toString()));
-
-    protected final Boolean storageEnabled;
-
-    protected Whiteboard whiteboard;
-
-    protected final List<String> nodeTypes;
-
-    private final Random random = new Random(29);
-
-    private List<String> searchRootPaths;
-
-    private List<String> searchDescPaths;
-
-    public ScalabilityNodeSuite(Boolean storageEnabled) {
-        this.storageEnabled = storageEnabled;
-        this.nodeTypes = newArrayList();
-    }
-
-    @Override
-    public ScalabilitySuite addBenchmarks(ScalabilityBenchmark... tests) {
-        for (ScalabilityBenchmark test : tests) {
-            benchmarks.put(test.toString(), test);
-        }
-        return this;
-    }
-
-    @Override
-    protected void beforeSuite() throws Exception {
-        Session session = loginWriter();
-        Node root = session.getRootNode();
-        root.addNode(ROOT_NODE_NAME);
-        session.save();
-
-        if (CUSTOM_TYPE) {
-            NodeTypeUtils.createNodeType(session, CUSTOM_DESC_NODE_TYPE,
-                    new String[] {DATE_PROP, SORT_PROP, FILTER_PROP, TITLE_PROP},
-                    new int[] {PropertyType.DATE, PropertyType.BOOLEAN, PropertyType.STRING,
-                            PropertyType.STRING},
-                    new String[0], new String[] {CUSTOM_DESC_NODE_TYPE}, null, false);
-            NodeTypeUtils.createNodeType(session, CUSTOM_ROOT_NODE_TYPE,
-                    new String[] {DATE_PROP, SORT_PROP, FILTER_PROP, TITLE_PROP},
-                    new int[] {PropertyType.DATE, PropertyType.BOOLEAN, PropertyType.STRING,
-                            PropertyType.STRING},
-                    new String[0], new String[] {CUSTOM_DESC_NODE_TYPE}, null, false);
-            nodeTypes.add(CUSTOM_ROOT_NODE_TYPE);
-            nodeTypes.add(CUSTOM_DESC_NODE_TYPE);
-        }
-
-        if (INDEX) {
-            createIndexes(session);
-        }
-    }
-
-    protected void createIndexes(Session session) throws RepositoryException {
-        Map<String, Map<String, String>> orderedMap = Maps.newHashMap();
-        String persistencePath = "";
-
-        switch (INDEX_TYPE) {
-            case ORDERED:
-                // define ordered indexes on properties
-                OakIndexUtils.orderedIndexDefinition(session, "customIndexParent", ASYNC_INDEX,
-                    new String[] {DATE_PROP}, false,
-                    (nodeTypes.isEmpty() ? new String[0] : new String[] {nodeTypes.get(0)}),
-                    OrderedIndex.OrderDirection.DESC.getDirection());
-                OakIndexUtils.orderedIndexDefinition(session, "customIndexDescendant", ASYNC_INDEX,
-                        new String[]{DATE_PROP}, false,
-                        (nodeTypes.isEmpty() ? new String[0]: new String[] {nodeTypes.get(1)}),
-                        OrderedIndex.OrderDirection.DESC.getDirection());
-                break;
-            // define lucene index on properties
-            case LUCENE_FILE:
-                persistencePath =
-                    "target" + StandardSystemProperty.FILE_SEPARATOR.value() + "lucene" + String
-                        .valueOf(System.currentTimeMillis());
-                OakIndexUtils.luceneIndexDefinition(session, "customIndex", ASYNC_INDEX,
-                    new String[] {FILTER_PROP, DATE_PROP},
-                    new String[] {PropertyType.TYPENAME_STRING, PropertyType.TYPENAME_DATE},
-                    null, persistencePath);
-                break;
-            case LUCENE_FILE_DOC:
-                persistencePath =
-                    "target" + StandardSystemProperty.FILE_SEPARATOR.value() + "lucene" + String
-                        .valueOf(System.currentTimeMillis());
-            case LUCENE_DOC:
-                Map<String, String> propMap = Maps.newHashMap();
-                propMap.put(FulltextIndexConstants.PROP_TYPE, PropertyType.TYPENAME_DATE);
-                orderedMap.put(DATE_PROP, propMap);
-            case LUCENE:
-                OakIndexUtils.luceneIndexDefinition(session, "customIndex", ASYNC_INDEX,
-                    new String[] {FILTER_PROP, DATE_PROP},
-                    new String[] {PropertyType.TYPENAME_STRING, PropertyType.TYPENAME_DATE},
-                    orderedMap, persistencePath);
-                break;
-            case PROPERTY:
-                break;
-        }
-    }
-
-    /**
-     * Executes before each test run
-     */
-    @Override
-    public void beforeIteration(ExecutionContext context) throws RepositoryException {
-        if (LOG.isDebugEnabled()) {
-            LOG.debug("Started beforeIteration()");
-        }
-
-        // Contextualize the node types being used
-        if (nodeTypes != null && !nodeTypes.isEmpty()) {
-            context.getMap().put(CTX_ACT_NODE_TYPE_PROP, nodeTypes.get(0));
-            context.getMap().put(CTX_REL_NODE_TYPE_PROP, nodeTypes.get(1));
-        }
-
-        // recreate paths created in this run
-        searchRootPaths = newArrayList();
-        searchDescPaths = newArrayList();
-
-        // create the blob load for this iteration
-        createLoad(context);
-        long loadFinish = System.currentTimeMillis();
-
-        context.getMap().put(CTX_ROOT_NODE_NAME_PROP, ROOT_NODE_NAME);
-        context.getMap().put(CTX_SEARCH_PATHS_PROP, searchRootPaths);
-        context.getMap().put(CTX_DESC_SEARCH_PATHS_PROP, searchDescPaths);
-
-        waitBeforeIterationFinish(loadFinish);
-
-        if (LOG.isDebugEnabled()) {
-            LOG.debug("Finished beforeIteration()");
-        }
-    }
-
-    protected void waitBeforeIterationFinish(long loadFinish) {
-        IndexStatsMBean indexStatsMBean = WhiteboardUtils.getService(whiteboard, IndexStatsMBean.class);
-
-        if (indexStatsMBean != null) {
-            String lastIndexedTime = indexStatsMBean.getLastIndexedTime();
-            while (((lastIndexedTime == null)
-                || ISO8601.parse(lastIndexedTime).getTimeInMillis() < loadFinish)) {
-                try {
-                    if (LOG.isDebugEnabled()) {
-                        LOG.debug("Waiting for async indexing to finish");
-                    }
-                    Thread.sleep(5000);
-                } catch (InterruptedException e) {
-                    LOG.error("Error waiting for async index to finish", e);
-                }
-                lastIndexedTime = indexStatsMBean.getLastIndexedTime();
-            }
-
-            LOG.info("Execution Count {}", indexStatsMBean.getExecutionCount());
-            LOG.info("Execution Time {}", indexStatsMBean.getExecutionTime());
-            LOG.info("Consolidated Execution Stats {}", indexStatsMBean.getConsolidatedExecutionStats());
-        }
-    }
-
-    /**
-     * Creates the load for the search.
-     *
-     * @param context the context
-     * @throws RepositoryException the repository exception
-     */
-    protected void createLoad(ExecutionContext context) throws RepositoryException {
-        // Creates assets for this run
-
-        SynchronizedDescriptiveStatistics writeStats = new SynchronizedDescriptiveStatistics();
-
-        List<Thread> loadThreads = newArrayList();
-        for (int idx = 0; idx < LOADERS; idx++) {
-            /* Each loader will write to a directory of the form load-idx */
-            Thread t =
-                    new Thread(getWriter(context, writeStats, idx),
-                            "LoadThread-" + idx);
-            loadThreads.add(t);
-            t.start();
-        }
-
-        // wait for the load threads to finish
-        for (Thread t : loadThreads) {
-            try {
-                t.join();
-            } catch (InterruptedException e) {
-                LOG.error("Exception waiting for join ", e);
-            }
-        }
-        
-        LOG.info("Write stats");
-        LOG.info(String.format(
-            "# min     10%%     50%%     90%%     max       N%n"));
-        LOG.info(String.format(
-            "%6.0f  %6.0f  %6.0f  %6.0f  %6.0f  %6d%n",
-            writeStats.getMin(),
-            writeStats.getPercentile(10.0),
-            writeStats.getPercentile(50.0),
-            writeStats.getPercentile(90.0),
-            writeStats.getMax(),
-            writeStats.getN()));
-    }
-
-    protected Writer getWriter(ExecutionContext context,
-            SynchronizedDescriptiveStatistics writeStats, int idx) throws RepositoryException {
-        return new Writer((context.getIncrement() + "-" + idx),
-                (context.getIncrement() * Integer.parseInt(NODE_LEVELS.get(0)))
-                        / LOADERS,
-                writeStats);
-    }
-
-    @Override
-    protected void executeBenchmark(final ScalabilityBenchmark benchmark,
-            final ExecutionContext context) throws Exception {
-
-        LOG.info("Started pre benchmark hook : {}", benchmark);
-        benchmark.beforeExecute(getRepository(), CREDENTIALS, context);
-
-        LOG.info("Started execution : {}", benchmark);
-        if (PROFILE) {
-            context.startProfiler();
-        }
-        //Execute the benchmark with the number threads configured 
-        List<Thread> threads = newArrayListWithCapacity(TESTERS);
-        for (int idx = 0; idx < TESTERS; idx++) {
-            Thread t = new Thread("Tester-" + idx) {
-                @Override
-                public void run() {
-                    try {
-                        benchmark.execute(getRepository(), CREDENTIALS, context);
-                    } catch (Exception e) {
-                        LOG.error("Exception in benchmark execution ", e);
-                    }
-                }
-            };
-            threads.add(t);
-            t.start();
-        }
-
-        for (Thread t : threads) {
-            try {
-                t.join();
-            } catch (Exception e) {
-                LOG.error("Exception in search thread join ", e);
-            }
-        }
-        context.stopProfiler();
-
-        LOG.info("Started post benchmark hook : {}", benchmark);
-        benchmark.afterExecute(getRepository(), CREDENTIALS, context);
-    }
-
-    @Override
-    protected Repository[] createRepository(RepositoryFixture fixture) throws Exception {
-        if (fixture instanceof OakRepositoryFixture) {
-            return ((OakRepositoryFixture) fixture).setUpCluster(1, new JcrCreator() {
-                @Override
-                public Jcr customize(Oak oak) {
-                    LuceneIndexProvider provider = new LuceneIndexProvider();
-                    oak.with((QueryIndexProvider) provider)
-                            .with((Observer) provider)
-                            .with(new LuceneIndexEditorProvider());
-
-                    if (!Strings.isNullOrEmpty(ASYNC_INDEX) && ASYNC_INDEX
-                        .equals(IndexConstants.ASYNC_PROPERTY_NAME)) {
-                        oak.withAsyncIndexing();
-                    }
-
-                    if (FULL_TEXT) {
-                        oak.with(new LuceneInitializerHelper("luceneGlobal", storageEnabled));
-                    }
-
-                    whiteboard = oak.getWhiteboard();
-                    return new Jcr(oak);
-                }
-            });
-        }
-        return super.createRepository(fixture);
-    }
-
-    private synchronized void addRootSearchPath(String path) {
-        int limit = 1000;
-        if (searchRootPaths.size() < limit) {
-            searchRootPaths.add(path);
-        } else if (random.nextDouble() < 0.5) {
-            searchRootPaths.set(random.nextInt(limit), path);
-        }
-    }
-
-    private synchronized void addDescSearchPath(String path) {
-        int limit = 1000;
-        if (searchDescPaths.size() < limit) {
-            searchDescPaths.add(path);
-        } else if (random.nextDouble() < 0.5) {
-            searchDescPaths.set(random.nextInt(limit), path);
-        }
-    }
-
-    /**
-     * Creates a node hierarchy as follows:
-     *
-     * <pre>
-     * {@code
-     *  /LongevitySearchAssets<ID>
-     *      /writer<ID>
-     *          /Node<ID>
-     *              jcr:primaryType : <oak:Unstructured|rootType|nt:unstructured>
-     *              added : <DATE>
-     *              viewed : <true|false>
-     *              filter : <true|false>
-     *              title : Node<ID>
-     *              /SubNode<ID>
-     *                  jcr:primaryType : <oak:Unstructured|descendantTypeType|nt:unstructured>
-     *                  added : <DATE>
-     *                  viewed : <true|false>
-     *                  filter : <true|false>
-     *                  title : SubNode<ID>
-     * }
-     * </pre>
-     */
-    class Writer implements Runnable {
-
-        final Node parent;
-
-        final Session session;
-
-        final String id;
-
-        final SynchronizedDescriptiveStatistics stats;
-
-        long counter;
-
-        int secsIn2Years = 31622400;
-
-        Calendar start;
-
-        long startMillis;
-
-        Timer timer;
-
-        /** The maximum number of assets to be written by this thread. */
-        final int maxAssets;
-
-        Writer(String id, int maxAssets, SynchronizedDescriptiveStatistics writeStats)
-                throws RepositoryException {
-            this.id = id;
-            this.maxAssets = maxAssets;
-            this.stats = writeStats;
-            this.session = loginWriter();
-            this.parent = session
-                    .getRootNode()
-                    .getNode(ROOT_NODE_NAME)
-                    .addNode("writer-" + id);
-            start = Calendar.getInstance();
-            start.add(Calendar.YEAR, -2);
-            start.setTimeZone(TimeZone.getTimeZone("GMT"));
-            startMillis = start.getTimeInMillis();
-
-            session.save();
-
-            timer = new Timer(writeStats);
-        }
-
-        protected Calendar generateDate() {
-            if (RAND_DATE) {
-                start.setTimeInMillis(startMillis + random.nextInt(secsIn2Years));
-            } else {
-                start.add(Calendar.SECOND, 1);
-            }
-            return start;
-        }
-
-        @Override
-        public void run() {
-            try {
-                int count = 1;
-                while (count <= maxAssets) {
-                    session.refresh(false);
-
-                    // skip creation of child nodes based on the defined DENSITY_LEVEL
-                    Node node =
-                            createParent(parent, (random.nextInt(100) <= DENSITY_LEVEL), "Node"
-                                    + count);
-
-                    // record for searching and reading
-                    addRootSearchPath(node.getPath());
-
-                    if ((counter + 1) % 1000 == 0) {
-                        LOG.info("Thread " + id + " - Added nodes : " + (counter));
-                    }
-                    count++;
-                }
-            } catch (Exception e) {
-                LOG.error("Exception in load creation ", e);
-            }
-            LOG.info("Max Assets created by " + id + " - " + counter);
-        }
-
-        private Node createParent(Node parent, boolean createChildren, String name) throws Exception {
-            Node node = createNode(parent, 0, name);
-
-            if (createChildren) {
-                createChildren(node, 1);
-            }
-
-            return node;
-        }
-
-        private void createChildren(Node parent, int levelIdx) throws Exception {
-            if (levelIdx > NODE_LEVELS.size() - 1) {
-                return;
-            }
-
-            // Recursively create sub nodes
-            for (int idx = 0; idx < Integer.parseInt(NODE_LEVELS.get(levelIdx)); idx++) {
-                Node subNode =
-                        createNode(parent, levelIdx, "SubNode-" + levelIdx + "-" + idx);
-                addDescSearchPath(subNode.getPath());
-
-                createChildren(subNode, (levelIdx + 1));
-            }
-        }
-
-        /**
-         * Creates the node.
-         *
-         * @param parent the parent
-         * @param levelIdx the level idx
-         * @param name the name
-         * @return the node
-         * @throws Exception the exception
-         */
-        private Node createNode(Node parent, int levelIdx, String name)
-                throws Exception {
-
-            timer.start();
-            Node node =
-                    JcrUtils.getOrAddNode(parent, name, getType(levelIdx));
-            // Add relevant properties
-            node.setProperty(DATE_PROP, generateDate());
-            node.setProperty(SORT_PROP, toss());
-            node.setProperty(FILTER_PROP, toss());
-            node.setProperty(TITLE_PROP, name);
-
-            session.save();
-            counter++;
-            if (LOG.isDebugEnabled()) {
-                LOG.debug(node.getPath());
-            }
-
-            // Record time taken for creation
-            timer.stop();
-
-            return node;
-        }
-
-        /**
-         * Order of precedence is customNodeType, oak:Unstructured, nt:unstructured.
-         *
-         * @param levelIdx the hierarchy level of node (root or descendant)
-         * @return the type
-         * @throws RepositoryException the repository exception
-         */
-        protected String getType(int levelIdx) throws RepositoryException {
-            String typeOfNode = (levelIdx == 0 ? CTX_ACT_NODE_TYPE_PROP : CTX_REL_NODE_TYPE_PROP);
-
-            String type = NodeTypeConstants.NT_UNSTRUCTURED;
-            if (context.getMap().containsKey(typeOfNode)) {
-                type = (String) context.getMap().get(typeOfNode);
-            } else if (parent.getSession().getWorkspace().getNodeTypeManager().hasNodeType(
-                    NodeTypeConstants.NT_OAK_UNSTRUCTURED)) {
-                type = NodeTypeConstants.NT_OAK_UNSTRUCTURED;
-                context.getMap().put(typeOfNode, type);
-            }
-            return type;
-        }
-
-        private boolean toss() {
-            int tossOutcome = random.nextInt(2);
-            return tossOutcome == 0;
-        }
-    }
-
-    static class Timer {
-        private final Stopwatch watch;
-        private final SynchronizedDescriptiveStatistics stats;
-
-        public Timer(SynchronizedDescriptiveStatistics stats) {
-            watch = Stopwatch.createUnstarted();
-            this.stats = stats;
-        }
-
-        public void start() {
-            if (watch.isRunning()) {
-                watch.stop();
-                watch.reset();
-            }
-            watch.start();
-        }
-
-        public void stop() {
-            watch.stop();
-            stats.addValue(watch.elapsed(TimeUnit.MILLISECONDS));
-            watch.reset();
-        }
-    }
-}
-
diff --git oak-lucene/src/main/java/org/apache/jackrabbit/oak/plugins/index/lucene/util/LuceneInitializerHelper.java oak-lucene/src/main/java/org/apache/jackrabbit/oak/plugins/index/lucene/util/LuceneInitializerHelper.java
index 63641b4..47cdcaf 100644
--- oak-lucene/src/main/java/org/apache/jackrabbit/oak/plugins/index/lucene/util/LuceneInitializerHelper.java
+++ oak-lucene/src/main/java/org/apache/jackrabbit/oak/plugins/index/lucene/util/LuceneInitializerHelper.java
@@ -18,6 +18,7 @@ package org.apache.jackrabbit.oak.plugins.index.lucene.util;
 
 import java.util.Set;
 
+import org.apache.jackrabbit.oak.plugins.index.IndexUtils;
 import org.apache.jackrabbit.oak.plugins.index.search.util.IndexHelper;
 import org.apache.jackrabbit.oak.spi.lifecycle.RepositoryInitializer;
 import org.apache.jackrabbit.oak.spi.state.NodeBuilder;
@@ -98,11 +99,11 @@ public class LuceneInitializerHelper implements RepositoryInitializer {
                 && builder.getChildNode(INDEX_DEFINITIONS_NAME).hasChildNode(name)) {
             // do nothing
         } else if (filePath == null) {
-            newLuceneIndexDefinition(builder.child(INDEX_DEFINITIONS_NAME),
+            newLuceneIndexDefinition(IndexUtils.getOrCreateOakIndex(builder),
                     name, propertyTypes, excludes, async, storageEnabled);
         } else {
             newLuceneFileIndexDefinition(
-                    builder.child(INDEX_DEFINITIONS_NAME),
+                    IndexUtils.getOrCreateOakIndex(builder),
                     name, propertyTypes, excludes, filePath, async);
         }
     }
diff --git pom.xml pom.xml
index 2b636f2..231fae5 100644
--- pom.xml
+++ pom.xml
@@ -76,6 +76,8 @@
     <module>oak-segment-azure</module>
     <module>oak-benchmarks</module>
     <module>oak-search-elastic</module>
+    <module>oak-benchmarks-lucene</module>
+    <module>oak-benchmarks-solr</module>
   </modules>
 
   <scm>
